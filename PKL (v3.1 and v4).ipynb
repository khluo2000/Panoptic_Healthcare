{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The csv file has been formed in the directory r'/Users/kinho123/Downloads/v3&4/id_1/recording2/15 mins trial/Iphone_mediapipe_meanRGB.csv'\n",
      "The csv file has been formed in the directory r'/Users/kinho123/Downloads/v3&4/id_1/recording2/15 mins trial/Ipad_mediapipe_meanRGB.csv'\n",
      "[29.998428246704602, 29.99842813112144]\n"
     ]
    }
   ],
   "source": [
    "# for converting the mean_rgb files (npz) to csv and show the frame of states#\n",
    "num = [1 ]\n",
    "people =  [\"id_{}\".format(i) for i in num]\n",
    "recording = 'recording2'\n",
    "protocol = '15 mins trial'\n",
    "devices = ['Iphone', 'Ipad']\n",
    "directory = r'/Users/kinho123/Downloads/v3&4'\n",
    "\n",
    "fps = []\n",
    "for person in people:\n",
    "    for device in devices:\n",
    "        \n",
    "        rgb = np.load(r\"{}/{}/{}/{}/{}_mediapipe_meanRGB.npz\".format(directory, person, recording, protocol, device), mmap_mode = 'r', allow_pickle = True)['arr_0']\n",
    "\n",
    "        rgb = rgb.reshape(-1, 1)[0][0]\n",
    "        rgb['mean_RGB'].to_csv(r'{}/{}/{}/{}/{}_mediapipe_meanRGB.csv'.format(directory, person, recording, protocol, device), header = True, index = False)\n",
    "        print(\"The csv file has been formed in the directory r'{}/{}/{}/{}/{}_mediapipe_meanRGB.csv'\".format(directory, person, recording, protocol, device))\n",
    "        fps.append(rgb[\"fps\"])\n",
    "        df = pd.read_csv(r\"/Users/kinho123/Downloads/v3&4/{}/recording2/15 mins trial/{}_mediapipe_meanRGB.csv\".format(person, device))\n",
    "        df = df[df['mean_B'].isna()]\n",
    "        df1 = df.diff()\n",
    "        df1 = df1[df1['Timestamp (s)']>50]\n",
    "        df1 = df1[df1['Timestamp (s)']<110]\n",
    "        df1[\"Start\"] = df1.index - df1[\"Frame index\"]\n",
    "        df1[\"Break\"] = df1.index - 20\n",
    "        df.to_csv(r'/Users/kinho123/Downloads/v3&4/{}/recording2/15 mins trial/all_frame_{}_mediapipe_meanRGB.csv'.format(person, device))\n",
    "        df1.to_csv(r'/Users/kinho123/Downloads/v3&4/{}/recording2/15 mins trial/frame_{}_mediapipe_meanRGB.csv'.format(person, device))\n",
    "print(fps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3/id_16/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3/id_16/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3/id_16/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3/id_16/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3/id_16/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3/id_16/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3/id_16/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3/id_16/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3/id_16/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3/id_16/recording2/13 mins trial. \n",
      "       Frame index  Timestamp (s)      mean_B      mean_G      mean_R\n",
      "18239      18240.0     608.031775         NaN         NaN         NaN\n",
      "18240      18241.0     608.065110  105.753864  117.301315  170.790093\n",
      "18241      18242.0     608.098445         NaN         NaN         NaN\n",
      "18242      18243.0     608.131780         NaN         NaN         NaN\n",
      "18243      18244.0     608.165116         NaN         NaN         NaN\n",
      "...            ...            ...         ...         ...         ...\n",
      "23664      23665.0     788.874559         NaN         NaN         NaN\n",
      "23665      23666.0     788.907894         NaN         NaN         NaN\n",
      "23666      23667.0     788.941229         NaN         NaN         NaN\n",
      "23667      23668.0     788.974564         NaN         NaN         NaN\n",
      "23668      23669.0     789.007900         NaN         NaN         NaN\n",
      "\n",
      "[5430 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------------------------------------------------------------------------------\n",
    "# for splitting the csv files of mean_rgb in 13 mins trial#\n",
    "def sec_to_stamps(sec, fps):\n",
    "    if sec == 0:\n",
    "        return None\n",
    "    else:\n",
    "        return (round(sec*fps))\n",
    "    \n",
    "\n",
    "def split_df(datafile_dir: str,  save_excel: bool = False) -> pd.DataFrame:\n",
    "    # Import the required libraries\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    # Read the mp csv\n",
    "    device = [\"Ipad\", \"Iphone\"]\n",
    "    index = 1\n",
    "    filename = [\"rPPG_{}\".format(device[index]), \"{}_mediapipe_meanRGB\".format(device[index])]\n",
    "    states = [\"RestL0\", \"Breath\", \"RestS\", \"Pedal\",\"RestL1\"]\n",
    "    luminosities = [\"300\"]\n",
    "    distances = [\"0.5\"]\n",
    "    s = np.array([16, 204, 391, 458, 615])-7\n",
    "    f = np.array([197, 385, 452, 609, 796])-7\n",
    "    for i, state in enumerate(states):\n",
    "        for j, name in enumerate(filename):\n",
    "            for luminosity in luminosities:\n",
    "                for distance in distances:\n",
    "                    \n",
    "                    mp_df = pd.read_csv(r\"{}/{}.csv\".format(datafile_dir, name) )[sec_to_stamps(s[i],fps[1]):sec_to_stamps(f[i],fps[1])]\n",
    "\n",
    "\n",
    "                    mp_df.to_csv(r\"{}/{}_{}_{}_{}.csv\".format(datafile_dir, name, state, luminosity , distance), header = True, index = False)\n",
    "                    print(\"The csv file has been formed in the directory {}. \".format(datafile_dir))\n",
    "                    # Return the dataframe\n",
    "    return mp_df\n",
    "\n",
    "\n",
    "\n",
    "num = 16\n",
    "datafile_dir = r\"/Users/kinho123/Downloads/v3/id_{}/recording2/13 mins trial\".format(num)\n",
    "\n",
    "# Read the mp csv\n",
    "mp_df = split_df(datafile_dir = datafile_dir, save_excel = True)\n",
    "print(mp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3/id_13/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3/id_13/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3/id_13/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3/id_13/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3/id_13/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3/id_13/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3/id_13/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3/id_13/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3/id_13/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3/id_13/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3/id_13/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3/id_13/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3/id_13/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3/id_13/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3/id_13/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3/id_13/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3/id_13/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3/id_13/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3/id_13/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3/id_13/recording2/13 mins trial. \n",
      "       03-02-2023 14:59:10.440  494206976  03-02-2023 14:59:17.523  0.38  \\\n",
      "37935  03-02-2023 15:09:17.416  499062784  03-02-2023 15:09:25.026 -0.04   \n",
      "37936  03-02-2023 15:09:17.416  499062784  03-02-2023 15:09:25.026 -0.05   \n",
      "37937  03-02-2023 15:09:17.416  499062784  03-02-2023 15:09:25.026 -0.06   \n",
      "37938  03-02-2023 15:09:17.416  499062784  03-02-2023 15:09:25.026 -0.08   \n",
      "37939  03-02-2023 15:09:17.416  499062784  03-02-2023 15:09:25.026 -0.10   \n",
      "...                        ...        ...                      ...   ...   \n",
      "49242  03-02-2023 15:12:18.152  500508672  03-02-2023 15:12:25.338 -0.29   \n",
      "49243  03-02-2023 15:12:18.152  500508672  03-02-2023 15:12:25.338 -0.29   \n",
      "49244  03-02-2023 15:12:18.152  500508672  03-02-2023 15:12:25.338 -0.30   \n",
      "49245  03-02-2023 15:12:18.152  500508672  03-02-2023 15:12:25.338 -0.32   \n",
      "49246  03-02-2023 15:12:18.152  500508672  03-02-2023 15:12:25.338 -0.36   \n",
      "\n",
      "       Unnamed: 4  \n",
      "37935         NaN  \n",
      "37936         NaN  \n",
      "37937         NaN  \n",
      "37938         NaN  \n",
      "37939         NaN  \n",
      "...           ...  \n",
      "49242         NaN  \n",
      "49243         NaN  \n",
      "49244         NaN  \n",
      "49245         NaN  \n",
      "49246         NaN  \n",
      "\n",
      "[11312 rows x 5 columns]\n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3/id_14/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3/id_14/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3/id_14/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3/id_14/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3/id_14/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3/id_14/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3/id_14/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3/id_14/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3/id_14/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3/id_14/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3/id_14/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3/id_14/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3/id_14/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3/id_14/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3/id_14/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3/id_14/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3/id_14/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3/id_14/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3/id_14/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3/id_14/recording2/13 mins trial. \n",
      "       06-02-2023 16:05:02.992  2598453248  06-02-2023 16:05:10.027  1.89  \\\n",
      "41071  06-02-2023 16:16:00.144  2603710464  06-02-2023 16:16:07.722  0.24   \n",
      "41072  06-02-2023 16:16:00.144  2603710464  06-02-2023 16:16:07.722 -0.17   \n",
      "41073  06-02-2023 16:16:00.144  2603710464  06-02-2023 16:16:07.722 -0.58   \n",
      "41074  06-02-2023 16:16:00.144  2603710464  06-02-2023 16:16:07.722 -0.60   \n",
      "41075  06-02-2023 16:16:00.144  2603710464  06-02-2023 16:16:07.722 -0.60   \n",
      "...                        ...         ...                      ...   ...   \n",
      "52378  06-02-2023 16:19:00.880  2605156352  06-02-2023 16:19:08.041 -0.60   \n",
      "52379  06-02-2023 16:19:00.880  2605156352  06-02-2023 16:19:08.041 -0.60   \n",
      "52380  06-02-2023 16:19:00.880  2605156352  06-02-2023 16:19:08.041 -0.60   \n",
      "52381  06-02-2023 16:19:00.880  2605156352  06-02-2023 16:19:08.041 -0.60   \n",
      "52382  06-02-2023 16:19:00.880  2605156352  06-02-2023 16:19:08.041 -0.60   \n",
      "\n",
      "       Unnamed: 4  \n",
      "41071         NaN  \n",
      "41072         NaN  \n",
      "41073         NaN  \n",
      "41074         NaN  \n",
      "41075         NaN  \n",
      "...           ...  \n",
      "52378         NaN  \n",
      "52379         NaN  \n",
      "52380         NaN  \n",
      "52381         NaN  \n",
      "52382         NaN  \n",
      "\n",
      "[11312 rows x 5 columns]\n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3/id_15/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3/id_15/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3/id_15/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3/id_15/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3/id_15/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3/id_15/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3/id_15/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3/id_15/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3/id_15/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3/id_15/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3/id_15/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3/id_15/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3/id_15/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3/id_15/recording2/13 mins trial. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3/id_15/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3/id_15/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3/id_15/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3/id_15/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3/id_15/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3/id_15/recording2/13 mins trial. \n",
      "       06-02-2023 17:14:29.640  2631770112  06-02-2023 17:14:36.542  1.52  \\\n",
      "39855  06-02-2023 17:25:07.336  2636871680  06-02-2023 17:25:14.784  1.90   \n",
      "39856  06-02-2023 17:25:07.336  2636871680  06-02-2023 17:25:14.784  1.90   \n",
      "39857  06-02-2023 17:25:07.336  2636871680  06-02-2023 17:25:14.784  1.90   \n",
      "39858  06-02-2023 17:25:07.336  2636871680  06-02-2023 17:25:14.784  1.90   \n",
      "39859  06-02-2023 17:25:07.336  2636871680  06-02-2023 17:25:14.784  1.90   \n",
      "...                        ...         ...                      ...   ...   \n",
      "51162  06-02-2023 17:28:08.072  2638317568  06-02-2023 17:28:15.094 -0.12   \n",
      "51163  06-02-2023 17:28:08.072  2638317568  06-02-2023 17:28:15.094 -0.12   \n",
      "51164  06-02-2023 17:28:08.072  2638317568  06-02-2023 17:28:15.094 -0.12   \n",
      "51165  06-02-2023 17:28:08.072  2638317568  06-02-2023 17:28:15.094 -0.13   \n",
      "51166  06-02-2023 17:28:08.072  2638317568  06-02-2023 17:28:15.094 -0.13   \n",
      "\n",
      "       Unnamed: 4  \n",
      "39855         NaN  \n",
      "39856         NaN  \n",
      "39857         NaN  \n",
      "39858         NaN  \n",
      "39859         NaN  \n",
      "...           ...  \n",
      "51162         NaN  \n",
      "51163         NaN  \n",
      "51164         NaN  \n",
      "51165         NaN  \n",
      "51166         NaN  \n",
      "\n",
      "[11312 rows x 5 columns]\n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3/id_16/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3/id_16/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3/id_16/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3/id_16/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3/id_16/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3/id_16/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3/id_16/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3/id_16/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3/id_16/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3/id_16/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3/id_16/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3/id_16/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3/id_16/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3/id_16/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3/id_16/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3/id_16/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3/id_16/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3/id_16/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3/id_16/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3/id_16/recording2/13 mins trial. \n",
      "       07-02-2023 10:48:12.672  3137314816  07-02-2023 10:48:18.947  -0.12  \\\n",
      "38383  07-02-2023 10:58:26.816  3142227968  07-02-2023 10:58:33.620  -0.03   \n",
      "38384  07-02-2023 10:58:26.816  3142227968  07-02-2023 10:58:33.620   0.00   \n",
      "38385  07-02-2023 10:58:26.816  3142227968  07-02-2023 10:58:33.620   0.02   \n",
      "38386  07-02-2023 10:58:26.816  3142227968  07-02-2023 10:58:33.620   0.03   \n",
      "38387  07-02-2023 10:58:26.816  3142227968  07-02-2023 10:58:33.620   0.02   \n",
      "...                        ...         ...                      ...    ...   \n",
      "49690  07-02-2023 11:01:27.552  3143673856  07-02-2023 11:01:33.928   0.41   \n",
      "49691  07-02-2023 11:01:27.552  3143673856  07-02-2023 11:01:33.928   0.41   \n",
      "49692  07-02-2023 11:01:27.552  3143673856  07-02-2023 11:01:33.928   0.39   \n",
      "49693  07-02-2023 11:01:27.552  3143673856  07-02-2023 11:01:33.928   0.37   \n",
      "49694  07-02-2023 11:01:27.552  3143673856  07-02-2023 11:01:33.928   0.34   \n",
      "\n",
      "       Unnamed: 4  \n",
      "38383         NaN  \n",
      "38384         NaN  \n",
      "38385         NaN  \n",
      "38386         NaN  \n",
      "38387         NaN  \n",
      "...           ...  \n",
      "49690         NaN  \n",
      "49691         NaN  \n",
      "49692         NaN  \n",
      "49693         NaN  \n",
      "49694         NaN  \n",
      "\n",
      "[11312 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------------------------------------------------------------------------------\n",
    "# for splitting the csv files of vital in 13 mins trial#\n",
    "def sec_to_stamps(sec, fps):\n",
    "    if sec == 0:\n",
    "        return None\n",
    "    else:\n",
    "        return -(round(sec*fps))\n",
    "\n",
    "\n",
    "def shift_df(datafile_dir: str,  save_excel: bool = False) -> pd.DataFrame:\n",
    "    # Import the required libraries\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    # Read the mp csv\n",
    "    filename = [\"MPDataExport\", \"NOM_ECG_ELEC_POTL_IIWaveExport\", \"NOM_PLETHWaveExport\", \"NOM_RESPWaveExport\"]\n",
    "    fps = [1/(1.024),750, 125,125/2]\n",
    "    states = [\"RestL0\", \"Breath\", \"RestS\", \"Pedal\",\"RestL1\"]\n",
    "    luminosities = [\"300\"]\n",
    "    distances = [\"0.5\"]\n",
    "    s = [780, 592, 405, 338, 181]\n",
    "    f = [599, 411, 344, 187, 0 ]\n",
    "    for i, state in enumerate(states):\n",
    "        for j, name in enumerate(filename):\n",
    "            for luminosity in luminosities:\n",
    "                for distance in distances:\n",
    "                    \n",
    "                    mp_df = pd.read_csv(r\"{}/{}.csv\".format(datafile_dir, name) )[sec_to_stamps(s[i],fps[j]):sec_to_stamps(f[i],fps[j])]\n",
    "\n",
    "\n",
    "                    mp_df.to_csv(r\"{}/{}_{}_{}_{}.csv\".format(datafile_dir, name, state, luminosity , distance), header = True, index = False)\n",
    "                    print(\"The csv file has been formed in the directory {}. \".format(datafile_dir))\n",
    "                    # Return the dataframe\n",
    "    return mp_df\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Define the directory and the filename\n",
    "    num = [13, 13+1, 15, 16 ]\n",
    "    for i in num:\n",
    "        datafile_dir = r\"/Users/kinho123/Downloads/v3/id_{}/recording2/13 mins trial\".format(i)\n",
    "\n",
    "    # Read the mp csv\n",
    "        mp_df = shift_df(datafile_dir = datafile_dir, save_excel = True)\n",
    "        print(mp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished: v3_id_1_recording2_13 mins trial_RestL0_300_0.5\n",
      "finished: v3_id_1_recording2_13 mins trial_Breath_300_0.5\n",
      "finished: v3_id_1_recording2_13 mins trial_RestS_300_0.5\n",
      "finished: v3_id_1_recording2_13 mins trial_Pedal_300_0.5\n",
      "finished: v3_id_1_recording2_13 mins trial_RestL1_300_0.5\n",
      "finished: v3_id_2_recording2_13 mins trial_RestL0_300_0.5\n",
      "finished: v3_id_2_recording2_13 mins trial_Breath_300_0.5\n",
      "finished: v3_id_2_recording2_13 mins trial_RestS_300_0.5\n",
      "finished: v3_id_2_recording2_13 mins trial_Pedal_300_0.5\n",
      "finished: v3_id_2_recording2_13 mins trial_RestL1_300_0.5\n",
      "finished: v3_id_3_recording2_13 mins trial_RestL0_300_0.5\n",
      "finished: v3_id_3_recording2_13 mins trial_Breath_300_0.5\n",
      "finished: v3_id_3_recording2_13 mins trial_RestS_300_0.5\n",
      "finished: v3_id_3_recording2_13 mins trial_Pedal_300_0.5\n",
      "finished: v3_id_3_recording2_13 mins trial_RestL1_300_0.5\n",
      "finished: v3_id_4_recording2_13 mins trial_RestL0_300_0.5\n",
      "finished: v3_id_4_recording2_13 mins trial_Breath_300_0.5\n",
      "finished: v3_id_4_recording2_13 mins trial_RestS_300_0.5\n",
      "finished: v3_id_4_recording2_13 mins trial_Pedal_300_0.5\n",
      "finished: v3_id_4_recording2_13 mins trial_RestL1_300_0.5\n",
      "finished: v3_id_5_recording2_13 mins trial_RestL0_300_0.5\n",
      "finished: v3_id_5_recording2_13 mins trial_Breath_300_0.5\n",
      "finished: v3_id_5_recording2_13 mins trial_RestS_300_0.5\n",
      "finished: v3_id_5_recording2_13 mins trial_Pedal_300_0.5\n",
      "finished: v3_id_5_recording2_13 mins trial_RestL1_300_0.5\n",
      "finished: v3_id_6_recording2_13 mins trial_RestL0_300_0.5\n",
      "finished: v3_id_6_recording2_13 mins trial_Breath_300_0.5\n",
      "finished: v3_id_6_recording2_13 mins trial_RestS_300_0.5\n",
      "finished: v3_id_6_recording2_13 mins trial_Pedal_300_0.5\n",
      "finished: v3_id_6_recording2_13 mins trial_RestL1_300_0.5\n",
      "finished: v3_id_7_recording2_13 mins trial_RestL0_300_0.5\n",
      "finished: v3_id_7_recording2_13 mins trial_Breath_300_0.5\n",
      "finished: v3_id_7_recording2_13 mins trial_RestS_300_0.5\n",
      "finished: v3_id_7_recording2_13 mins trial_Pedal_300_0.5\n",
      "finished: v3_id_7_recording2_13 mins trial_RestL1_300_0.5\n",
      "finished: v3_id_8_recording2_13 mins trial_RestL0_300_0.5\n",
      "finished: v3_id_8_recording2_13 mins trial_Breath_300_0.5\n",
      "finished: v3_id_8_recording2_13 mins trial_RestS_300_0.5\n",
      "finished: v3_id_8_recording2_13 mins trial_Pedal_300_0.5\n",
      "finished: v3_id_8_recording2_13 mins trial_RestL1_300_0.5\n",
      "finished: v3_id_9_recording2_13 mins trial_RestL0_300_0.5\n",
      "finished: v3_id_9_recording2_13 mins trial_Breath_300_0.5\n",
      "finished: v3_id_9_recording2_13 mins trial_RestS_300_0.5\n",
      "finished: v3_id_9_recording2_13 mins trial_Pedal_300_0.5\n",
      "finished: v3_id_9_recording2_13 mins trial_RestL1_300_0.5\n",
      "finished: v3_id_10_recording2_13 mins trial_RestL0_300_0.5\n",
      "finished: v3_id_10_recording2_13 mins trial_Breath_300_0.5\n",
      "finished: v3_id_10_recording2_13 mins trial_RestS_300_0.5\n",
      "finished: v3_id_10_recording2_13 mins trial_Pedal_300_0.5\n",
      "finished: v3_id_10_recording2_13 mins trial_RestL1_300_0.5\n",
      "finished: v3_id_11_recording2_13 mins trial_RestL0_300_0.5\n",
      "finished: v3_id_11_recording2_13 mins trial_Breath_300_0.5\n",
      "finished: v3_id_11_recording2_13 mins trial_RestS_300_0.5\n",
      "finished: v3_id_11_recording2_13 mins trial_Pedal_300_0.5\n",
      "finished: v3_id_11_recording2_13 mins trial_RestL1_300_0.5\n",
      "finished: v3_id_12_recording2_13 mins trial_RestL0_300_0.5\n",
      "finished: v3_id_12_recording2_13 mins trial_Breath_300_0.5\n",
      "finished: v3_id_12_recording2_13 mins trial_RestS_300_0.5\n",
      "finished: v3_id_12_recording2_13 mins trial_Pedal_300_0.5\n",
      "finished: v3_id_12_recording2_13 mins trial_RestL1_300_0.5\n",
      "finished: v3_id_13_recording2_13 mins trial_RestL0_300_0.5\n",
      "finished: v3_id_13_recording2_13 mins trial_Breath_300_0.5\n",
      "finished: v3_id_13_recording2_13 mins trial_RestS_300_0.5\n",
      "finished: v3_id_13_recording2_13 mins trial_Pedal_300_0.5\n",
      "finished: v3_id_13_recording2_13 mins trial_RestL1_300_0.5\n",
      "finished: v3_id_14_recording2_13 mins trial_RestL0_300_0.5\n",
      "finished: v3_id_14_recording2_13 mins trial_Breath_300_0.5\n",
      "finished: v3_id_14_recording2_13 mins trial_RestS_300_0.5\n",
      "finished: v3_id_14_recording2_13 mins trial_Pedal_300_0.5\n",
      "finished: v3_id_14_recording2_13 mins trial_RestL1_300_0.5\n",
      "finished: v3_id_15_recording2_13 mins trial_RestL0_300_0.5\n",
      "finished: v3_id_15_recording2_13 mins trial_Breath_300_0.5\n",
      "finished: v3_id_15_recording2_13 mins trial_RestS_300_0.5\n",
      "finished: v3_id_15_recording2_13 mins trial_Pedal_300_0.5\n",
      "finished: v3_id_15_recording2_13 mins trial_RestL1_300_0.5\n",
      "finished: v3_id_16_recording2_13 mins trial_RestL0_300_0.5\n",
      "finished: v3_id_16_recording2_13 mins trial_Breath_300_0.5\n",
      "finished: v3_id_16_recording2_13 mins trial_RestS_300_0.5\n",
      "finished: v3_id_16_recording2_13 mins trial_Pedal_300_0.5\n",
      "finished: v3_id_16_recording2_13 mins trial_RestL1_300_0.5\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------------------------------------------------------------------------------        \n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Created on Thu Dec  8 17:23:50 2022\n",
    "\n",
    "@author: Ellgan\n",
    "\"\"\"\n",
    "\n",
    "# Import libraries\n",
    "# import cv2\n",
    "#import datetime as dt\n",
    "import os\n",
    "from datetime import datetime\n",
    "# from functools import partial\n",
    "# import matplotlib.pyplot as plt\n",
    "# import re\n",
    "\n",
    "# Expand the dataframe if necessary\n",
    "pd.set_option('display.expand_frame_repr', False)\n",
    "# Define the path for hkstp and home\n",
    "hkstp1home2 = 1\n",
    "\n",
    "# Define the directory of the data files (Change it if necessary)\n",
    "if hkstp1home2 == 1:\n",
    "    datafile_dir = r\"/Users/kinho123/Downloads\"\n",
    "elif hkstp1home2 == 2:\n",
    "    datafile_dir = \"/User/Ellgan/Download\"\n",
    "\n",
    "\n",
    "# --------------------------------------------------------------------- Function part -----------------------------------------------------------------------------\n",
    "def read_csv_data(datafile_dir: str, filename: str, state: str, luminosity: str, distance: str, col_name: str) -> pd.DataFrame:\n",
    "    # Read the csv\n",
    "    df = pd.read_csv(\"{}/{}_{}_{}_{}.csv\".format(datafile_dir, filename, state, luminosity, distance), index_col=False,\n",
    "                     names=[\"Time\", \"RelativeTime\", \"SystemLocalTime\", col_name], engine='python')\n",
    "    # Change the data type of time\n",
    "    df[\"Time\"] = pd.to_datetime(df[\"Time\"], format=\"%d-%m-%Y %H:%M:%S.%f\")\n",
    "    # Change the data type of relative time\n",
    "    df[\"RelativeTime\"] = df[\"RelativeTime\"].astype(np.int64)\n",
    "    # Change the data type of system local time\n",
    "    df[\"SystemLocalTime\"] = pd.to_datetime(df[\"SystemLocalTime\"], format=\"%d-%m-%Y %H:%M:%S.%f\")\n",
    "    # ------------------------------------------------------------------------------------------------------------------------------\n",
    "    if col_name in [\"PLETH\", \"RESP\"]:\n",
    "        for item in [\"Time\", \"RelativeTime\", \"SystemLocalTime\"]:\n",
    "            time_dic = df[item].value_counts(dropna=False).to_dict()\n",
    "            # Sort the time dictionary by timestamp\n",
    "            time_dic = dict(sorted(time_dic.items(), key=lambda item: item[0]))\n",
    "            if item == \"RelativeTime\":\n",
    "                # initialize a list\n",
    "                rel_time_ls = np.array([])\n",
    "                for index in range(len(list(time_dic.keys())) - 1):\n",
    "                    ref_ls = np.linspace(start=list(time_dic.keys())[index], stop=list(time_dic.keys())[index + 1], \\\n",
    "                                         num=list(time_dic.values())[index] + 1)[:-1]\n",
    "                    rel_time_ls = np.concatenate([rel_time_ls, ref_ls])\n",
    "                # Find the difference of frames\n",
    "                difference = list(time_dic.keys())[2] - list(time_dic.keys())[1]\n",
    "                # Find the count\n",
    "                count = max(list(set(time_dic.values())))\n",
    "                # Add the last date range\n",
    "                ref_ls = np.array(\n",
    "                    [list(time_dic.keys())[-1] + i * difference / count for i in range(list(time_dic.values())[-1])])\n",
    "                rel_time_ls = np.concatenate([rel_time_ls, ref_ls])\n",
    "                # Sort the new date range\n",
    "                new_date_range = sorted(rel_time_ls)\n",
    "                # Replace the original column\n",
    "                df[item] = rel_time_ls\n",
    "            else:\n",
    "                # Initialize the new date range\n",
    "                new_date_range = pd.DatetimeIndex([], dtype='datetime64[ns]', freq=None)\n",
    "                # For loop to expand the date range\n",
    "                for index in range(len(list(time_dic.keys())) - 1):\n",
    "                    new_date_range = new_date_range.append(\n",
    "                        pd.date_range(start=list(time_dic.keys())[index], end=list(time_dic.keys())[index + 1], \\\n",
    "                                      periods=list(time_dic.values())[index] + 1)[:-1])\n",
    "                # Find the frequency\n",
    "                frequency = (1 / 125) * 1000\n",
    "                # Add the last date range\n",
    "                new_date_range = new_date_range.append(\n",
    "                    pd.date_range(start=list(time_dic.keys())[-1], freq=\"{:.3f}ms\".format(frequency),\n",
    "                                  periods=list(time_dic.values())[-1]))\n",
    "                # Sort the new date range\n",
    "                new_date_range = sorted(new_date_range)\n",
    "                # Replace the original column\n",
    "                df[item] = new_date_range\n",
    "\n",
    "    elif col_name == \"ELEC\":\n",
    "        for item in [\"Time\", \"RelativeTime\", \"SystemLocalTime\"]:\n",
    "            time_dic = df[item].value_counts(dropna=False).to_dict()\n",
    "            # Sort the time dictionary by timestamp\n",
    "            time_dic = dict(sorted(time_dic.items(), key=lambda item: item[0]))\n",
    "            if item == \"RelativeTime\":\n",
    "                # initialize a list\n",
    "                rel_time_ls = np.array([])\n",
    "                for index in range(len(list(time_dic.keys())) - 1):\n",
    "                    ref_ls = np.linspace(start=list(time_dic.keys())[index], stop=list(time_dic.keys())[index + 1], \\\n",
    "                                         num=list(time_dic.values())[index] + 1)[:-1]\n",
    "                    rel_time_ls = np.concatenate([rel_time_ls, ref_ls])\n",
    "                # Find the difference of frames\n",
    "                difference = list(time_dic.keys())[2] - list(time_dic.keys())[1]\n",
    "                # Find the count\n",
    "                count = max(list(set(time_dic.values())))\n",
    "                # Add the last date range\n",
    "                ref_ls = np.array(\n",
    "                    [list(time_dic.keys())[-1] + i * difference / count for i in range(list(time_dic.values())[-1])])\n",
    "                rel_time_ls = np.concatenate([rel_time_ls, ref_ls])\n",
    "                # Sort the new date range\n",
    "                new_date_range = sorted(rel_time_ls)\n",
    "                # Replace the original column\n",
    "                df[item] = rel_time_ls\n",
    "            else:\n",
    "                # Initialize the new date range\n",
    "                new_date_range = pd.DatetimeIndex([], dtype='datetime64[ns]', freq=None)\n",
    "                # For loop to expand the date range\n",
    "                for index in range(len(list(time_dic.keys())) - 1):\n",
    "                    new_date_range = new_date_range.append(\n",
    "                        pd.date_range(start=list(time_dic.keys())[index], end=list(time_dic.keys())[index + 1], \\\n",
    "                                      periods=list(time_dic.values())[index] + 1)[:-1])\n",
    "                # Find the frequency\n",
    "                frequency = (1 / 750) * 1000\n",
    "                # Add the last date range\n",
    "                new_date_range = new_date_range.append(\n",
    "                    pd.date_range(start=list(time_dic.keys())[-1], freq=\"{:.3f}ms\".format(frequency),\n",
    "                                  periods=list(time_dic.values())[-1]))\n",
    "                # Sort the new date range\n",
    "                new_date_range = sorted(new_date_range)\n",
    "                # Replace the original column\n",
    "                df[item] = new_date_range\n",
    "    # ------------------------------------------------------------------------------------------------------------------------------\n",
    "    # return the final dataframe\n",
    "    return df\n",
    "\n",
    "\n",
    "def shift_df(datafile_dir: str, filename: str, state: str, luminosity: str, distance: str, save_excel: bool = False) -> pd.DataFrame:\n",
    "    # Import the required libraries\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    # Read the mp csv\n",
    "    df = pd.read_csv(r\"{}/{}_{}_{}_{}.csv\".format(datafile_dir, filename, state, luminosity, distance))\n",
    "    # Change the data type of time\n",
    "    df[\"Time\"] = pd.to_datetime(df[\"Time\"], format=\"%d-%m-%Y %H:%M:%S.%f\")\n",
    "    # Change the data type of system local time\n",
    "    df[\"SystemLocalTime\"] = pd.to_datetime(df[\"SystemLocalTime\"], format=\"%d-%m-%Y %H:%M:%S.%f\")\n",
    "    # Replace the hivine by np.nan\n",
    "    df = df.replace(\"-\", np.nan)\n",
    "    # Change the types of the data\n",
    "    df[['NOM_PRESS_BLD_NONINV_SYS', 'NOM_PRESS_BLD_NONINV_DIA',\n",
    "        'NOM_PRESS_BLD_NONINV_MEAN', 'NOM_PRESS_BLD_NONINV_PULS_RATE',\n",
    "        'NOM_PULS_OXIM_SAT_O2', 'NOM_PLETH_PULS_RATE']] = df[['NOM_PRESS_BLD_NONINV_SYS', 'NOM_PRESS_BLD_NONINV_DIA',\n",
    "                                                              'NOM_PRESS_BLD_NONINV_MEAN',\n",
    "                                                              'NOM_PRESS_BLD_NONINV_PULS_RATE',\n",
    "                                                              'NOM_PULS_OXIM_SAT_O2', 'NOM_PLETH_PULS_RATE']].astype(\n",
    "        np.float64())\n",
    "    df[['NOM_PLETH_PULS_RATE']] = df[['NOM_PLETH_PULS_RATE']].astype(np.float64())\n",
    "\n",
    "    # ---------------------------------------- shift_df part --------------------------------\n",
    "    # To adjust the displaced tables in MP data csv file\n",
    "    # Extract the shifted rows\n",
    "    shift_df = df[df[\"NOM_PLETH_PULS_RATE\"].isna() & df[\"NOM_PULS_OXIM_PERF_REL\"].isna()]\n",
    "    # Extract the values of the req_df\n",
    "    mat = np.concatenate([shift_df.values[:, 0:4], shift_df.values[:, 12:14], shift_df.values[:, 4:12]], axis=1)\n",
    "    # Restore the shifted rows\n",
    "    restored_shift_df = pd.DataFrame(mat, columns=shift_df.columns.tolist(), index=shift_df.index)\n",
    "    # Check the dimensions after the restoration\n",
    "    assert np.shape(shift_df) == np.shape(restored_shift_df)\n",
    "    # Restored the mp dataframe\n",
    "    df.iloc[shift_df.index] = restored_shift_df\n",
    "    # Save the dataframe as an excel file\n",
    "    if save_excel == True:\n",
    "        df.to_excel(excel_writer=r\"{}/{}_shifted.xlsx\".format(datafile_dir, filename), header=True, index=False)\n",
    "        print(\"The excel file has been formed in the directory {}. \".format(datafile_dir))\n",
    "    # Return the dataframe\n",
    "    return df\n",
    "\n",
    "#----read csv data of mean_RGB and rPPG----#\n",
    "def read_csv_data_RGB_rPPG(datafile_dir: str, device: str, filename: str, state: str, luminosity: str, distance: str) -> pd.DataFrame:\n",
    "    # Read the csv\n",
    "    if filename == '_mediapipe_meanRGB':\n",
    "        df = pd.read_csv(\"{}/{}{}_{}_{}_{}.csv\".format(datafile_dir, device, filename, state, luminosity, distance), index_col=False)\n",
    "        df = df[[\"mean_R\", \"mean_G\", \"mean_B\"]].values\n",
    "        return df\n",
    "        \n",
    "    elif filename == 'rPPG':\n",
    "        df = pd.read_csv(\"{}/{}_{}_{}_{}_{}.csv\".format(datafile_dir, filename, device, state, luminosity, distance), index_col=False)\n",
    "        df = df[\"rPPG\"].values\n",
    "        return df\n",
    "    \n",
    "\n",
    "# **********************************************************************************************************************\n",
    "# Define the names of the data files\n",
    "resp_file = \"NOM_RESPWaveExport\"\n",
    "pleth_file = \"NOM_PLETHWaveExport\"\n",
    "elec_file = \"NOM_ECG_ELEC_POTL_IIWaveExport\"\n",
    "mp_file = \"MPDataExport\"\n",
    "meanRGB_file = \"_mediapipe_meanRGB\"\n",
    "rPPG_file = \"rPPG\"\n",
    "\n",
    "\n",
    "data_dir = r\"/Users/kinho123/Downloads\"\n",
    "\n",
    "# ----------------------------------------------------------------------------------\n",
    "# date_ls = [\"22-11-2022\", \"25-11-2022\", \"06-12-2022\"]\n",
    "v1_v2_ls = [\"v3\", \"v3\"]\n",
    "v2_subject_ls = [i for i in range(1,16+1)]\n",
    "recording_ls = [\"recording{}\".format(i) for i in range(2, 1 + 2)]\n",
    "\n",
    "trials = [\"13 mins trial\"]\n",
    "states = [\"RestL0\", \"Breath\", \"RestS\", \"Pedal\",\"RestL1\"]\n",
    "    \n",
    "luminosities = [\"300\"]\n",
    "distances = [\"0.5\"]\n",
    "\n",
    "# Define the date\n",
    "# date = date_ls[2]\n",
    "v1_v2 = v1_v2_ls[1]\n",
    "\n",
    "# ------------------------------------------ Subject details -----------------------------------------\n",
    "# Read the subject data\n",
    "subject_details_df = pd.read_excel(r\"/Users/kinho123/Downloads/v3/{}.xlsx\".format(\"Subject details\"))\n",
    "#subject_details_df = pd.read_csv(r\"C:\\Users\\Ellgan\\Desktop\\dataFromDS\\v2\\{}.csv\".format(\"Subject details\"))\n",
    "# Drop column \"時間戳記\"\n",
    "subject_details_df.drop(columns=[\"時間戳記\"], inplace=True)\n",
    "\n",
    "# -------------------------------------------- Questionnaire -----------------------------------------\n",
    "# Read the subject data\n",
    "questionnaire_df = pd.read_excel(\n",
    "r\"/Users/kinho123/Downloads/v3/{}.xlsx\".format(\"Questionnaire for BP measurement response\"))\n",
    "# Drop column \"時間戳記\"\n",
    "questionnaire_df.drop(columns=[\"Timestamp\"], inplace=True)\n",
    "\n",
    "\n",
    "# ------------------------------------------ Initialization ------------------------------------------\n",
    "# Initialize the dataframe\n",
    "all_df = pd.DataFrame()\n",
    "\n",
    "# ----------------------------------------------------------------------------------------------------\n",
    "for luminosity in luminosities:\n",
    "    for distance in distances:\n",
    "        for num in v2_subject_ls:\n",
    "            for state in states:    \n",
    "                for recording in recording_ls:\n",
    "                    for trial in trials:\n",
    "                        # Define the subject\n",
    "                        subject = \"id_{}\".format(num)\n",
    "                        path = \"{}/{}/{}/{}/{}\".format(data_dir, v1_v2, subject, recording, trial)\n",
    "                        if os.path.exists(path):\n",
    "                            # --------------------------------------------- CSV reading ------------------------------------------\n",
    "                            # Read the resp csv\n",
    "                            resp_df = read_csv_data(datafile_dir=path, filename=resp_file, state = state, luminosity = luminosity, distance = distance, col_name=\"RESP\")\n",
    "                            # Read the pleth csv\n",
    "                            pleth_df = read_csv_data(datafile_dir=path, filename=pleth_file, state = state, luminosity = luminosity, distance = distance, col_name=\"PLETH\")\n",
    "                            # Read the elec csv\n",
    "                            elec_df = read_csv_data(datafile_dir=path, filename=elec_file, state = state, luminosity = luminosity, distance = distance, col_name=\"ELEC\") \n",
    "                            # --------------------------------------------- MP_CSV reading ------------------------------------------\n",
    "                            # Shift the MP dataframe\n",
    "                            mp_df = shift_df(datafile_dir=\"{}/{}/{}/{}/{}\".format(datafile_dir, v1_v2, subject, recording, trial),\n",
    "                                             filename=mp_file, state = state, luminosity = luminosity, distance = distance, save_excel=False)\n",
    "                            # Extract the relevant\n",
    "                            mp_extract_df = mp_df[['Time', 'NOM_PRESS_BLD_NONINV_SYS', 'NOM_PRESS_BLD_NONINV_DIA', 'NOM_PRESS_BLD_NONINV_PULS_RATE',\n",
    "                                                   'NOM_ECG_CARD_BEAT_RATE', 'NOM_RESP_RATE', 'NOM_PULS_OXIM_SAT_O2', 'NOM_PLETH_PULS_RATE']]\n",
    "                            # Dropna\n",
    "                            mp_extract_df = mp_extract_df.dropna()\n",
    "\n",
    "                            # &&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&& Mark details in a pkl &&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&\n",
    "                            # initialize a dictionary for saving\n",
    "                            all_dic = {}\n",
    "                            # Define the dataset name\n",
    "                            all_dic[\"dataset_name\"] = v1_v2\n",
    "\n",
    "                            # Find the subject ID\n",
    "                            \n",
    "                            all_dic[\"subject_id\"] = \"{}\".format(num)\n",
    "                            # Recording\n",
    "                            all_dic[\"recording_number\"] = \"{}\".format(recording)\n",
    "                            # state\n",
    "                            all_dic[\"state\"] = \"{}\".format(state)\n",
    "                            # luminosity\n",
    "                            all_dic[\"luminosity (lx)\"] = \"{}\".format(luminosity)\n",
    "                            # distance\n",
    "                            all_dic[\"distance (m)\"] = \"{}\".format(distance)\n",
    "                            # Find datetime\n",
    "                            # timestamp_ecg\n",
    "                            all_dic[\"timestamp_ecg\"] = elec_df['SystemLocalTime'][1:].tolist()\n",
    "                            #all_dic[\"\"] = pd.to_datetime(date, format = \"%d-%m-%Y\")\n",
    "                            \n",
    "                            # timestamp_iphone/ipad\n",
    "                            dt = datetime.strptime(str(mp_df['SystemLocalTime'][0]), \"%Y-%m-%d %H:%M:%S.%f\")\n",
    "                \n",
    "                            ts = round(dt.timestamp())\n",
    "                            list1 = [str(dt.fromtimestamp(i)) for i in np.arange(ts,ts + 780,1/30)]\n",
    "        \n",
    "                            all_dic[\"timestamp_iphone/ipad\"] = list1\n",
    "            \n",
    "                            # mean_rgb_iphone\n",
    "                            all_dic[\"mean_rgb_iphone\"] = read_csv_data_RGB_rPPG(datafile_dir = path, device = \"Iphone\", filename = \"_mediapipe_meanRGB\", state = state, luminosity = luminosity, distance = distance)\n",
    "                            # rppg_iphone\n",
    "                            all_dic[\"rppg_iphone\"] = read_csv_data_RGB_rPPG(datafile_dir = path, device = \"Iphone\", filename = \"rPPG\", state = state, luminosity = luminosity, distance = distance)\n",
    "                            # rppg_iphone\n",
    "                            all_dic[\"mean_rgb_ipad\"] = read_csv_data_RGB_rPPG(datafile_dir = path, device = \"Ipad\", filename = \"_mediapipe_meanRGB\", state = state, luminosity = luminosity, distance = distance)\n",
    "                            # mean_rgb_iphone\n",
    "                            all_dic[\"rppg_ipad\"] = read_csv_data_RGB_rPPG(datafile_dir = path, device = \"Ipad\", filename = \"rPPG\", state = state, luminosity = luminosity, distance = distance)\n",
    "                            # ECG data\n",
    "                            all_dic[\"ECG_data(mV)\"] = elec_df[\"ELEC\"].tolist() \n",
    "                            # timestamp_ppg\n",
    "                            all_dic[\"timestamp_ppg\"] = pleth_df['SystemLocalTime'][1:].tolist()\n",
    "                            # PPG data\n",
    "                            all_dic[\"PPG_data\"] = pleth_df[\"PLETH\"].tolist()\n",
    "                            # RESP data\n",
    "                            #all_dic[\"RESP_data(bpm)\"] = resp_df[\"RESP\"].tolist()\n",
    "                            # ECG_fps\n",
    "                            #all_dic[\"ECG_fps(Hz)\"] = 750\n",
    "                            # PPG_fps\n",
    "                            #all_dic[\"PPG_fps(Hz)\"] = 125\n",
    "                            # RESP_fps\n",
    "                            #all_dic[\"RESP_fps(Hz)\"] = 125\n",
    "                            # timestamp_vital_sign\n",
    "                            all_dic[\"timestamp_vital_sign\"] = mp_df['SystemLocalTime'].tolist()\n",
    "                            # Pulse rate (ecg)\n",
    "                            all_dic[\"hr_ecg(bpm)\"] = mp_extract_df['NOM_ECG_CARD_BEAT_RATE'].tolist()\n",
    "                            # Pulse rate (ppg)\n",
    "                            all_dic[\"hr_ppg(bpm)\"] = mp_extract_df['NOM_PLETH_PULS_RATE'].tolist()\n",
    "                            # SpO2\n",
    "                            all_dic[\"SpO2(%)\"] = mp_extract_df['NOM_PULS_OXIM_SAT_O2'].tolist()\n",
    "                            # SBP\n",
    "                            all_dic[\"SBP(mmHg)\"] = mp_extract_df['NOM_PRESS_BLD_NONINV_SYS'].dropna().unique().tolist()\n",
    "                            # DBP\n",
    "                            all_dic[\"DBP(mmHg)\"] = mp_extract_df['NOM_PRESS_BLD_NONINV_DIA'].dropna().unique().tolist()\n",
    "                            #respiratory_rate\n",
    "                            all_dic[\"respiratory_rate(pm)\"] = mp_extract_df[\"NOM_RESP_RATE\"].tolist()\n",
    "                            # SpO2_fps\n",
    "                            #all_dic[\"SpO2_fps(Hz)\"] = 1\n",
    "                            # Pulse_rate_fps(Hz)\n",
    "                            #all_dic[\"hr_fps(Hz)\"] = 1\n",
    "                            # *********************************** Questionnaire **********************************************\n",
    "                            # Extract the details of a specific subject\n",
    "                            specific_questionnaire_df = questionnaire_df[questionnaire_df[\"Subject ID\"] == num].copy()\n",
    "                            questionnaire_df[\"Subject ID\"] == num\n",
    "                            # Drop the subject ID\n",
    "                            specific_questionnaire_df.drop(columns=\"Subject ID\", inplace=True)\n",
    "                            # Ensure that the subject id is unique\n",
    "                            assert (len(list(specific_questionnaire_df.T.to_dict().values())))\n",
    "                            # Update the dictionary\n",
    "                            all_dic.update(list(specific_questionnaire_df.T.to_dict().values())[0])\n",
    "                            # *********************************** Subject details ********************************************\n",
    "                            specific_subject_df = subject_details_df[subject_details_df[\"Subject ID\"] == num].copy()\n",
    "                            subject_details_df[\"Subject ID\"] == num\n",
    "                            specific_subject_df.drop(columns=\"Subject ID\", inplace=True)\n",
    "                            ## Ensure that the subject id is unique\n",
    "                            assert (len(list(specific_subject_df.T.to_dict().values())))\n",
    "                            # Update the dictionary\n",
    "                            all_dic.update(list(specific_subject_df.T.to_dict().values())[0])\n",
    "                            # ************************************************************************************************\n",
    "                            # Append the dict to all_df\n",
    "                            all_df = all_df.append(all_dic, ignore_index=True)\n",
    "                            # Print the database and the subject for confirmation\n",
    "                            print(\"finished: {}_{}_{}_{}_{}_{}_{}\".format(v1_v2, subject, recording, trial, state, luminosity, distance ))\n",
    "                        else:\n",
    "                            print(\"The path {}/{}/{}/{} does not exist.\".format(v1_v2, subject, recording, trial))\n",
    "                            pass\n",
    "\n",
    "# +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
    "# Define the path for export\n",
    "export_dir = data_dir\n",
    "export_filename = \"BPdataset_{}\".format(\"v3.1\")\n",
    "# Export the dataframe to a pickle file\n",
    "all_df.to_pickle(path=\"{}/{}.pkl\".format(export_dir, export_filename))\n",
    "\n",
    "# Print the dataframe\n",
    "#print(all_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Body Fat (%) (L. Arm)</th>\n",
       "      <th>Body Fat (%) (L. Leg)</th>\n",
       "      <th>Body Fat (%) (R. Arm)</th>\n",
       "      <th>Body Fat (%) (R. Leg)</th>\n",
       "      <th>Body Fat (%) (Trunk)</th>\n",
       "      <th>Body Fat (%) (Whole)</th>\n",
       "      <th>Bone mass (kg)</th>\n",
       "      <th>DBP(mmHg)</th>\n",
       "      <th>...</th>\n",
       "      <th>respiratory_rate(pm)</th>\n",
       "      <th>rppg_ipad</th>\n",
       "      <th>rppg_iphone</th>\n",
       "      <th>state</th>\n",
       "      <th>subject_id</th>\n",
       "      <th>timestamp_ecg</th>\n",
       "      <th>timestamp_iphone/ipad</th>\n",
       "      <th>timestamp_ppg</th>\n",
       "      <th>timestamp_vital_sign</th>\n",
       "      <th>visceral fat index VFI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25.0</td>\n",
       "      <td>22.8</td>\n",
       "      <td>15.7</td>\n",
       "      <td>23.6</td>\n",
       "      <td>16.0</td>\n",
       "      <td>24.3</td>\n",
       "      <td>19.6</td>\n",
       "      <td>20.7</td>\n",
       "      <td>2.8</td>\n",
       "      <td>[56.0, 59.0, 58.0]</td>\n",
       "      <td>...</td>\n",
       "      <td>[15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 1...</td>\n",
       "      <td>[5.067705503537212, 3.854651217955393, 4.94031...</td>\n",
       "      <td>[17.727617552200684, 19.20040201212336, 18.584...</td>\n",
       "      <td>RestL0</td>\n",
       "      <td>1</td>\n",
       "      <td>[2023-01-13 12:00:06.508000, 2023-01-13 12:00:...</td>\n",
       "      <td>[2023-01-13 12:00:05, 2023-01-13 12:00:05.0333...</td>\n",
       "      <td>[2023-01-13 12:00:06.508000, 2023-01-13 12:00:...</td>\n",
       "      <td>[2023-01-13 12:00:05.463000, 2023-01-13 12:00:...</td>\n",
       "      <td>7.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25.0</td>\n",
       "      <td>22.8</td>\n",
       "      <td>15.7</td>\n",
       "      <td>23.6</td>\n",
       "      <td>16.0</td>\n",
       "      <td>24.3</td>\n",
       "      <td>19.6</td>\n",
       "      <td>20.7</td>\n",
       "      <td>2.8</td>\n",
       "      <td>[58.0, 49.0, 50.0]</td>\n",
       "      <td>...</td>\n",
       "      <td>[18, 18, 18, 18, 18, 18, 17, 17, 17, 17, 17, 1...</td>\n",
       "      <td>[4.384840468229186, 3.8104886412210415, 4.4103...</td>\n",
       "      <td>[15.313579472544262, 16.05224983185545, 15.144...</td>\n",
       "      <td>Breath</td>\n",
       "      <td>1</td>\n",
       "      <td>[2023-01-13 12:03:13.981000, 2023-01-13 12:03:...</td>\n",
       "      <td>[2023-01-13 12:03:14, 2023-01-13 12:03:14.0333...</td>\n",
       "      <td>[2023-01-13 12:03:13.981000, 2023-01-13 12:03:...</td>\n",
       "      <td>[2023-01-13 12:03:13.963000, 2023-01-13 12:03:...</td>\n",
       "      <td>7.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25.0</td>\n",
       "      <td>22.8</td>\n",
       "      <td>15.7</td>\n",
       "      <td>23.6</td>\n",
       "      <td>16.0</td>\n",
       "      <td>24.3</td>\n",
       "      <td>19.6</td>\n",
       "      <td>20.7</td>\n",
       "      <td>2.8</td>\n",
       "      <td>[50.0, 54.0]</td>\n",
       "      <td>...</td>\n",
       "      <td>[9, 9, 9, 9, 9, 9, 10, 10, 10, 10, 10, 10, 9, ...</td>\n",
       "      <td>[1.52091603587823, 1.1068966276329777, 2.52180...</td>\n",
       "      <td>[13.457012810057025, 14.065157609311314, 13.90...</td>\n",
       "      <td>RestS</td>\n",
       "      <td>1</td>\n",
       "      <td>[2023-01-13 12:06:21.456000, 2023-01-13 12:06:...</td>\n",
       "      <td>[2023-01-13 12:06:20, 2023-01-13 12:06:20.0333...</td>\n",
       "      <td>[2023-01-13 12:06:21.456000, 2023-01-13 12:06:...</td>\n",
       "      <td>[2023-01-13 12:06:20.417000, 2023-01-13 12:06:...</td>\n",
       "      <td>7.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25.0</td>\n",
       "      <td>22.8</td>\n",
       "      <td>15.7</td>\n",
       "      <td>23.6</td>\n",
       "      <td>16.0</td>\n",
       "      <td>24.3</td>\n",
       "      <td>19.6</td>\n",
       "      <td>20.7</td>\n",
       "      <td>2.8</td>\n",
       "      <td>[54.0, 67.0, 62.0]</td>\n",
       "      <td>...</td>\n",
       "      <td>[15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 1...</td>\n",
       "      <td>[1.7388879927892162, 0.795144798865266, 0.3760...</td>\n",
       "      <td>[18.350223291411517, 14.182410742355133, 20.92...</td>\n",
       "      <td>Pedal</td>\n",
       "      <td>1</td>\n",
       "      <td>[2023-01-13 12:07:28.049000, 2023-01-13 12:07:...</td>\n",
       "      <td>[2023-01-13 12:07:28, 2023-01-13 12:07:28.0333...</td>\n",
       "      <td>[2023-01-13 12:07:28.049000, 2023-01-13 12:07:...</td>\n",
       "      <td>[2023-01-13 12:07:28.033000, 2023-01-13 12:07:...</td>\n",
       "      <td>7.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25.0</td>\n",
       "      <td>22.8</td>\n",
       "      <td>15.7</td>\n",
       "      <td>23.6</td>\n",
       "      <td>16.0</td>\n",
       "      <td>24.3</td>\n",
       "      <td>19.6</td>\n",
       "      <td>20.7</td>\n",
       "      <td>2.8</td>\n",
       "      <td>[62.0, 55.0, 61.0, 76.0]</td>\n",
       "      <td>...</td>\n",
       "      <td>[27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 2...</td>\n",
       "      <td>[4.1511291304482265, 5.318825573105869, 6.6737...</td>\n",
       "      <td>[19.99691658275026, 17.705597584356696, 16.201...</td>\n",
       "      <td>RestL1</td>\n",
       "      <td>1</td>\n",
       "      <td>[2023-01-13 12:10:05.804000, 2023-01-13 12:10:...</td>\n",
       "      <td>[2023-01-13 12:10:05, 2023-01-13 12:10:05.0333...</td>\n",
       "      <td>[2023-01-13 12:10:05.804000, 2023-01-13 12:10:...</td>\n",
       "      <td>[2023-01-13 12:10:04.774000, 2023-01-13 12:10:...</td>\n",
       "      <td>7.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>22.0</td>\n",
       "      <td>22.4</td>\n",
       "      <td>30.8</td>\n",
       "      <td>33.7</td>\n",
       "      <td>30.0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>31.1</td>\n",
       "      <td>31.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>[62.0, 69.0]</td>\n",
       "      <td>...</td>\n",
       "      <td>[14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 15, 1...</td>\n",
       "      <td>[0.9279747408133971, 1.3526318649194309, 1.126...</td>\n",
       "      <td>[-8.54459179067669, -8.552539275628476, -8.560...</td>\n",
       "      <td>RestL0</td>\n",
       "      <td>16</td>\n",
       "      <td>[2023-02-07 10:48:34.320000, 2023-02-07 10:48:...</td>\n",
       "      <td>[2023-02-07 10:48:33, 2023-02-07 10:48:33.0333...</td>\n",
       "      <td>[2023-02-07 10:48:34.320000, 2023-02-07 10:48:...</td>\n",
       "      <td>[2023-02-07 10:48:33.266000, 2023-02-07 10:48:...</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>22.0</td>\n",
       "      <td>22.4</td>\n",
       "      <td>30.8</td>\n",
       "      <td>33.7</td>\n",
       "      <td>30.0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>31.1</td>\n",
       "      <td>31.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>[69.0, 61.0, 65.0, 68.0]</td>\n",
       "      <td>...</td>\n",
       "      <td>[15, 15, 15, 15, 15, 13, 13, 13, 15, 15, 14, 1...</td>\n",
       "      <td>[-1.7146905422382588, -1.6708137708142203, -2....</td>\n",
       "      <td>[-11.01155948034301, -10.95463225041226, -10.7...</td>\n",
       "      <td>Breath</td>\n",
       "      <td>16</td>\n",
       "      <td>[2023-02-07 10:51:41.784000, 2023-02-07 10:51:...</td>\n",
       "      <td>[2023-02-07 10:51:42, 2023-02-07 10:51:42.0333...</td>\n",
       "      <td>[2023-02-07 10:51:41.784000, 2023-02-07 10:51:...</td>\n",
       "      <td>[2023-02-07 10:51:41.767000, 2023-02-07 10:51:...</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>22.0</td>\n",
       "      <td>22.4</td>\n",
       "      <td>30.8</td>\n",
       "      <td>33.7</td>\n",
       "      <td>30.0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>31.1</td>\n",
       "      <td>31.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>[68.0, 67.0]</td>\n",
       "      <td>...</td>\n",
       "      <td>[10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 9, 9,...</td>\n",
       "      <td>[4.170919520292557, 4.754972241028838, 5.30667...</td>\n",
       "      <td>[-6.02122821696787, -5.555112244466102, -5.908...</td>\n",
       "      <td>RestS</td>\n",
       "      <td>16</td>\n",
       "      <td>[2023-02-07 10:54:49.253000, 2023-02-07 10:54:...</td>\n",
       "      <td>[2023-02-07 10:54:48, 2023-02-07 10:54:48.0333...</td>\n",
       "      <td>[2023-02-07 10:54:49.253000, 2023-02-07 10:54:...</td>\n",
       "      <td>[2023-02-07 10:54:48.222000, 2023-02-07 10:54:...</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>22.0</td>\n",
       "      <td>22.4</td>\n",
       "      <td>30.8</td>\n",
       "      <td>33.7</td>\n",
       "      <td>30.0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>31.1</td>\n",
       "      <td>31.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>[67.0, 51.0]</td>\n",
       "      <td>...</td>\n",
       "      <td>[21, 21, 22, 22, 22, 22, 23, 23, 23, 23, 23, 2...</td>\n",
       "      <td>[8.47757354721216, 8.430886580390705, 8.384199...</td>\n",
       "      <td>[0.9556050573968378, 1.015821460461268, 1.0760...</td>\n",
       "      <td>Pedal</td>\n",
       "      <td>16</td>\n",
       "      <td>[2023-02-07 10:55:55.853000, 2023-02-07 10:55:...</td>\n",
       "      <td>[2023-02-07 10:55:56, 2023-02-07 10:55:56.0333...</td>\n",
       "      <td>[2023-02-07 10:55:55.853000, 2023-02-07 10:55:...</td>\n",
       "      <td>[2023-02-07 10:55:55.836000, 2023-02-07 10:55:...</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>22.0</td>\n",
       "      <td>22.4</td>\n",
       "      <td>30.8</td>\n",
       "      <td>33.7</td>\n",
       "      <td>30.0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>31.1</td>\n",
       "      <td>31.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>[51.0, 66.0, 52.0, 60.0]</td>\n",
       "      <td>...</td>\n",
       "      <td>[48, 41, 41, 41, 41, 41, 40, 30, 30, 30, 28, 2...</td>\n",
       "      <td>[-1.8164464197092232, -1.7919008220125079, -1....</td>\n",
       "      <td>[-9.851341240974987, -10.13374413431734, -10.2...</td>\n",
       "      <td>RestL1</td>\n",
       "      <td>16</td>\n",
       "      <td>[2023-02-07 10:58:33.619000, 2023-02-07 10:58:...</td>\n",
       "      <td>[2023-02-07 10:58:33, 2023-02-07 10:58:33.0333...</td>\n",
       "      <td>[2023-02-07 10:58:33.619000, 2023-02-07 10:58:...</td>\n",
       "      <td>[2023-02-07 10:58:32.581000, 2023-02-07 10:58:...</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80 rows × 53 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Age   BMI  Body Fat (%) (L. Arm)  Body Fat (%) (L. Leg)  Body Fat (%) (R. Arm)  Body Fat (%) (R. Leg)  Body Fat (%) (Trunk)  Body Fat (%) (Whole)  Bone mass (kg)                 DBP(mmHg)  ...                               respiratory_rate(pm)                                          rppg_ipad                                        rppg_iphone   state subject_id                                      timestamp_ecg                              timestamp_iphone/ipad                                      timestamp_ppg                               timestamp_vital_sign  visceral fat index VFI\n",
       "0   25.0  22.8                   15.7                   23.6                   16.0                   24.3                  19.6                  20.7             2.8        [56.0, 59.0, 58.0]  ...  [15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 1...  [5.067705503537212, 3.854651217955393, 4.94031...  [17.727617552200684, 19.20040201212336, 18.584...  RestL0          1  [2023-01-13 12:00:06.508000, 2023-01-13 12:00:...  [2023-01-13 12:00:05, 2023-01-13 12:00:05.0333...  [2023-01-13 12:00:06.508000, 2023-01-13 12:00:...  [2023-01-13 12:00:05.463000, 2023-01-13 12:00:...                     7.5\n",
       "1   25.0  22.8                   15.7                   23.6                   16.0                   24.3                  19.6                  20.7             2.8        [58.0, 49.0, 50.0]  ...  [18, 18, 18, 18, 18, 18, 17, 17, 17, 17, 17, 1...  [4.384840468229186, 3.8104886412210415, 4.4103...  [15.313579472544262, 16.05224983185545, 15.144...  Breath          1  [2023-01-13 12:03:13.981000, 2023-01-13 12:03:...  [2023-01-13 12:03:14, 2023-01-13 12:03:14.0333...  [2023-01-13 12:03:13.981000, 2023-01-13 12:03:...  [2023-01-13 12:03:13.963000, 2023-01-13 12:03:...                     7.5\n",
       "2   25.0  22.8                   15.7                   23.6                   16.0                   24.3                  19.6                  20.7             2.8              [50.0, 54.0]  ...  [9, 9, 9, 9, 9, 9, 10, 10, 10, 10, 10, 10, 9, ...  [1.52091603587823, 1.1068966276329777, 2.52180...  [13.457012810057025, 14.065157609311314, 13.90...   RestS          1  [2023-01-13 12:06:21.456000, 2023-01-13 12:06:...  [2023-01-13 12:06:20, 2023-01-13 12:06:20.0333...  [2023-01-13 12:06:21.456000, 2023-01-13 12:06:...  [2023-01-13 12:06:20.417000, 2023-01-13 12:06:...                     7.5\n",
       "3   25.0  22.8                   15.7                   23.6                   16.0                   24.3                  19.6                  20.7             2.8        [54.0, 67.0, 62.0]  ...  [15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 1...  [1.7388879927892162, 0.795144798865266, 0.3760...  [18.350223291411517, 14.182410742355133, 20.92...   Pedal          1  [2023-01-13 12:07:28.049000, 2023-01-13 12:07:...  [2023-01-13 12:07:28, 2023-01-13 12:07:28.0333...  [2023-01-13 12:07:28.049000, 2023-01-13 12:07:...  [2023-01-13 12:07:28.033000, 2023-01-13 12:07:...                     7.5\n",
       "4   25.0  22.8                   15.7                   23.6                   16.0                   24.3                  19.6                  20.7             2.8  [62.0, 55.0, 61.0, 76.0]  ...  [27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 2...  [4.1511291304482265, 5.318825573105869, 6.6737...  [19.99691658275026, 17.705597584356696, 16.201...  RestL1          1  [2023-01-13 12:10:05.804000, 2023-01-13 12:10:...  [2023-01-13 12:10:05, 2023-01-13 12:10:05.0333...  [2023-01-13 12:10:05.804000, 2023-01-13 12:10:...  [2023-01-13 12:10:04.774000, 2023-01-13 12:10:...                     7.5\n",
       "..   ...   ...                    ...                    ...                    ...                    ...                   ...                   ...             ...                       ...  ...                                                ...                                                ...                                                ...     ...        ...                                                ...                                                ...                                                ...                                                ...                     ...\n",
       "75  22.0  22.4                   30.8                   33.7                   30.0                   33.6                  31.1                  31.9             3.1              [62.0, 69.0]  ...  [14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 15, 1...  [0.9279747408133971, 1.3526318649194309, 1.126...  [-8.54459179067669, -8.552539275628476, -8.560...  RestL0         16  [2023-02-07 10:48:34.320000, 2023-02-07 10:48:...  [2023-02-07 10:48:33, 2023-02-07 10:48:33.0333...  [2023-02-07 10:48:34.320000, 2023-02-07 10:48:...  [2023-02-07 10:48:33.266000, 2023-02-07 10:48:...                     4.5\n",
       "76  22.0  22.4                   30.8                   33.7                   30.0                   33.6                  31.1                  31.9             3.1  [69.0, 61.0, 65.0, 68.0]  ...  [15, 15, 15, 15, 15, 13, 13, 13, 15, 15, 14, 1...  [-1.7146905422382588, -1.6708137708142203, -2....  [-11.01155948034301, -10.95463225041226, -10.7...  Breath         16  [2023-02-07 10:51:41.784000, 2023-02-07 10:51:...  [2023-02-07 10:51:42, 2023-02-07 10:51:42.0333...  [2023-02-07 10:51:41.784000, 2023-02-07 10:51:...  [2023-02-07 10:51:41.767000, 2023-02-07 10:51:...                     4.5\n",
       "77  22.0  22.4                   30.8                   33.7                   30.0                   33.6                  31.1                  31.9             3.1              [68.0, 67.0]  ...  [10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 9, 9,...  [4.170919520292557, 4.754972241028838, 5.30667...  [-6.02122821696787, -5.555112244466102, -5.908...   RestS         16  [2023-02-07 10:54:49.253000, 2023-02-07 10:54:...  [2023-02-07 10:54:48, 2023-02-07 10:54:48.0333...  [2023-02-07 10:54:49.253000, 2023-02-07 10:54:...  [2023-02-07 10:54:48.222000, 2023-02-07 10:54:...                     4.5\n",
       "78  22.0  22.4                   30.8                   33.7                   30.0                   33.6                  31.1                  31.9             3.1              [67.0, 51.0]  ...  [21, 21, 22, 22, 22, 22, 23, 23, 23, 23, 23, 2...  [8.47757354721216, 8.430886580390705, 8.384199...  [0.9556050573968378, 1.015821460461268, 1.0760...   Pedal         16  [2023-02-07 10:55:55.853000, 2023-02-07 10:55:...  [2023-02-07 10:55:56, 2023-02-07 10:55:56.0333...  [2023-02-07 10:55:55.853000, 2023-02-07 10:55:...  [2023-02-07 10:55:55.836000, 2023-02-07 10:55:...                     4.5\n",
       "79  22.0  22.4                   30.8                   33.7                   30.0                   33.6                  31.1                  31.9             3.1  [51.0, 66.0, 52.0, 60.0]  ...  [48, 41, 41, 41, 41, 41, 40, 30, 30, 30, 28, 2...  [-1.8164464197092232, -1.7919008220125079, -1....  [-9.851341240974987, -10.13374413431734, -10.2...  RestL1         16  [2023-02-07 10:58:33.619000, 2023-02-07 10:58:...  [2023-02-07 10:58:33, 2023-02-07 10:58:33.0333...  [2023-02-07 10:58:33.619000, 2023-02-07 10:58:...  [2023-02-07 10:58:32.581000, 2023-02-07 10:58:...                     4.5\n",
       "\n",
       "[80 rows x 53 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_pickle(\"{}.pkl\".format(\"/Users/kinho123/Downloads/BPdataset_v3.1\") )\n",
    "df\n",
    "#df.pop(\"Unnamed: 10\")\n",
    "#df.pop(\"Unnamed: 11\")\n",
    "#print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3/id_2/recording2/15 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3/id_2/recording2/15 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3/id_2/recording2/15 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3/id_2/recording2/15 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3/id_2/recording2/15 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3/id_2/recording2/15 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3/id_2/recording2/15 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3/id_2/recording2/15 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3/id_2/recording2/15 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3/id_2/recording2/15 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3/id_2/recording2/15 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3/id_2/recording2/15 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3/id_2/recording2/15 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3/id_2/recording2/15 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3/id_2/recording2/15 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3/id_2/recording2/15 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3/id_2/recording2/15 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3/id_2/recording2/15 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3/id_2/recording2/15 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3/id_2/recording2/15 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3/id_2/recording2/15 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3/id_2/recording2/15 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3/id_2/recording2/15 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3/id_2/recording2/15 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3/id_2/recording2/15 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3/id_2/recording2/15 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3/id_2/recording2/15 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3/id_2/recording2/15 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3/id_2/recording2/15 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3/id_2/recording2/15 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3/id_2/recording2/15 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3/id_2/recording2/15 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3/id_2/recording2/15 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3/id_2/recording2/15 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3/id_2/recording2/15 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3/id_2/recording2/15 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3/id_2/recording2/15 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3/id_2/recording2/15 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3/id_2/recording2/15 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3/id_2/recording2/15 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3/id_2/recording2/15 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3/id_2/recording2/15 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3/id_2/recording2/15 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3/id_2/recording2/15 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3/id_2/recording2/15 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3/id_2/recording2/15 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3/id_2/recording2/15 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3/id_2/recording2/15 mins trial. \n",
      "        19-01-2023 15:38:43.928  1487446016  19-01-2023 15:38:52.702  -0.11  Unnamed: 4\n",
      "101540  19-01-2023 16:23:37.816  1508995072  19-01-2023 16:23:48.058   0.83         NaN\n",
      "101541  19-01-2023 16:23:37.816  1508995072  19-01-2023 16:23:48.058   0.84         NaN\n",
      "101542  19-01-2023 16:23:37.816  1508995072  19-01-2023 16:23:48.058   0.84         NaN\n",
      "101543  19-01-2023 16:23:37.816  1508995072  19-01-2023 16:23:48.058   0.84         NaN\n",
      "101544  19-01-2023 16:23:37.816  1508995072  19-01-2023 16:23:48.058   0.84         NaN\n",
      "...                         ...         ...                      ...    ...         ...\n",
      "105022  19-01-2023 16:24:33.368  1509439488  19-01-2023 16:24:43.388   0.69         NaN\n",
      "105023  19-01-2023 16:24:33.368  1509439488  19-01-2023 16:24:43.388   0.71         NaN\n",
      "105024  19-01-2023 16:24:33.624  1509441536  19-01-2023 16:24:43.389   0.73         NaN\n",
      "105025  19-01-2023 16:24:33.624  1509441536  19-01-2023 16:24:43.389   0.75         NaN\n",
      "105026  19-01-2023 16:24:33.624  1509441536  19-01-2023 16:24:43.389   0.77         NaN\n",
      "\n",
      "[3487 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------------------------------------------------------------------------------\n",
    "# for splitting the csv files of vital in 15 mins trial#\n",
    "\n",
    "\n",
    "def sec_to_stp(sec, fps):\n",
    "    if sec == 0:\n",
    "        return None\n",
    "    else:\n",
    "        return ((sec*fps))\n",
    "\n",
    "\n",
    "def shift_df(datafile_dir: str,  save_excel: bool = False) -> pd.DataFrame:\n",
    "    # Import the required libraries\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    # Read the mp csv\n",
    "    filename = [\"MPDataExport\", \"NOM_ECG_ELEC_POTL_IIWaveExport\", \"NOM_PLETHWaveExport\", \"NOM_RESPWaveExport\"]\n",
    "    fps = [1/(1.024),750, 125,125/2]\n",
    "    states = \"Rest\"\n",
    "    scale = [1,(1.0234)*750,(1.0234)*125, (1.00234)*125/2 ]\n",
    "    lum_dist = [\"100_0.4\",\"100_0.5\", \"100_0.6\", \"200_0.4\",\"200_0.5\",\"200_0.6\", \"300_0.4\", \"300_0.5\",\"300_0.6\", \"500_0.4\", \"500_0.5\", \"500_0.6\"]\n",
    "    s = np.array([\n",
    "        ])-1.024\n",
    "    \n",
    "    f = np.array([])-1.024\n",
    "    \n",
    "    for j, name in enumerate(filename):\n",
    "        for i, ld in enumerate(lum_dist):\n",
    "            leng = -len(pd.read_csv(r\"{}/MPDataExport.csv\".format(datafile_dir)))\n",
    "            mp_df = pd.read_csv(r\"{}/{}.csv\".format(datafile_dir, name) )[int((leng+ sec_to_stp(s[i],fps[0]))*scale[j]):int((leng + sec_to_stp(f[i],fps[0]))*scale[j])]\n",
    "\n",
    "\n",
    "            mp_df.to_csv(r\"{}/{}_{}_{}.csv\".format(datafile_dir, name, states, ld), header = True, index = False)\n",
    "            print(\"The csv file has been formed in the directory {}. \".format(datafile_dir))\n",
    "                    # Return the dataframe\n",
    "    return mp_df\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Define the directory and the filename\n",
    "    num = [3]\n",
    "    for i in num:\n",
    "        datafile_dir = r\"/Users/kinho123/Downloads/v3/id_{}/recording2/15 mins trial\".format(i)\n",
    "\n",
    "    # Read the mp csv\n",
    "        mp_df = shift_df(datafile_dir = datafile_dir, save_excel = True)\n",
    "        print(mp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished: v3_id_1_recording2_15 mins trial_Rest_100_0.4\n",
      "finished: v3_id_1_recording2_15 mins trial_Rest_100_0.5\n",
      "finished: v3_id_1_recording2_15 mins trial_Rest_100_0.6\n",
      "finished: v3_id_1_recording2_15 mins trial_Rest_200_0.4\n",
      "finished: v3_id_1_recording2_15 mins trial_Rest_200_0.5\n",
      "finished: v3_id_1_recording2_15 mins trial_Rest_200_0.6\n",
      "finished: v3_id_1_recording2_15 mins trial_Rest_300_0.4\n",
      "finished: v3_id_1_recording2_15 mins trial_Rest_300_0.5\n",
      "finished: v3_id_1_recording2_15 mins trial_Rest_300_0.6\n",
      "finished: v3_id_1_recording2_15 mins trial_Rest_500_0.4\n",
      "finished: v3_id_1_recording2_15 mins trial_Rest_500_0.5\n",
      "finished: v3_id_1_recording2_15 mins trial_Rest_500_0.6\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------------------------------------------------------------------------------        \n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Thu Dec  8 17:23:50 2022\n",
    "\n",
    "@author: Ellgan\n",
    "\"\"\"\n",
    "\n",
    "# Import libraries\n",
    "# import cv2\n",
    "#import datetime as dt\n",
    "from datetime import datetime\n",
    "import os\n",
    "# from functools import partial\n",
    "# import matplotlib.pyplot as plt\n",
    "# import re\n",
    "\n",
    "# Expand the dataframe if necessary\n",
    "pd.set_option('display.expand_frame_repr', False)\n",
    "# Define the path for hkstp and home\n",
    "hkstp1home2 = 1\n",
    "\n",
    "# Define the directory of the data files (Change it if necessary)\n",
    "if hkstp1home2 == 1:\n",
    "    datafile_dir = r\"/Users/kinho123/Downloads\"\n",
    "elif hkstp1home2 == 2:\n",
    "    datafile_dir = \"/User/Ellgan/Download\"\n",
    "\n",
    "# --------------------------------------------------------------------- Function part -----------------------------------------------------------------------------\n",
    "def read_csv_data(datafile_dir: str, filename: str, state: str, luminosity: str, distance: str, col_name: str) -> pd.DataFrame:\n",
    "    # Read the csv\n",
    "    df = pd.read_csv(\"{}/{}_{}_{}_{}.csv\".format(datafile_dir, filename, state, luminosity, distance), index_col=False,\n",
    "                     names=[\"Time\", \"RelativeTime\", \"SystemLocalTime\", col_name])\n",
    "    # Change the data type of time\n",
    "    df[\"Time\"] = pd.to_datetime(df[\"Time\"], format=\"%d-%m-%Y %H:%M:%S.%f\")\n",
    "    # Change the data type of relative time\n",
    "    df[\"RelativeTime\"] = df[\"RelativeTime\"].astype(np.int64)\n",
    "    # Change the data type of system local time\n",
    "    df[\"SystemLocalTime\"] = pd.to_datetime(df[\"SystemLocalTime\"], format=\"%d-%m-%Y %H:%M:%S.%f\")\n",
    "    # ------------------------------------------------------------------------------------------------------------------------------\n",
    "    if col_name in [\"PLETH\", \"RESP\"]:\n",
    "        for item in [\"Time\", \"RelativeTime\", \"SystemLocalTime\"]:\n",
    "            time_dic = df[item].value_counts(dropna=False).to_dict()\n",
    "            # Sort the time dictionary by timestamp\n",
    "            time_dic = dict(sorted(time_dic.items(), key=lambda item: item[0]))\n",
    "            if item == \"RelativeTime\":\n",
    "                # initialize a list\n",
    "                rel_time_ls = np.array([])\n",
    "                for index in range(len(list(time_dic.keys())) - 1):\n",
    "                    ref_ls = np.linspace(start=list(time_dic.keys())[index], stop=list(time_dic.keys())[index + 1], \\\n",
    "                                         num=list(time_dic.values())[index] + 1)[:-1]\n",
    "                    rel_time_ls = np.concatenate([rel_time_ls, ref_ls])\n",
    "                # Find the difference of frames\n",
    "                difference = list(time_dic.keys())[2] - list(time_dic.keys())[1]\n",
    "                # Find the count\n",
    "                count = max(list(set(time_dic.values())))\n",
    "                # Add the last date range\n",
    "                ref_ls = np.array(\n",
    "                    [list(time_dic.keys())[-1] + i * difference / count for i in range(list(time_dic.values())[-1])])\n",
    "                rel_time_ls = np.concatenate([rel_time_ls, ref_ls])\n",
    "                # Sort the new date range\n",
    "                new_date_range = sorted(rel_time_ls)\n",
    "                # Replace the original column\n",
    "                df[item] = rel_time_ls\n",
    "            else:\n",
    "                # Initialize the new date range\n",
    "                new_date_range = pd.DatetimeIndex([], dtype='datetime64[ns]', freq=None)\n",
    "                # For loop to expand the date range\n",
    "                for index in range(len(list(time_dic.keys())) - 1):\n",
    "                    new_date_range = new_date_range.append(\n",
    "                        pd.date_range(start=list(time_dic.keys())[index], end=list(time_dic.keys())[index + 1], \\\n",
    "                                      periods=list(time_dic.values())[index] + 1)[:-1])\n",
    "                # Find the frequency\n",
    "                frequency = (1 / 125) * 1000\n",
    "                # Add the last date range\n",
    "                new_date_range = new_date_range.append(\n",
    "                    pd.date_range(start=list(time_dic.keys())[-1], freq=\"{:.3f}ms\".format(frequency),\n",
    "                                  periods=list(time_dic.values())[-1]))\n",
    "                # Sort the new date range\n",
    "                new_date_range = sorted(new_date_range)\n",
    "                # Replace the original column\n",
    "                df[item] = new_date_range\n",
    "\n",
    "    elif col_name == \"ELEC\":\n",
    "        for item in [\"Time\", \"RelativeTime\", \"SystemLocalTime\"]:\n",
    "            time_dic = df[item].value_counts(dropna=False).to_dict()\n",
    "            # Sort the time dictionary by timestamp\n",
    "            time_dic = dict(sorted(time_dic.items(), key=lambda item: item[0]))\n",
    "            if item == \"RelativeTime\":\n",
    "                # initialize a list\n",
    "                rel_time_ls = np.array([])\n",
    "                for index in range(len(list(time_dic.keys())) - 1):\n",
    "                    ref_ls = np.linspace(start=list(time_dic.keys())[index], stop=list(time_dic.keys())[index + 1], \\\n",
    "                                         num=list(time_dic.values())[index] + 1)[:-1]\n",
    "                    rel_time_ls = np.concatenate([rel_time_ls, ref_ls])\n",
    "                # Find the difference of frames\n",
    "                difference = list(time_dic.keys())[2] - list(time_dic.keys())[1]\n",
    "                # Find the count\n",
    "                count = max(list(set(time_dic.values())))\n",
    "                # Add the last date range\n",
    "                ref_ls = np.array(\n",
    "                    [list(time_dic.keys())[-1] + i * difference / count for i in range(list(time_dic.values())[-1])])\n",
    "                rel_time_ls = np.concatenate([rel_time_ls, ref_ls])\n",
    "                # Sort the new date range\n",
    "                new_date_range = sorted(rel_time_ls)\n",
    "                # Replace the original column\n",
    "                df[item] = rel_time_ls\n",
    "            else:\n",
    "                # Initialize the new date range\n",
    "                new_date_range = pd.DatetimeIndex([], dtype='datetime64[ns]', freq=None)\n",
    "                # For loop to expand the date range\n",
    "                for index in range(len(list(time_dic.keys())) - 1):\n",
    "                    new_date_range = new_date_range.append(\n",
    "                        pd.date_range(start=list(time_dic.keys())[index], end=list(time_dic.keys())[index + 1], \\\n",
    "                                      periods=list(time_dic.values())[index] + 1)[:-1])\n",
    "                # Find the frequency\n",
    "                frequency = (1 / 750) * 1000\n",
    "                # Add the last date range\n",
    "                new_date_range = new_date_range.append(\n",
    "                    pd.date_range(start=list(time_dic.keys())[-1], freq=\"{:.3f}ms\".format(frequency),\n",
    "                                  periods=list(time_dic.values())[-1]))\n",
    "                # Sort the new date range\n",
    "                new_date_range = sorted(new_date_range)\n",
    "                # Replace the original column\n",
    "                df[item] = new_date_range\n",
    "    # ------------------------------------------------------------------------------------------------------------------------------\n",
    "    # return the final dataframe\n",
    "    return df\n",
    "\n",
    "\n",
    "def shift_df(datafile_dir: str, filename: str, state: str, luminosity: str, distance: str, save_excel: bool = False) -> pd.DataFrame:\n",
    "    # Import the required libraries\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    # Read the mp csv\n",
    "    df = pd.read_csv(r\"{}/{}_{}_{}_{}.csv\".format(datafile_dir, filename, state, luminosity, distance))\n",
    "    # Change the data type of time\n",
    "    df[\"Time\"] = pd.to_datetime(df[\"Time\"], format=\"%d-%m-%Y %H:%M:%S.%f\")\n",
    "    # Change the data type of system local time\n",
    "    df[\"SystemLocalTime\"] = pd.to_datetime(df[\"SystemLocalTime\"], format=\"%d-%m-%Y %H:%M:%S.%f\")\n",
    "    # Replace the hivine by np.nan\n",
    "    df = df.replace(\"-\", np.nan)\n",
    "    # Change the types of the data\n",
    "    df[['NOM_PRESS_BLD_NONINV_SYS', 'NOM_PRESS_BLD_NONINV_DIA',\n",
    "        'NOM_PRESS_BLD_NONINV_MEAN', 'NOM_PRESS_BLD_NONINV_PULS_RATE',\n",
    "        'NOM_PULS_OXIM_SAT_O2', 'NOM_PLETH_PULS_RATE']] = df[['NOM_PRESS_BLD_NONINV_SYS', 'NOM_PRESS_BLD_NONINV_DIA',\n",
    "                                                              'NOM_PRESS_BLD_NONINV_MEAN',\n",
    "                                                              'NOM_PRESS_BLD_NONINV_PULS_RATE',\n",
    "                                                              'NOM_PULS_OXIM_SAT_O2', 'NOM_PLETH_PULS_RATE']].astype(\n",
    "        np.float64())\n",
    "    df[['NOM_PLETH_PULS_RATE']] = df[['NOM_PLETH_PULS_RATE']].astype(np.float64())\n",
    "\n",
    "    # ---------------------------------------- shift_df part --------------------------------\n",
    "    # To adjust the displaced tables in MP data csv file\n",
    "    # Extract the shifted rows\n",
    "    shift_df = df[df[\"NOM_PLETH_PULS_RATE\"].isna() & df[\"NOM_PULS_OXIM_PERF_REL\"].isna()]\n",
    "    # Extract the values of the req_df\n",
    "    mat = np.concatenate([shift_df.values[:, 0:4], shift_df.values[:, 12:14], shift_df.values[:, 4:12]], axis=1)\n",
    "    # Restore the shifted rows\n",
    "    restored_shift_df = pd.DataFrame(mat, columns=shift_df.columns.tolist(), index=shift_df.index)\n",
    "    # Check the dimensions after the restoration\n",
    "    assert np.shape(shift_df) == np.shape(restored_shift_df)\n",
    "    # Restored the mp dataframe\n",
    "    df.iloc[shift_df.index] = restored_shift_df\n",
    "    # Save the dataframe as an excel file\n",
    "    if save_excel == True:\n",
    "        df.to_excel(excel_writer=r\"{}/{}_shifted.xlsx\".format(datafile_dir, filename), header=True, index=False)\n",
    "        print(\"The excel file has been formed in the directory {}. \".format(datafile_dir))\n",
    "    # Return the dataframe\n",
    "    return df\n",
    "\n",
    "\n",
    "# **********************************************************************************************************************\n",
    "# Define the names of the data files\n",
    "resp_file = \"NOM_RESPWaveExport\"\n",
    "pleth_file = \"NOM_PLETHWaveExport\"\n",
    "elec_file = \"NOM_ECG_ELEC_POTL_IIWaveExport\"\n",
    "mp_file = \"MPDataExport\"\n",
    "\n",
    "data_dir = r\"/Users/kinho123/Downloads\"\n",
    "\n",
    "# ----------------------------------------------------------------------------------\n",
    "date_ls = [\"22-11-2022\", \"25-11-2022\", \"06-12-2022\"]\n",
    "v1_v2_ls = [\"v3\", \"v3\"]\n",
    "v2_subject_ls = [1]\n",
    "recording_ls = [\"recording{}\".format(i) for i in range(2, 1 + 2)]\n",
    "\n",
    "trials = [\"15 mins trial\"]\n",
    "states = [\"Rest\"]\n",
    "    \n",
    "luminosities = [\"100\", \"200\", \"300\", \"500\"]\n",
    "distances = [\"0.4\",\"0.5\", \"0.6\"]\n",
    "\n",
    "# Define the date\n",
    "# date = date_ls[2]\n",
    "v1_v2 = v1_v2_ls[1]\n",
    "\n",
    "# ------------------------------------------ Subject details -----------------------------------------\n",
    "# Read the subject data\n",
    "# subject_details_df = pd.read_excel(r\"C:\\Users\\Ellgan\\Desktop\\dataFromDS\\v2\\{}.xlsx\".format(\"Subject details\"))\n",
    "# subject_details_df = pd.read_csv(r\"C:\\Users\\Ellgan\\Desktop\\dataFromDS\\v2\\{}.csv\".format(\"Subject details\"))\n",
    "# Drop column \"時間戳記\"\n",
    "# subject_details_df.drop(columns=[\"時間戳記\"], inplace=True)\n",
    "\n",
    "# -------------------------------------------- Questionnaire -----------------------------------------\n",
    "# Read the subject data\n",
    "# questionnaire_df = pd.read_excel(\n",
    "    # r\"C:\\Users\\Ellgan\\Desktop\\dataFromDS\\v2\\{}.xlsx\".format(\"Questionnaire for BP measurement response\"))\n",
    "# Drop column \"時間戳記\"\n",
    "# questionnaire_df.drop(columns=[\"Timestamp\"], inplace=True)\n",
    "\n",
    "\n",
    "# ------------------------------------------ Initialization ------------------------------------------\n",
    "# Initialize the dataframe\n",
    "all_df = pd.DataFrame()\n",
    "\n",
    "# ----------------------------------------------------------------------------------------------------\n",
    "for luminosity in luminosities:\n",
    "    for distance in distances:\n",
    "        for num in v2_subject_ls:\n",
    "            for state in states:    \n",
    "                for recording in recording_ls:\n",
    "                    for trial in trials:\n",
    "                        # Define the subject\n",
    "                        subject = \"id_{}\".format(num)\n",
    "                        path = \"{}/{}/{}/{}/{}\".format(data_dir, v1_v2, subject, recording, trial)\n",
    "                        if os.path.exists(path):\n",
    "                            # --------------------------------------------- CSV reading ------------------------------------------\n",
    "                            # Read the resp csv\n",
    "                            resp_df = read_csv_data(datafile_dir=path, filename=resp_file, state = state, luminosity = luminosity, distance = distance, col_name=\"RESP\")\n",
    "                            # Read the pleth csv\n",
    "                            pleth_df = read_csv_data(datafile_dir=path, filename=pleth_file, state = state, luminosity = luminosity, distance = distance, col_name=\"PLETH\")\n",
    "                            # Read the elec csv\n",
    "                            elec_df = read_csv_data(datafile_dir=path, filename=elec_file, state = state, luminosity = luminosity, distance = distance, col_name=\"ELEC\") \n",
    "                            # --------------------------------------------- MP_CSV reading ------------------------------------------\n",
    "                            # Shift the MP dataframe\n",
    "                            mp_df = shift_df(datafile_dir=\"{}/{}/{}/{}/{}\".format(datafile_dir, v1_v2, subject, recording, trial),\n",
    "                                             filename=mp_file, state = state, luminosity = luminosity, distance = distance, save_excel=False)\n",
    "                            # Extract the relevant\n",
    "                            mp_extract_df = mp_df[['Time', 'NOM_PRESS_BLD_NONINV_SYS', 'NOM_PRESS_BLD_NONINV_DIA', 'NOM_PRESS_BLD_NONINV_PULS_RATE',\n",
    "                                                   'NOM_ECG_CARD_BEAT_RATE', 'NOM_RESP_RATE', 'NOM_PULS_OXIM_SAT_O2', 'NOM_PLETH_PULS_RATE']]\n",
    "                            # Dropna\n",
    "                            mp_extract_df = mp_extract_df.dropna()\n",
    "\n",
    "                            # &&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&& Mark details in a pkl &&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&\n",
    "                            # initialize a dictionary for saving\n",
    "                            all_dic = {}\n",
    "                            # Define the dataset name\n",
    "                            all_dic[\"dataset_name\"] = v1_v2\n",
    "\n",
    "                            # Find the subject ID\n",
    "                            \n",
    "                            all_dic[\"subject_id\"] = \"{}\".format(num)\n",
    "                            # Recording\n",
    "                            all_dic[\"recording_number\"] = \"{}\".format(recording)\n",
    "                            # state\n",
    "                            all_dic[\"state\"] = \"{}\".format(state)\n",
    "                            # luminosity\n",
    "                            all_dic[\"luminosity (lx)\"] = \"{}\".format(luminosity)\n",
    "                            # distance\n",
    "                            all_dic[\"distance (m)\"] = \"{}\".format(distance)\n",
    "                            # Find datetime\n",
    "                            #all_dic[\"\"] = pd.to_datetime(date, format = \"%d-%m-%Y\")\n",
    "                           # timestamp_iphone/ipad\n",
    "                            dt = datetime.strptime(str(mp_df['SystemLocalTime'][0]), \"%Y-%m-%d %H:%M:%S.%f\")\n",
    "                \n",
    "                            ts = round(dt.timestamp())\n",
    "                            list1 = [str(dt.fromtimestamp(i)) for i in np.arange(ts,ts + 780,1/30)]\n",
    "        \n",
    "                            all_dic[\"timestamp_iphone/ipad\"] = list1\n",
    "                            # timestamp_ecg\n",
    "                            all_dic[\"timestamp_ecg\"] = elec_df['SystemLocalTime'][1:].tolist()\n",
    "                            # ECG data\n",
    "                            all_dic[\"ECG_data(mV)\"] = elec_df[\"ELEC\"].tolist() \n",
    "                            # timestamp_ppg\n",
    "                            all_dic[\"timestamp_ppg\"] = pleth_df['SystemLocalTime'][1:].tolist()\n",
    "                            # PPG data\n",
    "                            all_dic[\"PPG_data\"] = pleth_df[\"PLETH\"].tolist()\n",
    "                            # RESP data\n",
    "                            #all_dic[\"RESP_data(bpm)\"] = resp_df[\"RESP\"].tolist()\n",
    "                            # ECG_fps\n",
    "                            #all_dic[\"ECG_fps(Hz)\"] = 750\n",
    "                            # PPG_fps\n",
    "                            #all_dic[\"PPG_fps(Hz)\"] = 125\n",
    "                            # RESP_fps\n",
    "                            #all_dic[\"RESP_fps(Hz)\"] = 125\n",
    "                            # timestamp_vital_sign\n",
    "                            all_dic[\"timestamp_vital_sign\"] = mp_df['SystemLocalTime'].tolist()\n",
    "                            # Pulse rate (ecg)\n",
    "                            all_dic[\"hr_ecg(bpm)\"] = mp_extract_df['NOM_ECG_CARD_BEAT_RATE'].tolist()\n",
    "                            # Pulse rate (ppg)\n",
    "                            all_dic[\"hr_ppg(bpm)\"] = mp_extract_df['NOM_PLETH_PULS_RATE'].tolist()\n",
    "                            # SpO2\n",
    "                            all_dic[\"SpO2(%)\"] = mp_extract_df['NOM_PULS_OXIM_SAT_O2'].tolist()\n",
    "                            # SBP\n",
    "                            all_dic[\"SBP(mmHg)\"] = mp_extract_df['NOM_PRESS_BLD_NONINV_SYS'].dropna().unique().tolist()\n",
    "                            # DBP\n",
    "                            all_dic[\"DBP(mmHg)\"] = mp_extract_df['NOM_PRESS_BLD_NONINV_DIA'].dropna().unique().tolist()\n",
    "                            #respiratory_rate\n",
    "                            all_dic[\"respiratory_rate(pm)\"] = mp_extract_df[\"NOM_RESP_RATE\"].tolist()\n",
    "                            # SpO2_fps\n",
    "                            #all_dic[\"SpO2_fps(Hz)\"] = 1\n",
    "                            # Pulse_rate_fps(Hz)\n",
    "                            #all_dic[\"hr_fps(Hz)\"] = 1\n",
    "                            # *********************************** Questionnaire **********************************************\n",
    "                            # Extract the details of a specific subject\n",
    "                            #specific_questionnaire_df = questionnaire_df[questionnaire_df[\"Subject ID\"] == num]\n",
    "                            # Drop the subject ID\n",
    "                            #specific_questionnaire_df.drop(columns=\"Subject ID\", inplace=True)\n",
    "                            # Ensure that the subject id is unique\n",
    "                            #assert (len(list(specific_questionnaire_df.T.to_dict().values())))\n",
    "                            # Update the dictionary\n",
    "                            #all_dic.update(list(specific_questionnaire_df.T.to_dict().values())[0])\n",
    "                            # *********************************** Subject details ********************************************\n",
    "                            #specific_subject_df = subject_details_df[subject_details_df[\"Subject ID\"] == num]\n",
    "                            #specific_subject_df.drop(columns=\"Subject ID\", inplace=True)\n",
    "                            ## Ensure that the subject id is unique\n",
    "                            #assert (len(list(specific_subject_df.T.to_dict().values())))\n",
    "                            # Update the dictionary\n",
    "                            #all_dic.update(list(specific_subject_df.T.to_dict().values())[0])\n",
    "                            # ************************************************************************************************\n",
    "                            # Append the dict to all_df\n",
    "                            all_df = all_df.append(all_dic, ignore_index=True)\n",
    "                            # Print the database and the subject for confirmation\n",
    "                            print(\"finished: {}_{}_{}_{}_{}_{}_{}\".format(v1_v2, subject, recording, trial, state, luminosity, distance ))\n",
    "                        else:\n",
    "                            print(\"The path {}/{}/{}/{} does not exist.\".format(v1_v2, subject, recording, trial))\n",
    "                            pass\n",
    "\n",
    "# +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
    "# Define the path for export\n",
    "export_dir = data_dir\n",
    "export_filename = \"BPdataset_{}_1\".format(v1_v2)\n",
    "# Export the dataframe to a pickle file\n",
    "all_df.to_pickle(path=\"{}/{}.pkl\".format(export_dir, export_filename))\n",
    "\n",
    "# Print the dataframe\n",
    "#print(all_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DBP(mmHg)</th>\n",
       "      <th>ECG_data(mV)</th>\n",
       "      <th>PPG_data</th>\n",
       "      <th>SBP(mmHg)</th>\n",
       "      <th>SpO2(%)</th>\n",
       "      <th>dataset_name</th>\n",
       "      <th>distance (m)</th>\n",
       "      <th>hr_ecg(bpm)</th>\n",
       "      <th>hr_ppg(bpm)</th>\n",
       "      <th>luminosity (lx)</th>\n",
       "      <th>recording_number</th>\n",
       "      <th>respiratory_rate(pm)</th>\n",
       "      <th>state</th>\n",
       "      <th>subject_id</th>\n",
       "      <th>timestamp_ecg</th>\n",
       "      <th>timestamp_iphone/ipad</th>\n",
       "      <th>timestamp_ppg</th>\n",
       "      <th>timestamp_vital_sign</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[56.0]</td>\n",
       "      <td>[-0.23, -0.32, -0.34, -0.37, -0.39, -0.41, -0....</td>\n",
       "      <td>[2166, 2323, 2494, 2629, 2733, 2809, 2853, 286...</td>\n",
       "      <td>[91.0]</td>\n",
       "      <td>[100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100...</td>\n",
       "      <td>v3</td>\n",
       "      <td>0.4</td>\n",
       "      <td>[67.0, 67.0, 68.0, 68.0, 68.0, 69.0, 69.0, 69.0]</td>\n",
       "      <td>[65.0, 65.0, 65.0, 66.0, 66.0, 67.0, 67.0, 68.0]</td>\n",
       "      <td>100</td>\n",
       "      <td>recording2</td>\n",
       "      <td>[21, 22, 22, 22, 21, 23, 23, 23]</td>\n",
       "      <td>Rest</td>\n",
       "      <td>1</td>\n",
       "      <td>[2023-01-13 15:42:29.175000, 2023-01-13 15:42:...</td>\n",
       "      <td>[2023-01-13 15:42:28, 2023-01-13 15:42:28.0333...</td>\n",
       "      <td>[2023-01-13 15:42:30.199000, 2023-01-13 15:42:...</td>\n",
       "      <td>[2023-01-13 15:42:28.129000, 2023-01-13 15:42:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[56.0, 60.0]</td>\n",
       "      <td>[-0.23, 0.32, 0.35, 0.37, 0.38, 0.38, 0.37, 0....</td>\n",
       "      <td>[2166, 1406, 1401, 1398, 1394, 1390, 1386, 138...</td>\n",
       "      <td>[91.0, 93.0]</td>\n",
       "      <td>[100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100...</td>\n",
       "      <td>v3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>[68.0, 69.0, 70.0, 70.0, 72.0, 73.0, 74.0, 75....</td>\n",
       "      <td>[66.0, 66.0, 67.0, 67.0, 67.0, 67.0, 67.0, 68....</td>\n",
       "      <td>100</td>\n",
       "      <td>recording2</td>\n",
       "      <td>[13, 13, 15, 15, 15, 17, 17, 17, 18, 18, 18, 1...</td>\n",
       "      <td>Rest</td>\n",
       "      <td>1</td>\n",
       "      <td>[2023-01-13 15:47:03.724000, 2023-01-13 15:47:...</td>\n",
       "      <td>[2023-01-13 15:47:03, 2023-01-13 15:47:03.0333...</td>\n",
       "      <td>[2023-01-13 15:47:03.725000, 2023-01-13 15:47:...</td>\n",
       "      <td>[2023-01-13 15:47:02.685000, 2023-01-13 15:47:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[60.0, 62.0]</td>\n",
       "      <td>[-0.23, -0.27, -0.23, -0.19, -0.17, -0.18, -0....</td>\n",
       "      <td>[2166, 2009, 1995, 1975, 1950, 1921, 1890, 185...</td>\n",
       "      <td>[93.0]</td>\n",
       "      <td>[100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100...</td>\n",
       "      <td>v3</td>\n",
       "      <td>0.6</td>\n",
       "      <td>[75.0, 77.0, 79.0, 82.0, 84.0, 85.0, 85.0, 85....</td>\n",
       "      <td>[69.0, 69.0, 69.0, 70.0, 71.0, 72.0, 75.0, 77....</td>\n",
       "      <td>100</td>\n",
       "      <td>recording2</td>\n",
       "      <td>[22, 22, 22, 22, 22, 22, 22, 19, 19, 19, 19, 1...</td>\n",
       "      <td>Rest</td>\n",
       "      <td>1</td>\n",
       "      <td>[2023-01-13 15:51:01.401000, 2023-01-13 15:51:...</td>\n",
       "      <td>[2023-01-13 15:51:00, 2023-01-13 15:51:00.0333...</td>\n",
       "      <td>[2023-01-13 15:51:01.402000, 2023-01-13 15:51:...</td>\n",
       "      <td>[2023-01-13 15:51:00.360000, 2023-01-13 15:51:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[62.0, 58.0]</td>\n",
       "      <td>[-0.23, -0.19, -0.22, -0.23, -0.21, -0.17, -0....</td>\n",
       "      <td>[2166, 1600, 1597, 1597, 1598, 1598, 1596, 159...</td>\n",
       "      <td>[93.0, 92.0]</td>\n",
       "      <td>[100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100...</td>\n",
       "      <td>v3</td>\n",
       "      <td>0.4</td>\n",
       "      <td>[68.0, 68.0, 68.0, 69.0, 69.0, 70.0, 70.0, 71....</td>\n",
       "      <td>[70.0, 69.0, 68.0, 68.0, 68.0, 68.0, 68.0, 69....</td>\n",
       "      <td>200</td>\n",
       "      <td>recording2</td>\n",
       "      <td>[20, 20, 20, 20, 20, 19, 19, 19, 19, 19, 19, 1...</td>\n",
       "      <td>Rest</td>\n",
       "      <td>1</td>\n",
       "      <td>[2023-01-13 15:53:16.631000, 2023-01-13 15:53:...</td>\n",
       "      <td>[2023-01-13 15:53:16, 2023-01-13 15:53:16.0333...</td>\n",
       "      <td>[2023-01-13 15:53:16.631000, 2023-01-13 15:53:...</td>\n",
       "      <td>[2023-01-13 15:53:15.591000, 2023-01-13 15:53:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[58.0]</td>\n",
       "      <td>[-0.23, 0.59, 0.64, 0.68, 0.72, 0.74, 0.75, 0....</td>\n",
       "      <td>[2166, 1609, 1591, 1576, 1563, 1552, 1543, 153...</td>\n",
       "      <td>[92.0, 90.0]</td>\n",
       "      <td>[100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100...</td>\n",
       "      <td>v3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>[77.0, 77.0, 76.0, 75.0, 74.0, 73.0, 73.0, 72....</td>\n",
       "      <td>[72.0, 73.0, 74.0, 75.0, 75.0, 76.0, 76.0, 75....</td>\n",
       "      <td>200</td>\n",
       "      <td>recording2</td>\n",
       "      <td>[15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 16, 1...</td>\n",
       "      <td>Rest</td>\n",
       "      <td>1</td>\n",
       "      <td>[2023-01-13 15:55:15.470000, 2023-01-13 15:55:...</td>\n",
       "      <td>[2023-01-13 15:55:15, 2023-01-13 15:55:15.0333...</td>\n",
       "      <td>[2023-01-13 15:55:15.470000, 2023-01-13 15:55:...</td>\n",
       "      <td>[2023-01-13 15:55:15.455000, 2023-01-13 15:55:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[58.0, 62.0]</td>\n",
       "      <td>[-0.23, -0.23, -0.26, -0.28, -0.3, -0.28, -0.2...</td>\n",
       "      <td>[2166, 1799, 1974, 2154, 2328, 2481, 2612, 272...</td>\n",
       "      <td>[90.0, 88.0]</td>\n",
       "      <td>[100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100...</td>\n",
       "      <td>v3</td>\n",
       "      <td>0.6</td>\n",
       "      <td>[74.0, 75.0, 76.0, 76.0, 78.0, 80.0, 80.0, 81....</td>\n",
       "      <td>[73.0, 73.0, 73.0, 73.0, 74.0, 74.0, 75.0, 75....</td>\n",
       "      <td>200</td>\n",
       "      <td>recording2</td>\n",
       "      <td>[15, 15, 17, 17, 17, 16, 16, 16, 16, 16, 16, 1...</td>\n",
       "      <td>Rest</td>\n",
       "      <td>1</td>\n",
       "      <td>[2023-01-13 15:58:21.913000, 2023-01-13 15:58:...</td>\n",
       "      <td>[2023-01-13 15:58:21, 2023-01-13 15:58:21.0333...</td>\n",
       "      <td>[2023-01-13 15:58:21.913000, 2023-01-13 15:58:...</td>\n",
       "      <td>[2023-01-13 15:58:20.882000, 2023-01-13 15:58:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[62.0, 55.0]</td>\n",
       "      <td>[-0.23, -0.17, -0.14, -0.11, -0.12, -0.11, -0....</td>\n",
       "      <td>[2166, 2361, 2295, 2229, 2163, 2098, 2034, 197...</td>\n",
       "      <td>[88.0, 87.0]</td>\n",
       "      <td>[100.0, 100.0, 100.0, 100.0, 100.0, 99.9, 99.8...</td>\n",
       "      <td>v3</td>\n",
       "      <td>0.4</td>\n",
       "      <td>[73.0, 75.0, 76.0, 76.0, 76.0, 76.0, 75.0, 75....</td>\n",
       "      <td>[73.0, 74.0, 74.0, 74.0, 75.0, 75.0, 75.0, 75....</td>\n",
       "      <td>300</td>\n",
       "      <td>recording2</td>\n",
       "      <td>[18, 18, 18, 17, 16, 16, 16, 16, 16, 16, 17, 1...</td>\n",
       "      <td>Rest</td>\n",
       "      <td>1</td>\n",
       "      <td>[2023-01-13 16:00:45.353000, 2023-01-13 16:00:...</td>\n",
       "      <td>[2023-01-13 16:00:45, 2023-01-13 16:00:45.0333...</td>\n",
       "      <td>[2023-01-13 16:00:45.353000, 2023-01-13 16:00:...</td>\n",
       "      <td>[2023-01-13 16:00:45.333000, 2023-01-13 16:00:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[55.0, 58.0]</td>\n",
       "      <td>[-0.23, 0.1, 0.07, 0.05, 0.05, 0.07, 0.09, 0.1...</td>\n",
       "      <td>[2166, 1926, 1892, 1853, 1812, 1769, 1725, 167...</td>\n",
       "      <td>[87.0, 85.0]</td>\n",
       "      <td>[100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100...</td>\n",
       "      <td>v3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>[68.0, 70.0, 70.0, 71.0, 72.0, 72.0, 72.0, 71....</td>\n",
       "      <td>[65.0, 64.0, 63.0, 64.0, 66.0, 67.0, 69.0, 70....</td>\n",
       "      <td>300</td>\n",
       "      <td>recording2</td>\n",
       "      <td>[17, 17, 17, 17, 17, 17, 17, 18, 18, 18, 18, 1...</td>\n",
       "      <td>Rest</td>\n",
       "      <td>1</td>\n",
       "      <td>[2023-01-13 16:02:41.113000, 2023-01-13 16:02:...</td>\n",
       "      <td>[2023-01-13 16:02:41, 2023-01-13 16:02:41.0333...</td>\n",
       "      <td>[2023-01-13 16:02:41.113000, 2023-01-13 16:02:...</td>\n",
       "      <td>[2023-01-13 16:02:41.096000, 2023-01-13 16:02:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[58.0, 59.0]</td>\n",
       "      <td>[-0.23, -0.24, -0.22, -0.26, -0.29, -0.28, -0....</td>\n",
       "      <td>[2166, 1872, 1829, 1786, 1744, 1704, 1666, 163...</td>\n",
       "      <td>[85.0, 91.0]</td>\n",
       "      <td>[100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100...</td>\n",
       "      <td>v3</td>\n",
       "      <td>0.6</td>\n",
       "      <td>[78.0, 80.0, 80.0, 80.0, 80.0, 79.0, 79.0, 77....</td>\n",
       "      <td>[72.0, 73.0, 74.0, 75.0, 76.0, 78.0, 79.0, 80....</td>\n",
       "      <td>300</td>\n",
       "      <td>recording2</td>\n",
       "      <td>[19, 19, 19, 19, 19, 20, 20, 20, 19, 19, 19, 2...</td>\n",
       "      <td>Rest</td>\n",
       "      <td>1</td>\n",
       "      <td>[2023-01-13 16:05:26.040000, 2023-01-13 16:05:...</td>\n",
       "      <td>[2023-01-13 16:05:25, 2023-01-13 16:05:25.0333...</td>\n",
       "      <td>[2023-01-13 16:05:26.040000, 2023-01-13 16:05:...</td>\n",
       "      <td>[2023-01-13 16:05:25.011000, 2023-01-13 16:05:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[59.0, 57.0]</td>\n",
       "      <td>[-0.23, -0.23, -0.2, -0.15, -0.13, -0.12, -0.1...</td>\n",
       "      <td>[2166, 1790, 1838, 1887, 1938, 1985, 2025, 205...</td>\n",
       "      <td>[91.0, 85.0]</td>\n",
       "      <td>[100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100...</td>\n",
       "      <td>v3</td>\n",
       "      <td>0.4</td>\n",
       "      <td>[74.0, 76.0, 78.0, 79.0, 79.0, 79.0, 78.0, 77....</td>\n",
       "      <td>[71.0, 70.0, 70.0, 70.0, 72.0, 73.0, 74.0, 74....</td>\n",
       "      <td>500</td>\n",
       "      <td>recording2</td>\n",
       "      <td>[16, 16, 16, 16, 16, 16, 16, 15, 15, 15, 15, 1...</td>\n",
       "      <td>Rest</td>\n",
       "      <td>1</td>\n",
       "      <td>[2023-01-13 16:08:05.858000, 2023-01-13 16:08:...</td>\n",
       "      <td>[2023-01-13 16:08:05, 2023-01-13 16:08:05.0333...</td>\n",
       "      <td>[2023-01-13 16:08:05.858000, 2023-01-13 16:08:...</td>\n",
       "      <td>[2023-01-13 16:08:04.829000, 2023-01-13 16:08:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[57.0, 61.0]</td>\n",
       "      <td>[-0.23, -0.18, -0.2, -0.21, -0.19, -0.16, -0.1...</td>\n",
       "      <td>[2166, 1419, 1415, 1409, 1404, 1397, 1395, 140...</td>\n",
       "      <td>[85.0, 91.0]</td>\n",
       "      <td>[100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100...</td>\n",
       "      <td>v3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>[72.0, 73.0, 73.0, 75.0, 78.0, 78.0, 79.0, 79....</td>\n",
       "      <td>[71.0, 70.0, 70.0, 69.0, 70.0, 70.0, 72.0, 73....</td>\n",
       "      <td>500</td>\n",
       "      <td>recording2</td>\n",
       "      <td>[13, 13, 14, 14, 14, 14, 14, 14, 13, 12, 12, 1...</td>\n",
       "      <td>Rest</td>\n",
       "      <td>1</td>\n",
       "      <td>[2023-01-13 16:10:16.999000, 2023-01-13 16:10:...</td>\n",
       "      <td>[2023-01-13 16:10:16, 2023-01-13 16:10:16.0333...</td>\n",
       "      <td>[2023-01-13 16:10:16.999000, 2023-01-13 16:10:...</td>\n",
       "      <td>[2023-01-13 16:10:15.962000, 2023-01-13 16:10:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[61.0, 64.0]</td>\n",
       "      <td>[-0.23, 0.6, 0.71, 0.73, 0.65, 0.41, 0.03, -0....</td>\n",
       "      <td>[2166, 2159, 2283, 2392, 2485, 2557, 2604, 262...</td>\n",
       "      <td>[91.0, 87.0]</td>\n",
       "      <td>[100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100...</td>\n",
       "      <td>v3</td>\n",
       "      <td>0.6</td>\n",
       "      <td>[71.0, 71.0, 71.0, 70.0, 70.0, 69.0, 70.0, 71....</td>\n",
       "      <td>[69.0, 70.0, 70.0, 69.0, 69.0, 68.0, 68.0, 67....</td>\n",
       "      <td>500</td>\n",
       "      <td>recording2</td>\n",
       "      <td>[14, 14, 14, 14, 14, 14, 13, 12, 12, 12, 12, 1...</td>\n",
       "      <td>Rest</td>\n",
       "      <td>1</td>\n",
       "      <td>[2023-01-13 16:12:00.472000, 2023-01-13 16:12:...</td>\n",
       "      <td>[2023-01-13 16:12:00, 2023-01-13 16:12:00.0333...</td>\n",
       "      <td>[2023-01-13 16:12:00.472000, 2023-01-13 16:12:...</td>\n",
       "      <td>[2023-01-13 16:12:00.457000, 2023-01-13 16:12:...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       DBP(mmHg)                                       ECG_data(mV)                                           PPG_data     SBP(mmHg)                                            SpO2(%) dataset_name distance (m)                                        hr_ecg(bpm)                                        hr_ppg(bpm) luminosity (lx) recording_number                               respiratory_rate(pm) state subject_id                                      timestamp_ecg                              timestamp_iphone/ipad                                      timestamp_ppg                               timestamp_vital_sign\n",
       "0         [56.0]  [-0.23, -0.32, -0.34, -0.37, -0.39, -0.41, -0....  [2166, 2323, 2494, 2629, 2733, 2809, 2853, 286...        [91.0]  [100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100...           v3          0.4   [67.0, 67.0, 68.0, 68.0, 68.0, 69.0, 69.0, 69.0]   [65.0, 65.0, 65.0, 66.0, 66.0, 67.0, 67.0, 68.0]             100       recording2                   [21, 22, 22, 22, 21, 23, 23, 23]  Rest          1  [2023-01-13 15:42:29.175000, 2023-01-13 15:42:...  [2023-01-13 15:42:28, 2023-01-13 15:42:28.0333...  [2023-01-13 15:42:30.199000, 2023-01-13 15:42:...  [2023-01-13 15:42:28.129000, 2023-01-13 15:42:...\n",
       "1   [56.0, 60.0]  [-0.23, 0.32, 0.35, 0.37, 0.38, 0.38, 0.37, 0....  [2166, 1406, 1401, 1398, 1394, 1390, 1386, 138...  [91.0, 93.0]  [100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100...           v3          0.5  [68.0, 69.0, 70.0, 70.0, 72.0, 73.0, 74.0, 75....  [66.0, 66.0, 67.0, 67.0, 67.0, 67.0, 67.0, 68....             100       recording2  [13, 13, 15, 15, 15, 17, 17, 17, 18, 18, 18, 1...  Rest          1  [2023-01-13 15:47:03.724000, 2023-01-13 15:47:...  [2023-01-13 15:47:03, 2023-01-13 15:47:03.0333...  [2023-01-13 15:47:03.725000, 2023-01-13 15:47:...  [2023-01-13 15:47:02.685000, 2023-01-13 15:47:...\n",
       "2   [60.0, 62.0]  [-0.23, -0.27, -0.23, -0.19, -0.17, -0.18, -0....  [2166, 2009, 1995, 1975, 1950, 1921, 1890, 185...        [93.0]  [100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100...           v3          0.6  [75.0, 77.0, 79.0, 82.0, 84.0, 85.0, 85.0, 85....  [69.0, 69.0, 69.0, 70.0, 71.0, 72.0, 75.0, 77....             100       recording2  [22, 22, 22, 22, 22, 22, 22, 19, 19, 19, 19, 1...  Rest          1  [2023-01-13 15:51:01.401000, 2023-01-13 15:51:...  [2023-01-13 15:51:00, 2023-01-13 15:51:00.0333...  [2023-01-13 15:51:01.402000, 2023-01-13 15:51:...  [2023-01-13 15:51:00.360000, 2023-01-13 15:51:...\n",
       "3   [62.0, 58.0]  [-0.23, -0.19, -0.22, -0.23, -0.21, -0.17, -0....  [2166, 1600, 1597, 1597, 1598, 1598, 1596, 159...  [93.0, 92.0]  [100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100...           v3          0.4  [68.0, 68.0, 68.0, 69.0, 69.0, 70.0, 70.0, 71....  [70.0, 69.0, 68.0, 68.0, 68.0, 68.0, 68.0, 69....             200       recording2  [20, 20, 20, 20, 20, 19, 19, 19, 19, 19, 19, 1...  Rest          1  [2023-01-13 15:53:16.631000, 2023-01-13 15:53:...  [2023-01-13 15:53:16, 2023-01-13 15:53:16.0333...  [2023-01-13 15:53:16.631000, 2023-01-13 15:53:...  [2023-01-13 15:53:15.591000, 2023-01-13 15:53:...\n",
       "4         [58.0]  [-0.23, 0.59, 0.64, 0.68, 0.72, 0.74, 0.75, 0....  [2166, 1609, 1591, 1576, 1563, 1552, 1543, 153...  [92.0, 90.0]  [100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100...           v3          0.5  [77.0, 77.0, 76.0, 75.0, 74.0, 73.0, 73.0, 72....  [72.0, 73.0, 74.0, 75.0, 75.0, 76.0, 76.0, 75....             200       recording2  [15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 16, 1...  Rest          1  [2023-01-13 15:55:15.470000, 2023-01-13 15:55:...  [2023-01-13 15:55:15, 2023-01-13 15:55:15.0333...  [2023-01-13 15:55:15.470000, 2023-01-13 15:55:...  [2023-01-13 15:55:15.455000, 2023-01-13 15:55:...\n",
       "5   [58.0, 62.0]  [-0.23, -0.23, -0.26, -0.28, -0.3, -0.28, -0.2...  [2166, 1799, 1974, 2154, 2328, 2481, 2612, 272...  [90.0, 88.0]  [100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100...           v3          0.6  [74.0, 75.0, 76.0, 76.0, 78.0, 80.0, 80.0, 81....  [73.0, 73.0, 73.0, 73.0, 74.0, 74.0, 75.0, 75....             200       recording2  [15, 15, 17, 17, 17, 16, 16, 16, 16, 16, 16, 1...  Rest          1  [2023-01-13 15:58:21.913000, 2023-01-13 15:58:...  [2023-01-13 15:58:21, 2023-01-13 15:58:21.0333...  [2023-01-13 15:58:21.913000, 2023-01-13 15:58:...  [2023-01-13 15:58:20.882000, 2023-01-13 15:58:...\n",
       "6   [62.0, 55.0]  [-0.23, -0.17, -0.14, -0.11, -0.12, -0.11, -0....  [2166, 2361, 2295, 2229, 2163, 2098, 2034, 197...  [88.0, 87.0]  [100.0, 100.0, 100.0, 100.0, 100.0, 99.9, 99.8...           v3          0.4  [73.0, 75.0, 76.0, 76.0, 76.0, 76.0, 75.0, 75....  [73.0, 74.0, 74.0, 74.0, 75.0, 75.0, 75.0, 75....             300       recording2  [18, 18, 18, 17, 16, 16, 16, 16, 16, 16, 17, 1...  Rest          1  [2023-01-13 16:00:45.353000, 2023-01-13 16:00:...  [2023-01-13 16:00:45, 2023-01-13 16:00:45.0333...  [2023-01-13 16:00:45.353000, 2023-01-13 16:00:...  [2023-01-13 16:00:45.333000, 2023-01-13 16:00:...\n",
       "7   [55.0, 58.0]  [-0.23, 0.1, 0.07, 0.05, 0.05, 0.07, 0.09, 0.1...  [2166, 1926, 1892, 1853, 1812, 1769, 1725, 167...  [87.0, 85.0]  [100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100...           v3          0.5  [68.0, 70.0, 70.0, 71.0, 72.0, 72.0, 72.0, 71....  [65.0, 64.0, 63.0, 64.0, 66.0, 67.0, 69.0, 70....             300       recording2  [17, 17, 17, 17, 17, 17, 17, 18, 18, 18, 18, 1...  Rest          1  [2023-01-13 16:02:41.113000, 2023-01-13 16:02:...  [2023-01-13 16:02:41, 2023-01-13 16:02:41.0333...  [2023-01-13 16:02:41.113000, 2023-01-13 16:02:...  [2023-01-13 16:02:41.096000, 2023-01-13 16:02:...\n",
       "8   [58.0, 59.0]  [-0.23, -0.24, -0.22, -0.26, -0.29, -0.28, -0....  [2166, 1872, 1829, 1786, 1744, 1704, 1666, 163...  [85.0, 91.0]  [100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100...           v3          0.6  [78.0, 80.0, 80.0, 80.0, 80.0, 79.0, 79.0, 77....  [72.0, 73.0, 74.0, 75.0, 76.0, 78.0, 79.0, 80....             300       recording2  [19, 19, 19, 19, 19, 20, 20, 20, 19, 19, 19, 2...  Rest          1  [2023-01-13 16:05:26.040000, 2023-01-13 16:05:...  [2023-01-13 16:05:25, 2023-01-13 16:05:25.0333...  [2023-01-13 16:05:26.040000, 2023-01-13 16:05:...  [2023-01-13 16:05:25.011000, 2023-01-13 16:05:...\n",
       "9   [59.0, 57.0]  [-0.23, -0.23, -0.2, -0.15, -0.13, -0.12, -0.1...  [2166, 1790, 1838, 1887, 1938, 1985, 2025, 205...  [91.0, 85.0]  [100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100...           v3          0.4  [74.0, 76.0, 78.0, 79.0, 79.0, 79.0, 78.0, 77....  [71.0, 70.0, 70.0, 70.0, 72.0, 73.0, 74.0, 74....             500       recording2  [16, 16, 16, 16, 16, 16, 16, 15, 15, 15, 15, 1...  Rest          1  [2023-01-13 16:08:05.858000, 2023-01-13 16:08:...  [2023-01-13 16:08:05, 2023-01-13 16:08:05.0333...  [2023-01-13 16:08:05.858000, 2023-01-13 16:08:...  [2023-01-13 16:08:04.829000, 2023-01-13 16:08:...\n",
       "10  [57.0, 61.0]  [-0.23, -0.18, -0.2, -0.21, -0.19, -0.16, -0.1...  [2166, 1419, 1415, 1409, 1404, 1397, 1395, 140...  [85.0, 91.0]  [100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100...           v3          0.5  [72.0, 73.0, 73.0, 75.0, 78.0, 78.0, 79.0, 79....  [71.0, 70.0, 70.0, 69.0, 70.0, 70.0, 72.0, 73....             500       recording2  [13, 13, 14, 14, 14, 14, 14, 14, 13, 12, 12, 1...  Rest          1  [2023-01-13 16:10:16.999000, 2023-01-13 16:10:...  [2023-01-13 16:10:16, 2023-01-13 16:10:16.0333...  [2023-01-13 16:10:16.999000, 2023-01-13 16:10:...  [2023-01-13 16:10:15.962000, 2023-01-13 16:10:...\n",
       "11  [61.0, 64.0]  [-0.23, 0.6, 0.71, 0.73, 0.65, 0.41, 0.03, -0....  [2166, 2159, 2283, 2392, 2485, 2557, 2604, 262...  [91.0, 87.0]  [100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100...           v3          0.6  [71.0, 71.0, 71.0, 70.0, 70.0, 69.0, 70.0, 71....  [69.0, 70.0, 70.0, 69.0, 69.0, 68.0, 68.0, 67....             500       recording2  [14, 14, 14, 14, 14, 14, 13, 12, 12, 12, 12, 1...  Rest          1  [2023-01-13 16:12:00.472000, 2023-01-13 16:12:...  [2023-01-13 16:12:00, 2023-01-13 16:12:00.0333...  [2023-01-13 16:12:00.472000, 2023-01-13 16:12:...  [2023-01-13 16:12:00.457000, 2023-01-13 16:12:..."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_pickle(\"{}.pkl\".format(\"/Users/kinho123/Downloads/BPdataset_v4\") )\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DBP(mmHg)</th>\n",
       "      <th>ECG_data(mV)</th>\n",
       "      <th>ECG_fps(Hz)</th>\n",
       "      <th>PPG_data</th>\n",
       "      <th>PPG_fps(Hz)</th>\n",
       "      <th>Pulse_rate(bpm)</th>\n",
       "      <th>Pulse_rate_fps(Hz)</th>\n",
       "      <th>RESP_data(bpm)</th>\n",
       "      <th>RESP_fps(Hz)</th>\n",
       "      <th>SBP(mmHg)</th>\n",
       "      <th>SpO2(%)</th>\n",
       "      <th>SpO2_fps(Hz)</th>\n",
       "      <th>dataset_name</th>\n",
       "      <th>subject_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[66.0, 68.0, 60.0, 59.0, 63.0, 62.0, 75.0, 64....</td>\n",
       "      <td>[-0.2, -0.2, -0.19, -0.17, -0.18, -0.18, -0.2,...</td>\n",
       "      <td>750.0</td>\n",
       "      <td>[1629, 1765, 1902, 2034, 2154, 2256, 2341, 240...</td>\n",
       "      <td>125.0</td>\n",
       "      <td>[64.0, 65.0, 66.0, 67.0, 68.0, 69.0, 70.0, 70....</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[0.4, 0.41, 0.43, 0.44, 0.44, 0.45, 0.45, 0.46...</td>\n",
       "      <td>125.0</td>\n",
       "      <td>[113.0, 102.0, 93.0, 100.0, 98.0, 96.0, 87.0, ...</td>\n",
       "      <td>[97.7, 97.7, 97.7, 97.7, 97.7, 97.6, 97.6, 97....</td>\n",
       "      <td>1.0</td>\n",
       "      <td>v3</td>\n",
       "      <td>id_1_recording1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[61.0, 65.0, 69.0, 63.0, 70.0, 64.0, 60.0, 71....</td>\n",
       "      <td>[-0.1, 0.03, 0.14, 0.07, -0.06, -0.05, 0.12, 0...</td>\n",
       "      <td>750.0</td>\n",
       "      <td>[2414, 2408, 2401, 2390, 2372, 2348, 2321, 229...</td>\n",
       "      <td>125.0</td>\n",
       "      <td>[77.0, 75.0, 74.0, 73.0, 71.0, 71.0, 70.0, 71....</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[0.04, 0.04, 0.04, 0.04, 0.05, 0.05, 0.05, 0.0...</td>\n",
       "      <td>125.0</td>\n",
       "      <td>[106.0, 92.0, 98.0, 94.0, 85.0, 97.0, 95.0, 93...</td>\n",
       "      <td>[100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>v3</td>\n",
       "      <td>id_2_recording1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           DBP(mmHg)  \\\n",
       "0  [66.0, 68.0, 60.0, 59.0, 63.0, 62.0, 75.0, 64....   \n",
       "1  [61.0, 65.0, 69.0, 63.0, 70.0, 64.0, 60.0, 71....   \n",
       "\n",
       "                                        ECG_data(mV)  ECG_fps(Hz)  \\\n",
       "0  [-0.2, -0.2, -0.19, -0.17, -0.18, -0.18, -0.2,...        750.0   \n",
       "1  [-0.1, 0.03, 0.14, 0.07, -0.06, -0.05, 0.12, 0...        750.0   \n",
       "\n",
       "                                            PPG_data  PPG_fps(Hz)  \\\n",
       "0  [1629, 1765, 1902, 2034, 2154, 2256, 2341, 240...        125.0   \n",
       "1  [2414, 2408, 2401, 2390, 2372, 2348, 2321, 229...        125.0   \n",
       "\n",
       "                                     Pulse_rate(bpm)  Pulse_rate_fps(Hz)  \\\n",
       "0  [64.0, 65.0, 66.0, 67.0, 68.0, 69.0, 70.0, 70....                 1.0   \n",
       "1  [77.0, 75.0, 74.0, 73.0, 71.0, 71.0, 70.0, 71....                 1.0   \n",
       "\n",
       "                                      RESP_data(bpm)  RESP_fps(Hz)  \\\n",
       "0  [0.4, 0.41, 0.43, 0.44, 0.44, 0.45, 0.45, 0.46...         125.0   \n",
       "1  [0.04, 0.04, 0.04, 0.04, 0.05, 0.05, 0.05, 0.0...         125.0   \n",
       "\n",
       "                                           SBP(mmHg)  \\\n",
       "0  [113.0, 102.0, 93.0, 100.0, 98.0, 96.0, 87.0, ...   \n",
       "1  [106.0, 92.0, 98.0, 94.0, 85.0, 97.0, 95.0, 93...   \n",
       "\n",
       "                                             SpO2(%)  SpO2_fps(Hz)  \\\n",
       "0  [97.7, 97.7, 97.7, 97.7, 97.7, 97.6, 97.6, 97....           1.0   \n",
       "1  [100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100...           1.0   \n",
       "\n",
       "  dataset_name       subject_id  \n",
       "0           v3  id_1_recording1  \n",
       "1           v3  id_2_recording1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_pickle(\"/Users/kinho123/Downloads/BPdataset_v4.pkl\")\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 :\n",
      "['2023-01-19 15:56:40', '2023-01-19 15:56:41', '2023-01-19 15:56:42', '2023-01-19 15:56:43', '2023-01-19 15:56:44', '2023-01-19 15:56:45', '2023-01-19 15:56:46', '2023-01-19 15:56:47', '2023-01-19 15:56:48', '2023-01-19 15:56:49', '2023-01-19 15:56:50', '2023-01-19 15:56:51', '2023-01-19 15:56:52', '2023-01-19 15:56:53', '2023-01-19 15:56:54', '2023-01-19 15:56:55', '2023-01-19 15:56:56', '2023-01-19 15:56:57', '2023-01-19 15:56:58', '2023-01-19 15:56:59', '2023-01-19 15:57:00', '2023-01-19 15:57:01', '2023-01-19 15:57:02', '2023-01-19 15:57:03', '2023-01-19 15:57:04', '2023-01-19 15:57:05', '2023-01-19 15:57:06', '2023-01-19 15:57:07', '2023-01-19 15:57:08', '2023-01-19 15:57:09', '2023-01-19 15:57:10', '2023-01-19 15:57:11', '2023-01-19 15:57:12', '2023-01-19 15:57:13', '2023-01-19 15:57:15', '2023-01-19 15:57:16', '2023-01-19 15:57:17', '2023-01-19 15:57:18', '2023-01-19 15:57:19', '2023-01-19 15:57:20', '2023-01-19 15:57:21', '2023-01-19 15:57:22', '2023-01-19 15:57:23', '2023-01-19 15:57:24', '2023-01-19 15:57:25', '2023-01-19 15:57:26', '2023-01-19 15:57:27', '2023-01-19 15:57:28', '2023-01-19 15:57:29', '2023-01-19 15:57:30', '2023-01-19 15:57:31', '2023-01-19 15:57:32', '2023-01-19 15:57:33', '2023-01-19 15:57:34', '2023-01-19 15:57:35', '2023-01-19 15:57:36', '2023-01-19 15:57:37', '2023-01-19 15:57:38', '2023-01-19 15:57:39', '2023-01-19 15:57:40', '2023-01-19 15:57:41', '2023-01-19 15:57:42', '2023-01-19 15:57:43', '2023-01-19 15:57:44', '2023-01-19 15:57:45', '2023-01-19 15:57:46', '2023-01-19 15:57:47', '2023-01-19 15:57:48', '2023-01-19 15:57:49', '2023-01-19 15:57:50', '2023-01-19 15:57:51', '2023-01-19 15:57:52', '2023-01-19 15:57:53', '2023-01-19 15:57:54', '2023-01-19 15:57:55', '2023-01-19 15:57:57', '2023-01-19 15:57:58', '2023-01-19 15:57:59', '2023-01-19 15:58:00', '2023-01-19 15:58:01', '2023-01-19 15:58:02', '2023-01-19 15:58:03', '2023-01-19 15:58:04', '2023-01-19 15:58:05', '2023-01-19 15:58:06', '2023-01-19 15:58:07', '2023-01-19 15:58:08', '2023-01-19 15:58:09', '2023-01-19 15:58:10', '2023-01-19 15:58:11', '2023-01-19 15:58:12', '2023-01-19 15:58:13', '2023-01-19 15:58:14', '2023-01-19 15:58:15', '2023-01-19 15:58:16', '2023-01-19 15:58:17', '2023-01-19 15:58:18', '2023-01-19 15:58:19', '2023-01-19 15:58:20', '2023-01-19 15:58:21', '2023-01-19 15:58:22', '2023-01-19 15:58:23', '2023-01-19 15:58:24', '2023-01-19 15:58:25', '2023-01-19 15:58:26', '2023-01-19 15:58:27', '2023-01-19 15:58:28', '2023-01-19 15:58:29', '2023-01-19 15:58:30', '2023-01-19 15:58:31', '2023-01-19 15:58:32', '2023-01-19 15:58:33', '2023-01-19 15:58:34', '2023-01-19 15:58:35', '2023-01-19 15:58:36', '2023-01-19 15:58:37', '2023-01-19 15:58:39', '2023-01-19 15:58:40', '2023-01-19 15:58:41', '2023-01-19 15:58:42', '2023-01-19 15:58:43', '2023-01-19 15:58:44', '2023-01-19 15:58:45', '2023-01-19 15:58:46', '2023-01-19 15:58:47', '2023-01-19 15:58:48', '2023-01-19 15:58:49', '2023-01-19 15:58:50', '2023-01-19 15:58:51', '2023-01-19 15:58:52', '2023-01-19 15:58:53', '2023-01-19 15:58:54', '2023-01-19 15:58:55', '2023-01-19 15:58:56', '2023-01-19 15:58:57', '2023-01-19 15:58:58', '2023-01-19 15:58:59', '2023-01-19 15:59:00', '2023-01-19 15:59:01', '2023-01-19 15:59:02', '2023-01-19 15:59:03', '2023-01-19 15:59:04', '2023-01-19 15:59:05', '2023-01-19 15:59:06', '2023-01-19 15:59:07', '2023-01-19 15:59:08', '2023-01-19 15:59:09', '2023-01-19 15:59:10', '2023-01-19 15:59:11', '2023-01-19 15:59:12', '2023-01-19 15:59:13', '2023-01-19 15:59:14', '2023-01-19 15:59:15', '2023-01-19 15:59:16', '2023-01-19 15:59:17', '2023-01-19 15:59:18', '2023-01-19 15:59:19', '2023-01-19 15:59:21', '2023-01-19 15:59:22', '2023-01-19 15:59:23', '2023-01-19 15:59:24', '2023-01-19 15:59:25', '2023-01-19 15:59:26', '2023-01-19 15:59:27', '2023-01-19 15:59:28', '2023-01-19 15:59:29', '2023-01-19 15:59:30', '2023-01-19 15:59:31', '2023-01-19 15:59:32', '2023-01-19 15:59:33', '2023-01-19 15:59:34', '2023-01-19 15:59:35', '2023-01-19 15:59:36', '2023-01-19 15:59:37', '2023-01-19 15:59:38', '2023-01-19 15:59:39', '2023-01-19 15:59:40', '2023-01-19 15:59:41', '2023-01-19 15:59:42', '2023-01-19 15:59:43', '2023-01-19 15:59:44', '2023-01-19 15:59:45', '2023-01-19 15:59:46', '2023-01-19 15:59:47', '2023-01-19 15:59:48', '2023-01-19 15:59:49', '2023-01-19 15:59:50', '2023-01-19 15:59:51', '2023-01-19 15:59:52', '2023-01-19 15:59:53', '2023-01-19 15:59:54', '2023-01-19 15:59:55', '2023-01-19 15:59:56', '2023-01-19 15:59:57', '2023-01-19 15:59:58', '2023-01-19 15:59:59', '2023-01-19 16:00:00', '2023-01-19 16:00:01', '2023-01-19 16:00:03', '2023-01-19 16:00:04', '2023-01-19 16:00:05', '2023-01-19 16:00:06', '2023-01-19 16:00:07', '2023-01-19 16:00:08', '2023-01-19 16:00:09', '2023-01-19 16:00:10', '2023-01-19 16:00:11', '2023-01-19 16:00:12', '2023-01-19 16:00:13', '2023-01-19 16:00:14', '2023-01-19 16:00:15', '2023-01-19 16:00:16', '2023-01-19 16:00:17', '2023-01-19 16:00:18', '2023-01-19 16:00:19', '2023-01-19 16:00:20', '2023-01-19 16:00:21', '2023-01-19 16:00:22', '2023-01-19 16:00:23', '2023-01-19 16:00:24', '2023-01-19 16:00:25', '2023-01-19 16:00:26', '2023-01-19 16:00:27', '2023-01-19 16:00:28', '2023-01-19 16:00:29', '2023-01-19 16:00:30', '2023-01-19 16:00:31', '2023-01-19 16:00:32', '2023-01-19 16:00:33', '2023-01-19 16:00:34', '2023-01-19 16:00:35', '2023-01-19 16:00:36', '2023-01-19 16:00:37', '2023-01-19 16:00:38', '2023-01-19 16:00:39', '2023-01-19 16:00:40', '2023-01-19 16:00:41', '2023-01-19 16:00:42', '2023-01-19 16:00:43', '2023-01-19 16:00:45', '2023-01-19 16:00:46', '2023-01-19 16:00:47', '2023-01-19 16:00:48', '2023-01-19 16:00:49', '2023-01-19 16:00:50', '2023-01-19 16:00:51', '2023-01-19 16:00:52', '2023-01-19 16:00:53', '2023-01-19 16:00:54', '2023-01-19 16:00:55', '2023-01-19 16:00:56', '2023-01-19 16:00:57', '2023-01-19 16:00:58', '2023-01-19 16:00:59', '2023-01-19 16:01:00', '2023-01-19 16:01:01', '2023-01-19 16:01:02', '2023-01-19 16:01:03', '2023-01-19 16:01:04', '2023-01-19 16:01:05', '2023-01-19 16:01:06', '2023-01-19 16:01:07', '2023-01-19 16:01:08', '2023-01-19 16:01:09', '2023-01-19 16:01:10', '2023-01-19 16:01:11', '2023-01-19 16:01:12', '2023-01-19 16:01:13', '2023-01-19 16:01:14', '2023-01-19 16:01:15', '2023-01-19 16:01:16', '2023-01-19 16:01:17', '2023-01-19 16:01:18', '2023-01-19 16:01:19', '2023-01-19 16:01:20', '2023-01-19 16:01:21', '2023-01-19 16:01:22', '2023-01-19 16:01:23', '2023-01-19 16:01:24', '2023-01-19 16:01:26', '2023-01-19 16:01:27', '2023-01-19 16:01:28', '2023-01-19 16:01:29', '2023-01-19 16:01:30', '2023-01-19 16:01:31', '2023-01-19 16:01:32', '2023-01-19 16:01:33', '2023-01-19 16:01:34', '2023-01-19 16:01:35', '2023-01-19 16:01:36', '2023-01-19 16:01:37', '2023-01-19 16:01:38', '2023-01-19 16:01:39', '2023-01-19 16:01:40', '2023-01-19 16:01:41', '2023-01-19 16:01:42', '2023-01-19 16:01:43', '2023-01-19 16:01:44', '2023-01-19 16:01:45', '2023-01-19 16:01:46', '2023-01-19 16:01:47', '2023-01-19 16:01:48', '2023-01-19 16:01:49', '2023-01-19 16:01:50', '2023-01-19 16:01:51', '2023-01-19 16:01:52', '2023-01-19 16:01:53', '2023-01-19 16:01:54', '2023-01-19 16:01:55', '2023-01-19 16:01:56', '2023-01-19 16:01:57', '2023-01-19 16:01:58', '2023-01-19 16:01:59', '2023-01-19 16:02:00', '2023-01-19 16:02:01', '2023-01-19 16:02:02', '2023-01-19 16:02:03', '2023-01-19 16:02:04', '2023-01-19 16:02:05', '2023-01-19 16:02:06', '2023-01-19 16:02:08', '2023-01-19 16:02:09', '2023-01-19 16:02:10', '2023-01-19 16:02:11', '2023-01-19 16:02:12', '2023-01-19 16:02:13', '2023-01-19 16:02:14', '2023-01-19 16:02:15', '2023-01-19 16:02:16', '2023-01-19 16:02:17', '2023-01-19 16:02:18', '2023-01-19 16:02:19', '2023-01-19 16:02:20', '2023-01-19 16:02:21', '2023-01-19 16:02:22', '2023-01-19 16:02:23', '2023-01-19 16:02:24', '2023-01-19 16:02:25', '2023-01-19 16:02:26', '2023-01-19 16:02:27', '2023-01-19 16:02:28', '2023-01-19 16:02:29', '2023-01-19 16:02:30', '2023-01-19 16:02:31', '2023-01-19 16:02:32', '2023-01-19 16:02:33', '2023-01-19 16:02:34', '2023-01-19 16:02:35', '2023-01-19 16:02:36', '2023-01-19 16:02:37', '2023-01-19 16:02:38', '2023-01-19 16:02:39', '2023-01-19 16:02:40', '2023-01-19 16:02:41', '2023-01-19 16:02:42', '2023-01-19 16:02:43', '2023-01-19 16:02:44', '2023-01-19 16:02:45', '2023-01-19 16:02:46', '2023-01-19 16:02:47', '2023-01-19 16:02:48', '2023-01-19 16:02:50', '2023-01-19 16:02:51', '2023-01-19 16:02:52', '2023-01-19 16:02:53', '2023-01-19 16:02:54', '2023-01-19 16:02:55', '2023-01-19 16:02:56', '2023-01-19 16:02:57', '2023-01-19 16:02:58', '2023-01-19 16:02:59', '2023-01-19 16:03:00', '2023-01-19 16:03:01', '2023-01-19 16:03:02', '2023-01-19 16:03:03', '2023-01-19 16:03:04', '2023-01-19 16:03:05', '2023-01-19 16:03:06', '2023-01-19 16:03:07', '2023-01-19 16:03:08', '2023-01-19 16:03:09', '2023-01-19 16:03:10', '2023-01-19 16:03:11', '2023-01-19 16:03:12', '2023-01-19 16:03:13', '2023-01-19 16:03:14', '2023-01-19 16:03:15', '2023-01-19 16:03:16', '2023-01-19 16:03:17', '2023-01-19 16:03:18', '2023-01-19 16:03:19', '2023-01-19 16:03:20', '2023-01-19 16:03:21', '2023-01-19 16:03:22', '2023-01-19 16:03:23', '2023-01-19 16:03:24', '2023-01-19 16:03:25', '2023-01-19 16:03:26', '2023-01-19 16:03:27', '2023-01-19 16:03:28', '2023-01-19 16:03:29', '2023-01-19 16:03:30', '2023-01-19 16:03:32', '2023-01-19 16:03:33', '2023-01-19 16:03:34', '2023-01-19 16:03:35', '2023-01-19 16:03:36', '2023-01-19 16:03:37', '2023-01-19 16:03:38', '2023-01-19 16:03:39', '2023-01-19 16:03:40', '2023-01-19 16:03:41', '2023-01-19 16:03:42', '2023-01-19 16:03:43', '2023-01-19 16:03:44', '2023-01-19 16:03:45', '2023-01-19 16:03:46', '2023-01-19 16:03:47', '2023-01-19 16:03:48', '2023-01-19 16:03:49', '2023-01-19 16:03:50', '2023-01-19 16:03:51', '2023-01-19 16:03:52', '2023-01-19 16:03:53', '2023-01-19 16:03:54', '2023-01-19 16:03:55', '2023-01-19 16:03:56', '2023-01-19 16:03:57', '2023-01-19 16:03:58', '2023-01-19 16:03:59', '2023-01-19 16:04:00', '2023-01-19 16:04:01', '2023-01-19 16:04:02', '2023-01-19 16:04:03', '2023-01-19 16:04:04', '2023-01-19 16:04:05', '2023-01-19 16:04:06', '2023-01-19 16:04:07', '2023-01-19 16:04:08', '2023-01-19 16:04:09', '2023-01-19 16:04:10', '2023-01-19 16:04:11', '2023-01-19 16:04:12', '2023-01-19 16:04:14', '2023-01-19 16:04:15', '2023-01-19 16:04:16', '2023-01-19 16:04:17', '2023-01-19 16:04:18', '2023-01-19 16:04:19', '2023-01-19 16:04:20', '2023-01-19 16:04:21', '2023-01-19 16:04:22', '2023-01-19 16:04:23', '2023-01-19 16:04:24', '2023-01-19 16:04:25', '2023-01-19 16:04:26', '2023-01-19 16:04:27', '2023-01-19 16:04:28', '2023-01-19 16:04:29', '2023-01-19 16:04:30', '2023-01-19 16:04:31', '2023-01-19 16:04:32', '2023-01-19 16:04:33', '2023-01-19 16:04:34', '2023-01-19 16:04:35', '2023-01-19 16:04:36', '2023-01-19 16:04:37', '2023-01-19 16:04:38', '2023-01-19 16:04:39', '2023-01-19 16:04:40', '2023-01-19 16:04:41', '2023-01-19 16:04:42', '2023-01-19 16:04:43', '2023-01-19 16:04:44', '2023-01-19 16:04:45', '2023-01-19 16:04:46', '2023-01-19 16:04:47', '2023-01-19 16:04:48', '2023-01-19 16:04:49', '2023-01-19 16:04:50', '2023-01-19 16:04:51', '2023-01-19 16:04:52', '2023-01-19 16:04:53', '2023-01-19 16:04:54', '2023-01-19 16:04:56', '2023-01-19 16:04:57', '2023-01-19 16:04:58', '2023-01-19 16:04:59', '2023-01-19 16:05:00', '2023-01-19 16:05:01', '2023-01-19 16:05:02', '2023-01-19 16:05:03', '2023-01-19 16:05:04', '2023-01-19 16:05:05', '2023-01-19 16:05:06', '2023-01-19 16:05:07', '2023-01-19 16:05:08', '2023-01-19 16:05:09', '2023-01-19 16:05:10', '2023-01-19 16:05:11', '2023-01-19 16:05:12', '2023-01-19 16:05:13', '2023-01-19 16:05:14', '2023-01-19 16:05:15', '2023-01-19 16:05:16', '2023-01-19 16:05:17', '2023-01-19 16:05:18', '2023-01-19 16:05:19', '2023-01-19 16:05:20', '2023-01-19 16:05:21', '2023-01-19 16:05:22', '2023-01-19 16:05:23', '2023-01-19 16:05:24', '2023-01-19 16:05:25', '2023-01-19 16:05:26', '2023-01-19 16:05:27', '2023-01-19 16:05:28', '2023-01-19 16:05:29', '2023-01-19 16:05:30', '2023-01-19 16:05:31', '2023-01-19 16:05:32', '2023-01-19 16:05:33', '2023-01-19 16:05:34', '2023-01-19 16:05:35', '2023-01-19 16:05:36', '2023-01-19 16:05:38', '2023-01-19 16:05:39', '2023-01-19 16:05:40', '2023-01-19 16:05:41', '2023-01-19 16:05:42', '2023-01-19 16:05:43', '2023-01-19 16:05:44', '2023-01-19 16:05:45', '2023-01-19 16:05:46', '2023-01-19 16:05:47', '2023-01-19 16:05:48', '2023-01-19 16:05:49', '2023-01-19 16:05:50', '2023-01-19 16:05:51', '2023-01-19 16:05:52', '2023-01-19 16:05:53', '2023-01-19 16:05:54', '2023-01-19 16:05:55', '2023-01-19 16:05:56', '2023-01-19 16:05:57', '2023-01-19 16:05:58', '2023-01-19 16:05:59', '2023-01-19 16:06:00', '2023-01-19 16:06:01', '2023-01-19 16:06:02', '2023-01-19 16:06:03', '2023-01-19 16:06:04', '2023-01-19 16:06:05', '2023-01-19 16:06:06', '2023-01-19 16:06:07', '2023-01-19 16:06:08', '2023-01-19 16:06:09', '2023-01-19 16:06:10', '2023-01-19 16:06:11', '2023-01-19 16:06:12', '2023-01-19 16:06:13', '2023-01-19 16:06:14', '2023-01-19 16:06:15', '2023-01-19 16:06:16', '2023-01-19 16:06:17', '2023-01-19 16:06:19', '2023-01-19 16:06:20', '2023-01-19 16:06:21', '2023-01-19 16:06:22', '2023-01-19 16:06:23', '2023-01-19 16:06:24', '2023-01-19 16:06:25', '2023-01-19 16:06:26', '2023-01-19 16:06:27', '2023-01-19 16:06:28', '2023-01-19 16:06:29', '2023-01-19 16:06:30', '2023-01-19 16:06:31', '2023-01-19 16:06:32', '2023-01-19 16:06:33', '2023-01-19 16:06:34', '2023-01-19 16:06:35', '2023-01-19 16:06:36', '2023-01-19 16:06:37', '2023-01-19 16:06:38', '2023-01-19 16:06:39', '2023-01-19 16:06:40', '2023-01-19 16:06:41', '2023-01-19 16:06:42', '2023-01-19 16:06:43', '2023-01-19 16:06:44', '2023-01-19 16:06:45', '2023-01-19 16:06:46', '2023-01-19 16:06:47', '2023-01-19 16:06:48', '2023-01-19 16:06:49', '2023-01-19 16:06:50', '2023-01-19 16:06:51', '2023-01-19 16:06:52', '2023-01-19 16:06:53', '2023-01-19 16:06:54', '2023-01-19 16:06:55', '2023-01-19 16:06:56', '2023-01-19 16:06:57', '2023-01-19 16:06:58', '2023-01-19 16:06:59', '2023-01-19 16:07:01', '2023-01-19 16:07:02', '2023-01-19 16:07:03', '2023-01-19 16:07:04', '2023-01-19 16:07:05', '2023-01-19 16:07:06', '2023-01-19 16:07:07', '2023-01-19 16:07:08', '2023-01-19 16:07:09', '2023-01-19 16:07:10', '2023-01-19 16:07:11', '2023-01-19 16:07:12', '2023-01-19 16:07:13', '2023-01-19 16:07:14', '2023-01-19 16:07:15', '2023-01-19 16:07:16', '2023-01-19 16:07:17', '2023-01-19 16:07:18', '2023-01-19 16:07:19', '2023-01-19 16:07:20', '2023-01-19 16:07:21', '2023-01-19 16:07:22', '2023-01-19 16:07:23', '2023-01-19 16:07:24', '2023-01-19 16:07:25', '2023-01-19 16:07:26', '2023-01-19 16:07:27', '2023-01-19 16:07:28', '2023-01-19 16:07:29', '2023-01-19 16:07:30', '2023-01-19 16:07:31', '2023-01-19 16:07:32', '2023-01-19 16:07:33', '2023-01-19 16:07:34', '2023-01-19 16:07:35', '2023-01-19 16:07:36', '2023-01-19 16:07:37', '2023-01-19 16:07:38', '2023-01-19 16:07:39', '2023-01-19 16:07:40', '2023-01-19 16:07:41', '2023-01-19 16:07:43', '2023-01-19 16:07:44', '2023-01-19 16:07:45', '2023-01-19 16:07:46', '2023-01-19 16:07:47', '2023-01-19 16:07:48', '2023-01-19 16:07:49', '2023-01-19 16:07:50', '2023-01-19 16:07:51', '2023-01-19 16:07:52', '2023-01-19 16:07:53', '2023-01-19 16:07:54', '2023-01-19 16:07:55', '2023-01-19 16:07:56', '2023-01-19 16:07:57', '2023-01-19 16:07:58', '2023-01-19 16:07:59', '2023-01-19 16:08:00', '2023-01-19 16:08:01', '2023-01-19 16:08:02', '2023-01-19 16:08:03', '2023-01-19 16:08:04', '2023-01-19 16:08:05', '2023-01-19 16:08:06', '2023-01-19 16:08:07', '2023-01-19 16:08:08', '2023-01-19 16:08:09', '2023-01-19 16:08:10', '2023-01-19 16:08:11', '2023-01-19 16:08:12', '2023-01-19 16:08:13', '2023-01-19 16:08:14', '2023-01-19 16:08:15', '2023-01-19 16:08:16', '2023-01-19 16:08:17', '2023-01-19 16:08:18', '2023-01-19 16:08:19', '2023-01-19 16:08:20', '2023-01-19 16:08:21', '2023-01-19 16:08:22', '2023-01-19 16:08:23', '2023-01-19 16:08:25', '2023-01-19 16:08:26', '2023-01-19 16:08:27', '2023-01-19 16:08:28', '2023-01-19 16:08:29', '2023-01-19 16:08:30', '2023-01-19 16:08:31', '2023-01-19 16:08:32', '2023-01-19 16:08:33', '2023-01-19 16:08:34', '2023-01-19 16:08:35', '2023-01-19 16:08:36', '2023-01-19 16:08:37', '2023-01-19 16:08:38', '2023-01-19 16:08:39', '2023-01-19 16:08:40', '2023-01-19 16:08:41', '2023-01-19 16:08:42', '2023-01-19 16:08:43', '2023-01-19 16:08:44', '2023-01-19 16:08:45', '2023-01-19 16:08:46', '2023-01-19 16:08:47', '2023-01-19 16:08:48', '2023-01-19 16:08:49', '2023-01-19 16:08:50', '2023-01-19 16:08:51', '2023-01-19 16:08:52', '2023-01-19 16:08:53', '2023-01-19 16:08:54', '2023-01-19 16:08:55', '2023-01-19 16:08:56', '2023-01-19 16:08:57', '2023-01-19 16:08:58', '2023-01-19 16:08:59', '2023-01-19 16:09:00', '2023-01-19 16:09:01', '2023-01-19 16:09:02', '2023-01-19 16:09:03', '2023-01-19 16:09:04', '2023-01-19 16:09:05', '2023-01-19 16:09:07', '2023-01-19 16:09:08', '2023-01-19 16:09:09', '2023-01-19 16:09:10', '2023-01-19 16:09:11', '2023-01-19 16:09:12', '2023-01-19 16:09:13', '2023-01-19 16:09:14', '2023-01-19 16:09:15', '2023-01-19 16:09:16', '2023-01-19 16:09:17', '2023-01-19 16:09:18', '2023-01-19 16:09:19', '2023-01-19 16:09:20', '2023-01-19 16:09:21', '2023-01-19 16:09:22', '2023-01-19 16:09:23', '2023-01-19 16:09:24', '2023-01-19 16:09:25', '2023-01-19 16:09:26', '2023-01-19 16:09:27', '2023-01-19 16:09:28', '2023-01-19 16:09:29', '2023-01-19 16:09:30', '2023-01-19 16:09:31', '2023-01-19 16:09:32', '2023-01-19 16:09:33', '2023-01-19 16:09:34', '2023-01-19 16:09:35', '2023-01-19 16:09:36', '2023-01-19 16:09:37', '2023-01-19 16:09:38', '2023-01-19 16:09:39', '2023-01-19 16:09:40', '2023-01-19 16:09:41', '2023-01-19 16:09:42', '2023-01-19 16:09:43', '2023-01-19 16:09:44', '2023-01-19 16:09:45', '2023-01-19 16:09:46', '2023-01-19 16:09:47', '2023-01-19 16:09:49', '2023-01-19 16:09:50', '2023-01-19 16:09:51', '2023-01-19 16:09:52', '2023-01-19 16:09:53', '2023-01-19 16:09:54', '2023-01-19 16:09:55', '2023-01-19 16:09:56', '2023-01-19 16:09:57', '2023-01-19 16:09:58', '2023-01-19 16:09:59', '2023-01-19 16:10:00', '2023-01-19 16:10:01', '2023-01-19 16:10:02', '2023-01-19 16:10:03', '2023-01-19 16:10:04', '2023-01-19 16:10:05', '2023-01-19 16:10:06', '2023-01-19 16:10:07', '2023-01-19 16:10:08', '2023-01-19 16:10:09', '2023-01-19 16:10:10', '2023-01-19 16:10:11', '2023-01-19 16:10:12', '2023-01-19 16:10:13', '2023-01-19 16:10:14', '2023-01-19 16:10:15', '2023-01-19 16:10:16', '2023-01-19 16:10:17', '2023-01-19 16:10:18', '2023-01-19 16:10:19', '2023-01-19 16:10:20', '2023-01-19 16:10:21', '2023-01-19 16:10:22', '2023-01-19 16:10:23', '2023-01-19 16:10:24', '2023-01-19 16:10:25', '2023-01-19 16:10:26', '2023-01-19 16:10:27', '2023-01-19 16:10:28', '2023-01-19 16:10:29', '2023-01-19 16:10:31', '2023-01-19 16:10:32', '2023-01-19 16:10:33', '2023-01-19 16:10:34', '2023-01-19 16:10:35', '2023-01-19 16:10:36', '2023-01-19 16:10:37', '2023-01-19 16:10:38', '2023-01-19 16:10:39', '2023-01-19 16:10:40', '2023-01-19 16:10:41', '2023-01-19 16:10:42', '2023-01-19 16:10:43', '2023-01-19 16:10:44', '2023-01-19 16:10:45', '2023-01-19 16:10:46', '2023-01-19 16:10:47', '2023-01-19 16:10:48', '2023-01-19 16:10:49', '2023-01-19 16:10:50', '2023-01-19 16:10:51', '2023-01-19 16:10:52', '2023-01-19 16:10:53', '2023-01-19 16:10:54', '2023-01-19 16:10:55', '2023-01-19 16:10:56', '2023-01-19 16:10:57', '2023-01-19 16:10:58', '2023-01-19 16:10:59', '2023-01-19 16:11:00', '2023-01-19 16:11:01', '2023-01-19 16:11:02', '2023-01-19 16:11:03', '2023-01-19 16:11:04', '2023-01-19 16:11:05', '2023-01-19 16:11:06', '2023-01-19 16:11:07', '2023-01-19 16:11:08', '2023-01-19 16:11:09', '2023-01-19 16:11:10', '2023-01-19 16:11:11', '2023-01-19 16:11:13', '2023-01-19 16:11:14', '2023-01-19 16:11:15', '2023-01-19 16:11:16', '2023-01-19 16:11:17', '2023-01-19 16:11:18', '2023-01-19 16:11:19', '2023-01-19 16:11:20', '2023-01-19 16:11:21', '2023-01-19 16:11:22', '2023-01-19 16:11:23', '2023-01-19 16:11:24', '2023-01-19 16:11:25', '2023-01-19 16:11:26', '2023-01-19 16:11:27', '2023-01-19 16:11:28', '2023-01-19 16:11:29', '2023-01-19 16:11:30', '2023-01-19 16:11:31', '2023-01-19 16:11:32', '2023-01-19 16:11:33', '2023-01-19 16:11:34', '2023-01-19 16:11:35', '2023-01-19 16:11:36', '2023-01-19 16:11:37', '2023-01-19 16:11:38', '2023-01-19 16:11:39', '2023-01-19 16:11:40', '2023-01-19 16:11:41', '2023-01-19 16:11:42', '2023-01-19 16:11:43', '2023-01-19 16:11:44', '2023-01-19 16:11:45', '2023-01-19 16:11:46', '2023-01-19 16:11:47', '2023-01-19 16:11:48', '2023-01-19 16:11:49', '2023-01-19 16:11:50', '2023-01-19 16:11:51', '2023-01-19 16:11:52', '2023-01-19 16:11:54', '2023-01-19 16:11:55', '2023-01-19 16:11:56', '2023-01-19 16:11:57', '2023-01-19 16:11:58', '2023-01-19 16:11:59', '2023-01-19 16:12:00', '2023-01-19 16:12:01', '2023-01-19 16:12:02', '2023-01-19 16:12:03', '2023-01-19 16:12:04', '2023-01-19 16:12:05', '2023-01-19 16:12:06', '2023-01-19 16:12:07', '2023-01-19 16:12:08', '2023-01-19 16:12:09', '2023-01-19 16:12:10', '2023-01-19 16:12:11', '2023-01-19 16:12:12', '2023-01-19 16:12:13', '2023-01-19 16:12:14', '2023-01-19 16:12:15', '2023-01-19 16:12:16', '2023-01-19 16:12:17', '2023-01-19 16:12:18', '2023-01-19 16:12:19', '2023-01-19 16:12:20', '2023-01-19 16:12:21', '2023-01-19 16:12:22', '2023-01-19 16:12:23', '2023-01-19 16:12:24', '2023-01-19 16:12:25', '2023-01-19 16:12:26', '2023-01-19 16:12:27', '2023-01-19 16:12:28', '2023-01-19 16:12:29', '2023-01-19 16:12:30', '2023-01-19 16:12:31', '2023-01-19 16:12:32', '2023-01-19 16:12:33', '2023-01-19 16:12:34', '2023-01-19 16:12:36', '2023-01-19 16:12:37', '2023-01-19 16:12:38', '2023-01-19 16:12:39', '2023-01-19 16:12:40', '2023-01-19 16:12:41', '2023-01-19 16:12:42', '2023-01-19 16:12:43', '2023-01-19 16:12:44', '2023-01-19 16:12:45', '2023-01-19 16:12:46', '2023-01-19 16:12:47', '2023-01-19 16:12:48', '2023-01-19 16:12:49', '2023-01-19 16:12:50', '2023-01-19 16:12:51', '2023-01-19 16:12:52', '2023-01-19 16:12:53', '2023-01-19 16:12:54', '2023-01-19 16:12:55', '2023-01-19 16:12:56', '2023-01-19 16:12:57', '2023-01-19 16:12:58', '2023-01-19 16:12:59', '2023-01-19 16:13:00', '2023-01-19 16:13:01', '2023-01-19 16:13:02', '2023-01-19 16:13:03', '2023-01-19 16:13:04', '2023-01-19 16:13:05', '2023-01-19 16:13:06', '2023-01-19 16:13:07', '2023-01-19 16:13:08', '2023-01-19 16:13:09', '2023-01-19 16:13:10', '2023-01-19 16:13:11', '2023-01-19 16:13:12', '2023-01-19 16:13:13', '2023-01-19 16:13:14', '2023-01-19 16:13:15', '2023-01-19 16:13:16', '2023-01-19 16:13:18', '2023-01-19 16:13:19', '2023-01-19 16:13:20', '2023-01-19 16:13:21', '2023-01-19 16:13:22', '2023-01-19 16:13:23', '2023-01-19 16:13:24', '2023-01-19 16:13:25', '2023-01-19 16:13:26', '2023-01-19 16:13:27', '2023-01-19 16:13:28', '2023-01-19 16:13:29', '2023-01-19 16:13:30', '2023-01-19 16:13:31', '2023-01-19 16:13:32', '2023-01-19 16:13:33', '2023-01-19 16:13:34', '2023-01-19 16:13:35', '2023-01-19 16:13:36', '2023-01-19 16:13:37', '2023-01-19 16:13:38', '2023-01-19 16:13:39', '2023-01-19 16:13:40', '2023-01-19 16:13:41', '2023-01-19 16:13:42', '2023-01-19 16:13:43', '2023-01-19 16:13:44', '2023-01-19 16:13:45', '2023-01-19 16:13:46', '2023-01-19 16:13:47', '2023-01-19 16:13:48', '2023-01-19 16:13:49', '2023-01-19 16:13:50', '2023-01-19 16:13:51', '2023-01-19 16:13:52', '2023-01-19 16:13:53', '2023-01-19 16:13:54', '2023-01-19 16:13:55', '2023-01-19 16:13:56', '2023-01-19 16:13:57', '2023-01-19 16:13:58', '2023-01-19 16:14:00', '2023-01-19 16:14:01', '2023-01-19 16:14:02', '2023-01-19 16:14:03', '2023-01-19 16:14:05', '2023-01-19 16:14:06', '2023-01-19 16:14:07', '2023-01-19 16:14:08', '2023-01-19 16:14:09', '2023-01-19 16:14:10', '2023-01-19 16:14:11', '2023-01-19 16:14:12', '2023-01-19 16:14:13', '2023-01-19 16:14:14', '2023-01-19 16:14:15', '2023-01-19 16:14:16', '2023-01-19 16:14:17', '2023-01-19 16:14:18', '2023-01-19 16:14:19', '2023-01-19 16:14:20', '2023-01-19 16:14:21', '2023-01-19 16:14:22', '2023-01-19 16:14:23', '2023-01-19 16:14:24', '2023-01-19 16:14:25', '2023-01-19 16:14:26', '2023-01-19 16:14:27', '2023-01-19 16:14:28', '2023-01-19 16:14:29', '2023-01-19 16:14:30', '2023-01-19 16:14:31', '2023-01-19 16:14:32', '2023-01-19 16:14:33', '2023-01-19 16:14:34', '2023-01-19 16:14:35', '2023-01-19 16:14:36', '2023-01-19 16:14:37', '2023-01-19 16:14:38', '2023-01-19 16:14:39', '2023-01-19 16:14:40', '2023-01-19 16:14:42', '2023-01-19 16:14:43', '2023-01-19 16:14:44', '2023-01-19 16:14:45', '2023-01-19 16:14:46', '2023-01-19 16:14:47', '2023-01-19 16:14:48', '2023-01-19 16:14:49', '2023-01-19 16:14:50', '2023-01-19 16:14:51', '2023-01-19 16:14:52', '2023-01-19 16:14:53', '2023-01-19 16:14:54', '2023-01-19 16:14:55', '2023-01-19 16:14:56', '2023-01-19 16:14:57', '2023-01-19 16:14:58', '2023-01-19 16:14:59', '2023-01-19 16:15:00', '2023-01-19 16:15:01', '2023-01-19 16:15:02', '2023-01-19 16:15:03', '2023-01-19 16:15:04', '2023-01-19 16:15:05', '2023-01-19 16:15:06', '2023-01-19 16:15:07', '2023-01-19 16:15:08', '2023-01-19 16:15:09', '2023-01-19 16:15:10', '2023-01-19 16:15:11', '2023-01-19 16:15:12', '2023-01-19 16:15:13', '2023-01-19 16:15:14', '2023-01-19 16:15:15', '2023-01-19 16:15:16', '2023-01-19 16:15:17', '2023-01-19 16:15:18', '2023-01-19 16:15:19', '2023-01-19 16:15:20', '2023-01-19 16:15:21', '2023-01-19 16:15:22', '2023-01-19 16:15:24', '2023-01-19 16:15:25', '2023-01-19 16:15:26', '2023-01-19 16:15:27', '2023-01-19 16:15:28', '2023-01-19 16:15:29', '2023-01-19 16:15:30', '2023-01-19 16:15:31', '2023-01-19 16:15:32', '2023-01-19 16:15:33', '2023-01-19 16:15:34', '2023-01-19 16:15:35', '2023-01-19 16:15:36', '2023-01-19 16:15:37', '2023-01-19 16:15:38', '2023-01-19 16:15:39', '2023-01-19 16:15:40', '2023-01-19 16:15:41', '2023-01-19 16:15:42', '2023-01-19 16:15:43', '2023-01-19 16:15:44', '2023-01-19 16:15:45', '2023-01-19 16:15:46', '2023-01-19 16:15:47', '2023-01-19 16:15:48', '2023-01-19 16:15:49', '2023-01-19 16:15:50', '2023-01-19 16:15:51', '2023-01-19 16:15:52', '2023-01-19 16:15:53', '2023-01-19 16:15:54', '2023-01-19 16:15:55', '2023-01-19 16:15:56', '2023-01-19 16:15:57', '2023-01-19 16:15:58', '2023-01-19 16:15:59', '2023-01-19 16:16:00', '2023-01-19 16:16:01', '2023-01-19 16:16:02', '2023-01-19 16:16:03', '2023-01-19 16:16:04', '2023-01-19 16:16:06', '2023-01-19 16:16:07', '2023-01-19 16:16:08', '2023-01-19 16:16:09', '2023-01-19 16:16:10', '2023-01-19 16:16:11', '2023-01-19 16:16:12', '2023-01-19 16:16:13', '2023-01-19 16:16:14', '2023-01-19 16:16:15', '2023-01-19 16:16:16', '2023-01-19 16:16:17', '2023-01-19 16:16:18', '2023-01-19 16:16:19', '2023-01-19 16:16:20', '2023-01-19 16:16:21', '2023-01-19 16:16:22', '2023-01-19 16:16:23', '2023-01-19 16:16:24', '2023-01-19 16:16:25', '2023-01-19 16:16:26', '2023-01-19 16:16:27', '2023-01-19 16:16:28', '2023-01-19 16:16:29', '2023-01-19 16:16:30', '2023-01-19 16:16:31', '2023-01-19 16:16:32', '2023-01-19 16:16:33', '2023-01-19 16:16:34', '2023-01-19 16:16:35', '2023-01-19 16:16:36', '2023-01-19 16:16:37', '2023-01-19 16:16:38', '2023-01-19 16:16:39', '2023-01-19 16:16:40', '2023-01-19 16:16:41', '2023-01-19 16:16:42', '2023-01-19 16:16:43', '2023-01-19 16:16:44', '2023-01-19 16:16:45', '2023-01-19 16:16:46', '2023-01-19 16:16:48', '2023-01-19 16:16:49', '2023-01-19 16:16:50', '2023-01-19 16:16:51', '2023-01-19 16:16:52', '2023-01-19 16:16:53', '2023-01-19 16:16:54', '2023-01-19 16:16:55', '2023-01-19 16:16:56', '2023-01-19 16:16:57', '2023-01-19 16:16:58', '2023-01-19 16:16:59', '2023-01-19 16:17:00', '2023-01-19 16:17:01', '2023-01-19 16:17:02', '2023-01-19 16:17:03', '2023-01-19 16:17:04', '2023-01-19 16:17:05', '2023-01-19 16:17:06', '2023-01-19 16:17:07', '2023-01-19 16:17:08', '2023-01-19 16:17:09', '2023-01-19 16:17:10', '2023-01-19 16:17:11', '2023-01-19 16:17:12', '2023-01-19 16:17:13', '2023-01-19 16:17:14', '2023-01-19 16:17:15', '2023-01-19 16:17:16', '2023-01-19 16:17:17', '2023-01-19 16:17:18', '2023-01-19 16:17:19', '2023-01-19 16:17:20', '2023-01-19 16:17:21', '2023-01-19 16:17:22', '2023-01-19 16:17:23', '2023-01-19 16:17:24', '2023-01-19 16:17:25', '2023-01-19 16:17:26', '2023-01-19 16:17:27', '2023-01-19 16:17:28', '2023-01-19 16:17:30', '2023-01-19 16:17:31', '2023-01-19 16:17:32', '2023-01-19 16:17:33', '2023-01-19 16:17:34', '2023-01-19 16:17:35', '2023-01-19 16:17:36', '2023-01-19 16:17:37', '2023-01-19 16:17:38', '2023-01-19 16:17:39', '2023-01-19 16:17:40', '2023-01-19 16:17:41', '2023-01-19 16:17:42', '2023-01-19 16:17:43', '2023-01-19 16:17:44', '2023-01-19 16:17:45', '2023-01-19 16:17:46', '2023-01-19 16:17:47', '2023-01-19 16:17:48', '2023-01-19 16:17:49', '2023-01-19 16:17:50', '2023-01-19 16:17:51', '2023-01-19 16:17:52', '2023-01-19 16:17:53', '2023-01-19 16:17:54', '2023-01-19 16:17:55', '2023-01-19 16:17:56', '2023-01-19 16:17:57', '2023-01-19 16:17:58', '2023-01-19 16:17:59', '2023-01-19 16:18:00', '2023-01-19 16:18:01', '2023-01-19 16:18:02', '2023-01-19 16:18:03', '2023-01-19 16:18:04', '2023-01-19 16:18:05', '2023-01-19 16:18:06', '2023-01-19 16:18:07', '2023-01-19 16:18:08', '2023-01-19 16:18:09', '2023-01-19 16:18:11', '2023-01-19 16:18:12', '2023-01-19 16:18:13', '2023-01-19 16:18:14', '2023-01-19 16:18:15', '2023-01-19 16:18:16', '2023-01-19 16:18:17', '2023-01-19 16:18:18', '2023-01-19 16:18:19', '2023-01-19 16:18:20', '2023-01-19 16:18:21', '2023-01-19 16:18:22', '2023-01-19 16:18:23', '2023-01-19 16:18:24', '2023-01-19 16:18:25', '2023-01-19 16:18:26', '2023-01-19 16:18:27', '2023-01-19 16:18:28', '2023-01-19 16:18:29', '2023-01-19 16:18:30', '2023-01-19 16:18:31', '2023-01-19 16:18:32', '2023-01-19 16:18:33', '2023-01-19 16:18:34', '2023-01-19 16:18:35', '2023-01-19 16:18:36', '2023-01-19 16:18:37', '2023-01-19 16:18:38', '2023-01-19 16:18:39', '2023-01-19 16:18:40', '2023-01-19 16:18:41', '2023-01-19 16:18:42', '2023-01-19 16:18:43', '2023-01-19 16:18:44', '2023-01-19 16:18:45', '2023-01-19 16:18:46', '2023-01-19 16:18:47', '2023-01-19 16:18:48', '2023-01-19 16:18:49', '2023-01-19 16:18:50', '2023-01-19 16:18:51', '2023-01-19 16:18:53', '2023-01-19 16:18:54', '2023-01-19 16:18:55', '2023-01-19 16:18:56', '2023-01-19 16:18:57', '2023-01-19 16:18:58', '2023-01-19 16:18:59', '2023-01-19 16:19:00', '2023-01-19 16:19:01', '2023-01-19 16:19:02', '2023-01-19 16:19:03', '2023-01-19 16:19:04', '2023-01-19 16:19:05', '2023-01-19 16:19:06', '2023-01-19 16:19:07', '2023-01-19 16:19:08', '2023-01-19 16:19:09', '2023-01-19 16:19:10', '2023-01-19 16:19:11', '2023-01-19 16:19:12', '2023-01-19 16:19:13', '2023-01-19 16:19:14', '2023-01-19 16:19:15', '2023-01-19 16:19:16', '2023-01-19 16:19:17', '2023-01-19 16:19:18', '2023-01-19 16:19:19', '2023-01-19 16:19:20', '2023-01-19 16:19:21', '2023-01-19 16:19:22', '2023-01-19 16:19:23', '2023-01-19 16:19:24', '2023-01-19 16:19:25', '2023-01-19 16:19:26', '2023-01-19 16:19:27', '2023-01-19 16:19:28', '2023-01-19 16:19:29', '2023-01-19 16:19:30', '2023-01-19 16:19:31', '2023-01-19 16:19:32', '2023-01-19 16:19:33', '2023-01-19 16:19:35', '2023-01-19 16:19:36', '2023-01-19 16:19:37', '2023-01-19 16:19:38', '2023-01-19 16:19:39', '2023-01-19 16:19:40', '2023-01-19 16:19:41', '2023-01-19 16:19:42', '2023-01-19 16:19:43', '2023-01-19 16:19:44', '2023-01-19 16:19:45', '2023-01-19 16:19:46', '2023-01-19 16:19:47', '2023-01-19 16:19:48', '2023-01-19 16:19:49', '2023-01-19 16:19:50', '2023-01-19 16:19:51', '2023-01-19 16:19:52', '2023-01-19 16:19:53', '2023-01-19 16:19:54', '2023-01-19 16:19:55', '2023-01-19 16:19:56', '2023-01-19 16:19:57', '2023-01-19 16:19:58', '2023-01-19 16:19:59', '2023-01-19 16:20:00', '2023-01-19 16:20:01', '2023-01-19 16:20:02', '2023-01-19 16:20:03', '2023-01-19 16:20:04', '2023-01-19 16:20:05', '2023-01-19 16:20:06', '2023-01-19 16:20:07', '2023-01-19 16:20:08', '2023-01-19 16:20:09', '2023-01-19 16:20:10', '2023-01-19 16:20:11', '2023-01-19 16:20:12', '2023-01-19 16:20:13', '2023-01-19 16:20:14', '2023-01-19 16:20:15', '2023-01-19 16:20:17', '2023-01-19 16:20:18', '2023-01-19 16:20:19', '2023-01-19 16:20:20', '2023-01-19 16:20:21', '2023-01-19 16:20:22', '2023-01-19 16:20:23', '2023-01-19 16:20:24', '2023-01-19 16:20:25', '2023-01-19 16:20:26', '2023-01-19 16:20:27', '2023-01-19 16:20:28', '2023-01-19 16:20:29', '2023-01-19 16:20:30', '2023-01-19 16:20:31', '2023-01-19 16:20:32', '2023-01-19 16:20:33', '2023-01-19 16:20:34', '2023-01-19 16:20:35', '2023-01-19 16:20:36', '2023-01-19 16:20:37', '2023-01-19 16:20:38', '2023-01-19 16:20:39', '2023-01-19 16:20:40', '2023-01-19 16:20:41', '2023-01-19 16:20:42', '2023-01-19 16:20:43', '2023-01-19 16:20:44', '2023-01-19 16:20:45', '2023-01-19 16:20:46', '2023-01-19 16:20:47', '2023-01-19 16:20:48', '2023-01-19 16:20:49', '2023-01-19 16:20:50', '2023-01-19 16:20:51', '2023-01-19 16:20:52', '2023-01-19 16:20:53', '2023-01-19 16:20:54', '2023-01-19 16:20:55', '2023-01-19 16:20:56', '2023-01-19 16:20:57', '2023-01-19 16:20:59', '2023-01-19 16:21:00', '2023-01-19 16:21:01', '2023-01-19 16:21:02', '2023-01-19 16:21:03', '2023-01-19 16:21:04', '2023-01-19 16:21:05', '2023-01-19 16:21:06', '2023-01-19 16:21:07', '2023-01-19 16:21:08', '2023-01-19 16:21:09', '2023-01-19 16:21:10', '2023-01-19 16:21:11', '2023-01-19 16:21:12', '2023-01-19 16:21:13', '2023-01-19 16:21:14', '2023-01-19 16:21:15', '2023-01-19 16:21:16', '2023-01-19 16:21:17', '2023-01-19 16:21:18', '2023-01-19 16:21:19', '2023-01-19 16:21:20', '2023-01-19 16:21:21', '2023-01-19 16:21:22', '2023-01-19 16:21:23', '2023-01-19 16:21:24', '2023-01-19 16:21:25', '2023-01-19 16:21:26', '2023-01-19 16:21:27', '2023-01-19 16:21:28', '2023-01-19 16:21:29', '2023-01-19 16:21:30', '2023-01-19 16:21:31', '2023-01-19 16:21:32', '2023-01-19 16:21:33', '2023-01-19 16:21:34', '2023-01-19 16:21:35', '2023-01-19 16:21:36', '2023-01-19 16:21:37', '2023-01-19 16:21:38', '2023-01-19 16:21:39', '2023-01-19 16:21:41', '2023-01-19 16:21:42', '2023-01-19 16:21:43', '2023-01-19 16:21:44', '2023-01-19 16:21:45', '2023-01-19 16:21:46', '2023-01-19 16:21:47', '2023-01-19 16:21:48', '2023-01-19 16:21:49', '2023-01-19 16:21:50', '2023-01-19 16:21:51', '2023-01-19 16:21:52', '2023-01-19 16:21:53', '2023-01-19 16:21:54', '2023-01-19 16:21:55', '2023-01-19 16:21:56', '2023-01-19 16:21:57', '2023-01-19 16:21:58', '2023-01-19 16:21:59', '2023-01-19 16:22:00', '2023-01-19 16:22:01', '2023-01-19 16:22:02', '2023-01-19 16:22:03', '2023-01-19 16:22:04', '2023-01-19 16:22:05', '2023-01-19 16:22:06', '2023-01-19 16:22:07', '2023-01-19 16:22:08', '2023-01-19 16:22:09', '2023-01-19 16:22:10', '2023-01-19 16:22:11', '2023-01-19 16:22:12', '2023-01-19 16:22:13', '2023-01-19 16:22:14', '2023-01-19 16:22:15', '2023-01-19 16:22:16', '2023-01-19 16:22:17', '2023-01-19 16:22:18', '2023-01-19 16:22:19', '2023-01-19 16:22:20', '2023-01-19 16:22:21', '2023-01-19 16:22:23', '2023-01-19 16:22:24', '2023-01-19 16:22:25', '2023-01-19 16:22:26', '2023-01-19 16:22:27', '2023-01-19 16:22:28', '2023-01-19 16:22:29', '2023-01-19 16:22:30', '2023-01-19 16:22:31', '2023-01-19 16:22:32', '2023-01-19 16:22:33', '2023-01-19 16:22:34', '2023-01-19 16:22:35', '2023-01-19 16:22:36', '2023-01-19 16:22:37', '2023-01-19 16:22:38', '2023-01-19 16:22:39', '2023-01-19 16:22:40', '2023-01-19 16:22:41', '2023-01-19 16:22:42', '2023-01-19 16:22:43', '2023-01-19 16:22:44', '2023-01-19 16:22:45', '2023-01-19 16:22:46', '2023-01-19 16:22:47', '2023-01-19 16:22:48', '2023-01-19 16:22:49', '2023-01-19 16:22:50', '2023-01-19 16:22:51', '2023-01-19 16:22:52', '2023-01-19 16:22:53', '2023-01-19 16:22:54', '2023-01-19 16:22:55', '2023-01-19 16:22:56', '2023-01-19 16:22:57', '2023-01-19 16:22:58', '2023-01-19 16:22:59', '2023-01-19 16:23:00', '2023-01-19 16:23:01', '2023-01-19 16:23:02', '2023-01-19 16:23:04', '2023-01-19 16:23:05', '2023-01-19 16:23:06', '2023-01-19 16:23:07', '2023-01-19 16:23:08', '2023-01-19 16:23:09', '2023-01-19 16:23:10', '2023-01-19 16:23:11', '2023-01-19 16:23:12', '2023-01-19 16:23:13', '2023-01-19 16:23:14', '2023-01-19 16:23:15', '2023-01-19 16:23:16', '2023-01-19 16:23:17', '2023-01-19 16:23:18', '2023-01-19 16:23:19', '2023-01-19 16:23:20', '2023-01-19 16:23:21', '2023-01-19 16:23:22', '2023-01-19 16:23:23', '2023-01-19 16:23:24', '2023-01-19 16:23:25', '2023-01-19 16:23:26', '2023-01-19 16:23:27', '2023-01-19 16:23:28', '2023-01-19 16:23:29', '2023-01-19 16:23:30', '2023-01-19 16:23:31', '2023-01-19 16:23:32', '2023-01-19 16:23:33', '2023-01-19 16:23:34', '2023-01-19 16:23:35', '2023-01-19 16:23:36', '2023-01-19 16:23:37', '2023-01-19 16:23:38', '2023-01-19 16:23:39', '2023-01-19 16:23:40', '2023-01-19 16:23:41', '2023-01-19 16:23:42', '2023-01-19 16:23:43', '2023-01-19 16:23:44', '2023-01-19 16:23:46', '2023-01-19 16:23:47', '2023-01-19 16:23:48', '2023-01-19 16:23:49', '2023-01-19 16:23:50', '2023-01-19 16:23:51', '2023-01-19 16:23:52', '2023-01-19 16:23:53', '2023-01-19 16:23:54', '2023-01-19 16:23:55', '2023-01-19 16:23:56', '2023-01-19 16:23:57', '2023-01-19 16:23:58', '2023-01-19 16:23:59', '2023-01-19 16:24:00', '2023-01-19 16:24:01', '2023-01-19 16:24:02', '2023-01-19 16:24:03', '2023-01-19 16:24:04', '2023-01-19 16:24:05', '2023-01-19 16:24:06', '2023-01-19 16:24:07', '2023-01-19 16:24:08', '2023-01-19 16:24:09', '2023-01-19 16:24:10', '2023-01-19 16:24:11', '2023-01-19 16:24:12', '2023-01-19 16:24:13', '2023-01-19 16:24:14', '2023-01-19 16:24:15', '2023-01-19 16:24:16', '2023-01-19 16:24:17', '2023-01-19 16:24:18', '2023-01-19 16:24:19', '2023-01-19 16:24:20', '2023-01-19 16:24:21', '2023-01-19 16:24:22', '2023-01-19 16:24:23', '2023-01-19 16:24:24', '2023-01-19 16:24:25', '2023-01-19 16:24:26', '2023-01-19 16:24:28', '2023-01-19 16:24:29', '2023-01-19 16:24:30', '2023-01-19 16:24:31', '2023-01-19 16:24:32', '2023-01-19 16:24:33', '2023-01-19 16:24:34', '2023-01-19 16:24:35', '2023-01-19 16:24:36', '2023-01-19 16:24:37', '2023-01-19 16:24:38', '2023-01-19 16:24:39', '2023-01-19 16:24:40', '2023-01-19 16:24:41', '2023-01-19 16:24:42', '2023-01-19 16:24:43', '2023-01-19 16:24:44', '2023-01-19 16:24:45', '2023-01-19 16:24:46', '2023-01-19 16:24:47', '2023-01-19 16:24:48', '2023-01-19 16:24:49', '2023-01-19 16:24:50', '2023-01-19 16:24:51', '2023-01-19 16:24:52', '2023-01-19 16:24:53', '2023-01-19 16:24:54', '2023-01-19 16:24:55', '2023-01-19 16:24:56', '2023-01-19 16:24:57', '2023-01-19 16:24:58', '2023-01-19 16:24:59', '2023-01-19 16:25:00', '2023-01-19 16:25:01', '2023-01-19 16:25:02', '2023-01-19 16:25:03', '2023-01-19 16:25:04', '2023-01-19 16:25:05', '2023-01-19 16:25:06', '2023-01-19 16:25:07', '2023-01-19 16:25:08', '2023-01-19 16:25:10', '2023-01-19 16:25:11', '2023-01-19 16:25:12', '2023-01-19 16:25:13', '2023-01-19 16:25:14', '2023-01-19 16:25:15', '2023-01-19 16:25:16', '2023-01-19 16:25:17', '2023-01-19 16:25:18', '2023-01-19 16:25:19', '2023-01-19 16:25:20', '2023-01-19 16:25:21', '2023-01-19 16:25:22', '2023-01-19 16:25:23', '2023-01-19 16:25:24', '2023-01-19 16:25:25', '2023-01-19 16:25:26', '2023-01-19 16:25:27', '2023-01-19 16:25:28', '2023-01-19 16:25:29', '2023-01-19 16:25:30', '2023-01-19 16:25:31', '2023-01-19 16:25:32', '2023-01-19 16:25:33', '2023-01-19 16:25:34', '2023-01-19 16:25:35', '2023-01-19 16:25:36', '2023-01-19 16:25:37', '2023-01-19 16:25:38', '2023-01-19 16:25:39', '2023-01-19 16:25:40', '2023-01-19 16:25:41', '2023-01-19 16:25:42', '2023-01-19 16:25:43', '2023-01-19 16:25:44', '2023-01-19 16:25:45', '2023-01-19 16:25:46', '2023-01-19 16:25:47', '2023-01-19 16:25:48', '2023-01-19 16:25:49', '2023-01-19 16:25:50', '2023-01-19 16:25:52', '2023-01-19 16:25:53', '2023-01-19 16:25:54', '2023-01-19 16:25:55', '2023-01-19 16:25:56', '2023-01-19 16:25:57', '2023-01-19 16:25:58', '2023-01-19 16:25:59', '2023-01-19 16:26:00', '2023-01-19 16:26:01', '2023-01-19 16:26:02', '2023-01-19 16:26:03', '2023-01-19 16:26:04', '2023-01-19 16:26:05', '2023-01-19 16:26:06', '2023-01-19 16:26:07', '2023-01-19 16:26:08', '2023-01-19 16:26:09', '2023-01-19 16:26:10', '2023-01-19 16:26:11', '2023-01-19 16:26:12', '2023-01-19 16:26:13', '2023-01-19 16:26:14', '2023-01-19 16:26:15', '2023-01-19 16:26:16', '2023-01-19 16:26:17', '2023-01-19 16:26:18', '2023-01-19 16:26:19', '2023-01-19 16:26:20', '2023-01-19 16:26:21', '2023-01-19 16:26:22', '2023-01-19 16:26:23', '2023-01-19 16:26:24', '2023-01-19 16:26:25', '2023-01-19 16:26:26', '2023-01-19 16:26:27', '2023-01-19 16:26:28', '2023-01-19 16:26:29', '2023-01-19 16:26:30', '2023-01-19 16:26:31', '2023-01-19 16:26:32', '2023-01-19 16:26:34', '2023-01-19 16:26:35', '2023-01-19 16:26:36', '2023-01-19 16:26:37', '2023-01-19 16:26:38', '2023-01-19 16:26:39', '2023-01-19 16:26:40', '2023-01-19 16:26:41', '2023-01-19 16:26:42', '2023-01-19 16:26:43', '2023-01-19 16:26:44', '2023-01-19 16:26:45', '2023-01-19 16:26:46', '2023-01-19 16:26:47', '2023-01-19 16:26:48', '2023-01-19 16:26:49', '2023-01-19 16:26:50', '2023-01-19 16:26:51', '2023-01-19 16:26:52', '2023-01-19 16:26:53', '2023-01-19 16:26:54', '2023-01-19 16:26:55', '2023-01-19 16:26:56', '2023-01-19 16:26:57', '2023-01-19 16:26:58', '2023-01-19 16:26:59', '2023-01-19 16:27:00', '2023-01-19 16:27:01', '2023-01-19 16:27:02', '2023-01-19 16:27:03', '2023-01-19 16:27:04', '2023-01-19 16:27:05', '2023-01-19 16:27:06', '2023-01-19 16:27:07', '2023-01-19 16:27:08', '2023-01-19 16:27:09', '2023-01-19 16:27:10', '2023-01-19 16:27:11', '2023-01-19 16:27:12', '2023-01-19 16:27:13', '2023-01-19 16:27:14', '2023-01-19 16:27:16', '2023-01-19 16:27:17', '2023-01-19 16:27:18', '2023-01-19 16:27:19', '2023-01-19 16:27:20', '2023-01-19 16:27:21', '2023-01-19 16:27:22', '2023-01-19 16:27:23', '2023-01-19 16:27:24', '2023-01-19 16:27:25', '2023-01-19 16:27:26', '2023-01-19 16:27:27', '2023-01-19 16:27:28', '2023-01-19 16:27:29', '2023-01-19 16:27:30', '2023-01-19 16:27:31', '2023-01-19 16:27:32', '2023-01-19 16:27:33', '2023-01-19 16:27:34', '2023-01-19 16:27:35', '2023-01-19 16:27:36', '2023-01-19 16:27:37', '2023-01-19 16:27:38', '2023-01-19 16:27:39', '2023-01-19 16:27:40', '2023-01-19 16:27:41', '2023-01-19 16:27:42', '2023-01-19 16:27:43', '2023-01-19 16:27:44', '2023-01-19 16:27:45', '2023-01-19 16:27:46', '2023-01-19 16:27:47', '2023-01-19 16:27:48', '2023-01-19 16:27:49', '2023-01-19 16:27:50', '2023-01-19 16:27:51', '2023-01-19 16:27:52', '2023-01-19 16:27:53', '2023-01-19 16:27:54', '2023-01-19 16:27:55', '2023-01-19 16:27:56', '2023-01-19 16:27:58', '2023-01-19 16:27:59', '2023-01-19 16:28:00', '2023-01-19 16:28:01', '2023-01-19 16:28:02', '2023-01-19 16:28:03', '2023-01-19 16:28:04', '2023-01-19 16:28:05', '2023-01-19 16:28:06', '2023-01-19 16:28:07', '2023-01-19 16:28:08', '2023-01-19 16:28:09', '2023-01-19 16:28:10', '2023-01-19 16:28:11', '2023-01-19 16:28:12', '2023-01-19 16:28:13', '2023-01-19 16:28:14', '2023-01-19 16:28:15', '2023-01-19 16:28:16', '2023-01-19 16:28:17', '2023-01-19 16:28:18', '2023-01-19 16:28:19', '2023-01-19 16:28:20', '2023-01-19 16:28:21', '2023-01-19 16:28:22', '2023-01-19 16:28:23', '2023-01-19 16:28:24', '2023-01-19 16:28:25', '2023-01-19 16:28:26', '2023-01-19 16:28:27', '2023-01-19 16:28:28', '2023-01-19 16:28:29', '2023-01-19 16:28:30', '2023-01-19 16:28:31', '2023-01-19 16:28:32', '2023-01-19 16:28:33', '2023-01-19 16:28:34', '2023-01-19 16:28:35', '2023-01-19 16:28:36', '2023-01-19 16:28:37', '2023-01-19 16:28:39', '2023-01-19 16:28:40', '2023-01-19 16:28:41', '2023-01-19 16:28:42', '2023-01-19 16:28:43', '2023-01-19 16:28:44', '2023-01-19 16:28:45', '2023-01-19 16:28:46', '2023-01-19 16:28:47', '2023-01-19 16:28:48', '2023-01-19 16:28:49', '2023-01-19 16:28:50', '2023-01-19 16:28:51', '2023-01-19 16:28:52', '2023-01-19 16:28:53', '2023-01-19 16:28:54', '2023-01-19 16:28:55', '2023-01-19 16:28:56', '2023-01-19 16:28:57', '2023-01-19 16:28:58', '2023-01-19 16:28:59', '2023-01-19 16:29:00', '2023-01-19 16:29:01', '2023-01-19 16:29:02', '2023-01-19 16:29:03', '2023-01-19 16:29:04', '2023-01-19 16:29:05', '2023-01-19 16:29:06', '2023-01-19 16:29:07', '2023-01-19 16:29:08', '2023-01-19 16:29:09', '2023-01-19 16:29:10', '2023-01-19 16:29:11', '2023-01-19 16:29:12', '2023-01-19 16:29:13', '2023-01-19 16:29:14', '2023-01-19 16:29:15', '2023-01-19 16:29:16', '2023-01-19 16:29:17', '2023-01-19 16:29:18', '2023-01-19 16:29:19', '2023-01-19 16:29:21', '2023-01-19 16:29:22', '2023-01-19 16:29:23', '2023-01-19 16:29:24', '2023-01-19 16:29:25', '2023-01-19 16:29:26', '2023-01-19 16:29:27', '2023-01-19 16:29:28', '2023-01-19 16:29:29', '2023-01-19 16:29:30', '2023-01-19 16:29:31', '2023-01-19 16:29:32', '2023-01-19 16:29:33', '2023-01-19 16:29:34', '2023-01-19 16:29:35', '2023-01-19 16:29:36', '2023-01-19 16:29:37', '2023-01-19 16:29:38', '2023-01-19 16:29:39', '2023-01-19 16:29:40', '2023-01-19 16:29:41', '2023-01-19 16:29:42', '2023-01-19 16:29:43', '2023-01-19 16:29:44', '2023-01-19 16:29:45', '2023-01-19 16:29:46', '2023-01-19 16:29:47', '2023-01-19 16:29:48', '2023-01-19 16:29:49', '2023-01-19 16:29:50', '2023-01-19 16:29:51', '2023-01-19 16:29:52', '2023-01-19 16:29:53', '2023-01-19 16:29:54', '2023-01-19 16:29:55', '2023-01-19 16:29:56', '2023-01-19 16:29:57', '2023-01-19 16:29:58', '2023-01-19 16:29:59', '2023-01-19 16:30:00', '2023-01-19 16:30:01', '2023-01-19 16:30:03', '2023-01-19 16:30:04', '2023-01-19 16:30:05', '2023-01-19 16:30:06', '2023-01-19 16:30:07', '2023-01-19 16:30:08', '2023-01-19 16:30:09', '2023-01-19 16:30:10', '2023-01-19 16:30:11', '2023-01-19 16:30:12', '2023-01-19 16:30:13', '2023-01-19 16:30:14', '2023-01-19 16:30:15', '2023-01-19 16:30:16', '2023-01-19 16:30:17', '2023-01-19 16:30:18', '2023-01-19 16:30:19', '2023-01-19 16:30:20', '2023-01-19 16:30:21', '2023-01-19 16:30:22', '2023-01-19 16:30:23', '2023-01-19 16:30:24', '2023-01-19 16:30:25', '2023-01-19 16:30:26', '2023-01-19 16:30:27', '2023-01-19 16:30:28', '2023-01-19 16:30:29', '2023-01-19 16:30:30', '2023-01-19 16:30:31', '2023-01-19 16:30:32', '2023-01-19 16:30:33', '2023-01-19 16:30:34', '2023-01-19 16:30:35', '2023-01-19 16:30:36', '2023-01-19 16:30:37', '2023-01-19 16:30:38', '2023-01-19 16:30:39', '2023-01-19 16:30:40', '2023-01-19 16:30:41', '2023-01-19 16:30:42', '2023-01-19 16:30:43', '2023-01-19 16:30:45', '2023-01-19 16:30:46', '2023-01-19 16:30:47', '2023-01-19 16:30:48', '2023-01-19 16:30:49', '2023-01-19 16:30:50', '2023-01-19 16:30:51', '2023-01-19 16:30:52', '2023-01-19 16:30:53', '2023-01-19 16:30:54', '2023-01-19 16:30:55', '2023-01-19 16:30:56', '2023-01-19 16:30:57', '2023-01-19 16:30:58', '2023-01-19 16:30:59', '2023-01-19 16:31:00', '2023-01-19 16:31:01', '2023-01-19 16:31:02', '2023-01-19 16:31:03', '2023-01-19 16:31:04', '2023-01-19 16:31:05', '2023-01-19 16:31:06', '2023-01-19 16:31:07', '2023-01-19 16:31:08', '2023-01-19 16:31:09', '2023-01-19 16:31:10', '2023-01-19 16:31:11', '2023-01-19 16:31:12', '2023-01-19 16:31:13', '2023-01-19 16:31:14', '2023-01-19 16:31:15', '2023-01-19 16:31:16', '2023-01-19 16:31:17', '2023-01-19 16:31:18', '2023-01-19 16:31:19', '2023-01-19 16:31:20', '2023-01-19 16:31:21', '2023-01-19 16:31:22', '2023-01-19 16:31:23', '2023-01-19 16:31:24', '2023-01-19 16:31:25', '2023-01-19 16:31:27', '2023-01-19 16:31:28', '2023-01-19 16:31:29', '2023-01-19 16:31:30', '2023-01-19 16:31:31', '2023-01-19 16:31:32', '2023-01-19 16:31:33', '2023-01-19 16:31:34', '2023-01-19 16:31:35', '2023-01-19 16:31:36', '2023-01-19 16:31:37', '2023-01-19 16:31:38', '2023-01-19 16:31:39', '2023-01-19 16:31:40', '2023-01-19 16:31:41', '2023-01-19 16:31:42', '2023-01-19 16:31:43', '2023-01-19 16:31:44', '2023-01-19 16:31:45', '2023-01-19 16:31:46', '2023-01-19 16:31:47', '2023-01-19 16:31:48', '2023-01-19 16:31:49', '2023-01-19 16:31:50', '2023-01-19 16:31:51', '2023-01-19 16:31:52', '2023-01-19 16:31:53', '2023-01-19 16:31:54', '2023-01-19 16:31:55', '2023-01-19 16:31:56', '2023-01-19 16:31:57', '2023-01-19 16:31:58', '2023-01-19 16:31:59', '2023-01-19 16:32:00', '2023-01-19 16:32:01', '2023-01-19 16:32:02', '2023-01-19 16:32:03', '2023-01-19 16:32:04', '2023-01-19 16:32:05', '2023-01-19 16:32:06', '2023-01-19 16:32:07', '2023-01-19 16:32:09', '2023-01-19 16:32:10', '2023-01-19 16:32:11', '2023-01-19 16:32:12', '2023-01-19 16:32:13', '2023-01-19 16:32:14', '2023-01-19 16:32:15', '2023-01-19 16:32:16', '2023-01-19 16:32:17', '2023-01-19 16:32:18', '2023-01-19 16:32:19', '2023-01-19 16:32:20', '2023-01-19 16:32:21', '2023-01-19 16:32:22', '2023-01-19 16:32:23', '2023-01-19 16:32:24', '2023-01-19 16:32:25', '2023-01-19 16:32:26', '2023-01-19 16:32:27', '2023-01-19 16:32:28', '2023-01-19 16:32:29', '2023-01-19 16:32:30', '2023-01-19 16:32:31', '2023-01-19 16:32:32', '2023-01-19 16:32:33', '2023-01-19 16:32:34', '2023-01-19 16:32:35', '2023-01-19 16:32:36', '2023-01-19 16:32:37', '2023-01-19 16:32:38', '2023-01-19 16:32:39', '2023-01-19 16:32:40', '2023-01-19 16:32:41', '2023-01-19 16:32:42', '2023-01-19 16:32:43', '2023-01-19 16:32:44', '2023-01-19 16:32:45', '2023-01-19 16:32:46', '2023-01-19 16:32:47', '2023-01-19 16:32:48', '2023-01-19 16:32:49', '2023-01-19 16:32:51', '2023-01-19 16:32:52', '2023-01-19 16:32:53', '2023-01-19 16:32:54', '2023-01-19 16:32:55', '2023-01-19 16:32:56', '2023-01-19 16:32:57', '2023-01-19 16:32:58', '2023-01-19 16:32:59', '2023-01-19 16:33:00', '2023-01-19 16:33:01', '2023-01-19 16:33:02', '2023-01-19 16:33:03', '2023-01-19 16:33:04', '2023-01-19 16:33:05', '2023-01-19 16:33:06', '2023-01-19 16:33:07', '2023-01-19 16:33:08', '2023-01-19 16:33:09', '2023-01-19 16:33:10', '2023-01-19 16:33:11', '2023-01-19 16:33:12', '2023-01-19 16:33:13', '2023-01-19 16:33:14', '2023-01-19 16:33:15', '2023-01-19 16:33:16', '2023-01-19 16:33:17', '2023-01-19 16:33:18', '2023-01-19 16:33:19', '2023-01-19 16:33:20', '2023-01-19 16:33:21', '2023-01-19 16:33:22', '2023-01-19 16:33:23', '2023-01-19 16:33:24', '2023-01-19 16:33:25', '2023-01-19 16:33:26', '2023-01-19 16:33:27', '2023-01-19 16:33:28', '2023-01-19 16:33:29', '2023-01-19 16:33:30', '2023-01-19 16:33:32', '2023-01-19 16:33:33', '2023-01-19 16:33:34', '2023-01-19 16:33:35', '2023-01-19 16:33:36', '2023-01-19 16:33:37', '2023-01-19 16:33:38', '2023-01-19 16:33:39', '2023-01-19 16:33:40', '2023-01-19 16:33:41', '2023-01-19 16:33:42', '2023-01-19 16:33:43', '2023-01-19 16:33:44', '2023-01-19 16:33:45', '2023-01-19 16:33:46', '2023-01-19 16:33:47', '2023-01-19 16:33:48', '2023-01-19 16:33:49', '2023-01-19 16:33:50', '2023-01-19 16:33:51', '2023-01-19 16:33:52', '2023-01-19 16:33:53', '2023-01-19 16:33:54', '2023-01-19 16:33:55', '2023-01-19 16:33:56', '2023-01-19 16:33:57', '2023-01-19 16:33:58', '2023-01-19 16:33:59', '2023-01-19 16:34:00', '2023-01-19 16:34:01', '2023-01-19 16:34:02', '2023-01-19 16:34:03', '2023-01-19 16:34:04', '2023-01-19 16:34:05', '2023-01-19 16:34:06', '2023-01-19 16:34:07', '2023-01-19 16:34:08', '2023-01-19 16:34:09', '2023-01-19 16:34:10', '2023-01-19 16:34:11', '2023-01-19 16:34:12', '2023-01-19 16:34:14', '2023-01-19 16:34:15', '2023-01-19 16:34:16', '2023-01-19 16:34:17', '2023-01-19 16:34:18', '2023-01-19 16:34:19', '2023-01-19 16:34:20', '2023-01-19 16:34:21', '2023-01-19 16:34:22', '2023-01-19 16:34:23', '2023-01-19 16:34:24', '2023-01-19 16:34:25', '2023-01-19 16:34:26', '2023-01-19 16:34:27', '2023-01-19 16:34:28', '2023-01-19 16:34:29', '2023-01-19 16:34:30', '2023-01-19 16:34:31', '2023-01-19 16:34:32', '2023-01-19 16:34:33', '2023-01-19 16:34:34', '2023-01-19 16:34:35', '2023-01-19 16:34:36', '2023-01-19 16:34:37', '2023-01-19 16:34:38', '2023-01-19 16:34:39', '2023-01-19 16:34:40', '2023-01-19 16:34:41', '2023-01-19 16:34:42', '2023-01-19 16:34:43', '2023-01-19 16:34:44', '2023-01-19 16:34:45', '2023-01-19 16:34:46', '2023-01-19 16:34:47', '2023-01-19 16:34:48', '2023-01-19 16:34:49', '2023-01-19 16:34:50', '2023-01-19 16:34:51', '2023-01-19 16:34:52', '2023-01-19 16:34:53', '2023-01-19 16:34:54', '2023-01-19 16:34:56', '2023-01-19 16:34:57', '2023-01-19 16:34:58', '2023-01-19 16:34:59', '2023-01-19 16:35:00', '2023-01-19 16:35:01', '2023-01-19 16:35:02', '2023-01-19 16:35:03', '2023-01-19 16:35:04', '2023-01-19 16:35:05', '2023-01-19 16:35:06', '2023-01-19 16:35:07', '2023-01-19 16:35:08', '2023-01-19 16:35:09', '2023-01-19 16:35:10', '2023-01-19 16:35:11', '2023-01-19 16:35:12', '2023-01-19 16:35:13', '2023-01-19 16:35:14', '2023-01-19 16:35:15', '2023-01-19 16:35:16', '2023-01-19 16:35:17', '2023-01-19 16:35:18', '2023-01-19 16:35:19']\n",
      "[array([   7,  120,  232,  396,  543,  646,  813, 1058, 1175, 1325, 1442,\n",
      "       1570, 1761, 1901, 2195]), array([   576,  15040,  29376,  50368,  69184,  82368, 103744, 135232,\n",
      "       150208, 169408, 184384, 200768, 225216, 243136, 280768])]\n",
      "[array([  66,  179,  290,  454,  602,  704,  871, 1115, 1233, 1383, 1501,\n",
      "       1627, 1817, 1959, 2253]), array([  8128,  22592,  36800,  57792,  76736,  89792, 111168, 142528,\n",
      "       157632, 176832, 191936, 208064, 232384, 250560, 288192])]\n"
     ]
    }
   ],
   "source": [
    "# for converting the mean_rgb files (npz) to csv and show the frame of states#\n",
    "num = [ 2]\n",
    "#ids =  [\"id_{}\".format(i) for i in num]\n",
    "recording = 'recording2'\n",
    "protocol = '15 mins trial'\n",
    "device = 'Ipad'\n",
    "directory = r'/Users/kinho123/Downloads/v3'\n",
    "\n",
    "fps = []\n",
    "for index, id in enumerate(num):\n",
    "        \n",
    "    rgb = np.load(r\"{}/id_{}/{}/{}/{}_mediapipe_meanRGB.npz\".format(directory, id, recording, protocol, device), mmap_mode = 'r', allow_pickle = True)['arr_0']\n",
    "\n",
    "    rgb = rgb.reshape(-1, 1)[0][0]\n",
    "        \n",
    "    dt = [datetime.strptime(\"13-02-2023 17:00:34.00\", \"%d-%m-%Y %H:%M:%S.%f\"),\n",
    "        datetime.strptime(\"19-01-2023 15:56:47.00\", \"%d-%m-%Y %H:%M:%S.%f\"),\n",
    "         datetime.strptime(\"03-02-2023 12:47:16.00\", \"%d-%m-%Y %H:%M:%S.%f\"),\n",
    "          datetime.strptime(\"13-02-2023 17:46:14.00\", \"%d-%m-%Y %H:%M:%S.%f\"),\n",
    "          datetime.strptime(\"19-01-2023 12:17:25.00\", \"%d-%m-%Y %H:%M:%S.%f\"),\n",
    "          datetime.strptime(\"19-01-2023 17:11:56.00\", \"%d-%m-%Y %H:%M:%S.%f\"),\n",
    "         datetime.strptime(\"20-01-2023 12:35:17.00\", \"%d-%m-%Y %H:%M:%S.%f\"),\n",
    "         datetime.strptime(\"20-01-2023 16:45:16.00\", \"%d-%m-%Y %H:%M:%S.%f\"),\n",
    "         datetime.strptime(\"26-01-2023 15:35:41.00\", \"%d-%m-%Y %H:%M:%S.%f\"),\n",
    "         datetime.strptime(\"26-01-2023 16:39:31.00\", \"%d-%m-%Y %H:%M:%S.%f\"),\n",
    "         datetime.strptime(\"26-01-2023 18:00:58.00\", \"%d-%m-%Y %H:%M:%S.%f\"),\n",
    "         datetime.strptime(\"27-01-2023 15:14:51.00\", \"%d-%m-%Y %H:%M:%S.%f\"),\n",
    "         datetime.strptime(\"03-02-2023 15:16:17.00\", \"%d-%m-%Y %H:%M:%S.%f\"),\n",
    "         datetime.strptime(\"06-02-2023 16:34:22.00\", \"%d-%m-%Y %H:%M:%S.%f\"),\n",
    "         datetime.strptime(\"06-02-2023 17:31:56.00\", \"%d-%m-%Y %H:%M:%S.%f\"),\n",
    "         datetime.strptime(\"07-02-2023 11:05:04.00\", \"%d-%m-%Y %H:%M:%S.%f\")]\n",
    "\n",
    "    ts = dt[index].timestamp()\n",
    "    list1 = [str((dt[index].fromtimestamp(int((rgb['mean_RGB']['Timestamp (s)'][i]) + ts) ))) for i in range(0,len(rgb['mean_RGB']['Timestamp (s)']))]\n",
    "\n",
    "    luxs = [100, 200, 300, 500,1000]\n",
    "    distances = [0.4, 0.5, 0.6]\n",
    "    \n",
    "\n",
    "    timestp_start = [list1[info[\"{}_Ipad_{}_{}\".format(id, i,j)][0]] for i in luxs for j in distances]\n",
    "    timestp_stop = [list1[info[\"{}_Ipad_{}_{}\".format(id, i,j)][1]] for i in luxs for j in distances]\n",
    "    \n",
    "    timestp_start_new =  [str(datetime.strptime(timestp_start[i] , \"%Y-%m-%d %H:%M:%S\") + timedelta(seconds=1)) for i in range(0, len(timestp_start))]\n",
    "    timestp_stop_new =  [str(datetime.strptime(timestp_stop[i] , \"%Y-%m-%d %H:%M:%S\") + timedelta(seconds=1)) for i in range(0, len(timestp_start))]\n",
    "\n",
    "    name = [\"MPDataExport\", \"NOM_PLETHWaveExport\"]\n",
    "    \n",
    "    df = [pd.read_csv(r\"/Users/kinho123/Downloads/v3/id_{}/recording2/15 mins trial/{}.csv\".format(id, j)) for j in name]\n",
    "\n",
    "    ti = [[datetime.strptime(df[0][\"SystemLocalTime\"][i], \"%d-%m-%Y %H:%M:%S.%f\") for i in range(0, len(df[0]))],\n",
    "          [datetime.strptime(df[1].iloc[:, 2][i], \"%d-%m-%Y %H:%M:%S.%f\") for i in range(0, len(df[1]))]]\n",
    "\n",
    "\n",
    "    trel = [[int(ti[j][i].timestamp()) for i in range(0, len(df[j]))] for j in range(0,2)]\n",
    "    trel_new = [[round(ti[j][i].timestamp()) for i in range(0, len(df[j]))] for j in range(0,2)]\n",
    "    tcsv = [[str(dt[index].fromtimestamp(trel[j][i])) for i in range(0, len(df[j]))] for j in range(0,2)]\n",
    "    tcsv_new = [[str(dt[index].fromtimestamp(trel_new[j][i])) for i in range(0, len(df[j]))] for j in range(0,2)]\n",
    "    \n",
    "\n",
    "    index_start = [np.array([tcsv[j].index(timestp_start[i]) if timestp_start[i] in tcsv[j] else tcsv[j].index(timestp_start_new[i]) for i in range(0, len(timestp_start))]) for j in range(0,2)] \n",
    "    index_stop = [np.array([tcsv[j].index(timestp_stop[i]) if timestp_stop[i] in tcsv[j] else tcsv[j].index(timestp_stop_new[i]) for i in range(0, len(timestp_stop))]) for j in range(0,2)]\n",
    "    \n",
    "    \n",
    "    \n",
    "    print(id, \":\")\n",
    "    #print(tcsv[0])\n",
    "    #print( timestp_start)\n",
    "    #print (timestp_stop)\n",
    "    print(index_start )\n",
    "    print(index_stop )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3/id_2/recording2/15 mins trial. \n",
      "<function shift_df at 0x1234a35e0>\n",
      "        03-02-2023 12:47:08.400  430858240  03-02-2023 12:47:15.264  1734  \\\n",
      "176959  03-02-2023 13:10:44.080  442183680  03-02-2023 13:10:52.105  2126   \n",
      "176960  03-02-2023 13:10:44.080  442183680  03-02-2023 13:10:52.105  2146   \n",
      "176961  03-02-2023 13:10:44.080  442183680  03-02-2023 13:10:52.105  2189   \n",
      "176962  03-02-2023 13:10:44.080  442183680  03-02-2023 13:10:52.105  2256   \n",
      "176963  03-02-2023 13:10:44.080  442183680  03-02-2023 13:10:52.105  2355   \n",
      "...                         ...        ...                      ...   ...   \n",
      "184506  03-02-2023 13:11:44.240  442664960  03-02-2023 13:11:51.526  1523   \n",
      "184507  03-02-2023 13:11:44.240  442664960  03-02-2023 13:11:51.526  1516   \n",
      "184508  03-02-2023 13:11:44.240  442664960  03-02-2023 13:11:51.526  1508   \n",
      "184509  03-02-2023 13:11:44.240  442664960  03-02-2023 13:11:51.526  1501   \n",
      "184510  03-02-2023 13:11:44.240  442664960  03-02-2023 13:11:51.526  1496   \n",
      "\n",
      "        Unnamed: 4  \n",
      "176959         NaN  \n",
      "176960         NaN  \n",
      "176961         NaN  \n",
      "176962         NaN  \n",
      "176963         NaN  \n",
      "...            ...  \n",
      "184506         NaN  \n",
      "184507         NaN  \n",
      "184508         NaN  \n",
      "184509         NaN  \n",
      "184510         NaN  \n",
      "\n",
      "[7552 rows x 5 columns]\n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3/id_3/recording2/15 mins trial. \n",
      "<function shift_df at 0x1234a35e0>\n",
      "        03-02-2023 12:47:08.400  430858240  03-02-2023 12:47:15.264  1734  \\\n",
      "176959  03-02-2023 13:10:44.080  442183680  03-02-2023 13:10:52.105  2126   \n",
      "176960  03-02-2023 13:10:44.080  442183680  03-02-2023 13:10:52.105  2146   \n",
      "176961  03-02-2023 13:10:44.080  442183680  03-02-2023 13:10:52.105  2189   \n",
      "176962  03-02-2023 13:10:44.080  442183680  03-02-2023 13:10:52.105  2256   \n",
      "176963  03-02-2023 13:10:44.080  442183680  03-02-2023 13:10:52.105  2355   \n",
      "...                         ...        ...                      ...   ...   \n",
      "184506  03-02-2023 13:11:44.240  442664960  03-02-2023 13:11:51.526  1523   \n",
      "184507  03-02-2023 13:11:44.240  442664960  03-02-2023 13:11:51.526  1516   \n",
      "184508  03-02-2023 13:11:44.240  442664960  03-02-2023 13:11:51.526  1508   \n",
      "184509  03-02-2023 13:11:44.240  442664960  03-02-2023 13:11:51.526  1501   \n",
      "184510  03-02-2023 13:11:44.240  442664960  03-02-2023 13:11:51.526  1496   \n",
      "\n",
      "        Unnamed: 4  \n",
      "176959         NaN  \n",
      "176960         NaN  \n",
      "176961         NaN  \n",
      "176962         NaN  \n",
      "176963         NaN  \n",
      "...            ...  \n",
      "184506         NaN  \n",
      "184507         NaN  \n",
      "184508         NaN  \n",
      "184509         NaN  \n",
      "184510         NaN  \n",
      "\n",
      "[7552 rows x 5 columns]\n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3/id_6/recording2/15 mins trial. \n",
      "<function shift_df at 0x1234a35e0>\n",
      "        03-02-2023 12:47:08.400  430858240  03-02-2023 12:47:15.264  1734  \\\n",
      "176959  03-02-2023 13:10:44.080  442183680  03-02-2023 13:10:52.105  2126   \n",
      "176960  03-02-2023 13:10:44.080  442183680  03-02-2023 13:10:52.105  2146   \n",
      "176961  03-02-2023 13:10:44.080  442183680  03-02-2023 13:10:52.105  2189   \n",
      "176962  03-02-2023 13:10:44.080  442183680  03-02-2023 13:10:52.105  2256   \n",
      "176963  03-02-2023 13:10:44.080  442183680  03-02-2023 13:10:52.105  2355   \n",
      "...                         ...        ...                      ...   ...   \n",
      "184506  03-02-2023 13:11:44.240  442664960  03-02-2023 13:11:51.526  1523   \n",
      "184507  03-02-2023 13:11:44.240  442664960  03-02-2023 13:11:51.526  1516   \n",
      "184508  03-02-2023 13:11:44.240  442664960  03-02-2023 13:11:51.526  1508   \n",
      "184509  03-02-2023 13:11:44.240  442664960  03-02-2023 13:11:51.526  1501   \n",
      "184510  03-02-2023 13:11:44.240  442664960  03-02-2023 13:11:51.526  1496   \n",
      "\n",
      "        Unnamed: 4  \n",
      "176959         NaN  \n",
      "176960         NaN  \n",
      "176961         NaN  \n",
      "176962         NaN  \n",
      "176963         NaN  \n",
      "...            ...  \n",
      "184506         NaN  \n",
      "184507         NaN  \n",
      "184508         NaN  \n",
      "184509         NaN  \n",
      "184510         NaN  \n",
      "\n",
      "[7552 rows x 5 columns]\n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3/id_7/recording2/15 mins trial. \n",
      "<function shift_df at 0x1234a35e0>\n",
      "        03-02-2023 12:47:08.400  430858240  03-02-2023 12:47:15.264  1734  \\\n",
      "176959  03-02-2023 13:10:44.080  442183680  03-02-2023 13:10:52.105  2126   \n",
      "176960  03-02-2023 13:10:44.080  442183680  03-02-2023 13:10:52.105  2146   \n",
      "176961  03-02-2023 13:10:44.080  442183680  03-02-2023 13:10:52.105  2189   \n",
      "176962  03-02-2023 13:10:44.080  442183680  03-02-2023 13:10:52.105  2256   \n",
      "176963  03-02-2023 13:10:44.080  442183680  03-02-2023 13:10:52.105  2355   \n",
      "...                         ...        ...                      ...   ...   \n",
      "184506  03-02-2023 13:11:44.240  442664960  03-02-2023 13:11:51.526  1523   \n",
      "184507  03-02-2023 13:11:44.240  442664960  03-02-2023 13:11:51.526  1516   \n",
      "184508  03-02-2023 13:11:44.240  442664960  03-02-2023 13:11:51.526  1508   \n",
      "184509  03-02-2023 13:11:44.240  442664960  03-02-2023 13:11:51.526  1501   \n",
      "184510  03-02-2023 13:11:44.240  442664960  03-02-2023 13:11:51.526  1496   \n",
      "\n",
      "        Unnamed: 4  \n",
      "176959         NaN  \n",
      "176960         NaN  \n",
      "176961         NaN  \n",
      "176962         NaN  \n",
      "176963         NaN  \n",
      "...            ...  \n",
      "184506         NaN  \n",
      "184507         NaN  \n",
      "184508         NaN  \n",
      "184509         NaN  \n",
      "184510         NaN  \n",
      "\n",
      "[7552 rows x 5 columns]\n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3/id_8/recording2/15 mins trial. \n",
      "<function shift_df at 0x1234a35e0>\n",
      "        03-02-2023 12:47:08.400  430858240  03-02-2023 12:47:15.264  1734  \\\n",
      "176959  03-02-2023 13:10:44.080  442183680  03-02-2023 13:10:52.105  2126   \n",
      "176960  03-02-2023 13:10:44.080  442183680  03-02-2023 13:10:52.105  2146   \n",
      "176961  03-02-2023 13:10:44.080  442183680  03-02-2023 13:10:52.105  2189   \n",
      "176962  03-02-2023 13:10:44.080  442183680  03-02-2023 13:10:52.105  2256   \n",
      "176963  03-02-2023 13:10:44.080  442183680  03-02-2023 13:10:52.105  2355   \n",
      "...                         ...        ...                      ...   ...   \n",
      "184506  03-02-2023 13:11:44.240  442664960  03-02-2023 13:11:51.526  1523   \n",
      "184507  03-02-2023 13:11:44.240  442664960  03-02-2023 13:11:51.526  1516   \n",
      "184508  03-02-2023 13:11:44.240  442664960  03-02-2023 13:11:51.526  1508   \n",
      "184509  03-02-2023 13:11:44.240  442664960  03-02-2023 13:11:51.526  1501   \n",
      "184510  03-02-2023 13:11:44.240  442664960  03-02-2023 13:11:51.526  1496   \n",
      "\n",
      "        Unnamed: 4  \n",
      "176959         NaN  \n",
      "176960         NaN  \n",
      "176961         NaN  \n",
      "176962         NaN  \n",
      "176963         NaN  \n",
      "...            ...  \n",
      "184506         NaN  \n",
      "184507         NaN  \n",
      "184508         NaN  \n",
      "184509         NaN  \n",
      "184510         NaN  \n",
      "\n",
      "[7552 rows x 5 columns]\n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3/id_9/recording2/15 mins trial. \n",
      "<function shift_df at 0x1234a35e0>\n",
      "        03-02-2023 12:47:08.400  430858240  03-02-2023 12:47:15.264  1734  \\\n",
      "176959  03-02-2023 13:10:44.080  442183680  03-02-2023 13:10:52.105  2126   \n",
      "176960  03-02-2023 13:10:44.080  442183680  03-02-2023 13:10:52.105  2146   \n",
      "176961  03-02-2023 13:10:44.080  442183680  03-02-2023 13:10:52.105  2189   \n",
      "176962  03-02-2023 13:10:44.080  442183680  03-02-2023 13:10:52.105  2256   \n",
      "176963  03-02-2023 13:10:44.080  442183680  03-02-2023 13:10:52.105  2355   \n",
      "...                         ...        ...                      ...   ...   \n",
      "184506  03-02-2023 13:11:44.240  442664960  03-02-2023 13:11:51.526  1523   \n",
      "184507  03-02-2023 13:11:44.240  442664960  03-02-2023 13:11:51.526  1516   \n",
      "184508  03-02-2023 13:11:44.240  442664960  03-02-2023 13:11:51.526  1508   \n",
      "184509  03-02-2023 13:11:44.240  442664960  03-02-2023 13:11:51.526  1501   \n",
      "184510  03-02-2023 13:11:44.240  442664960  03-02-2023 13:11:51.526  1496   \n",
      "\n",
      "        Unnamed: 4  \n",
      "176959         NaN  \n",
      "176960         NaN  \n",
      "176961         NaN  \n",
      "176962         NaN  \n",
      "176963         NaN  \n",
      "...            ...  \n",
      "184506         NaN  \n",
      "184507         NaN  \n",
      "184508         NaN  \n",
      "184509         NaN  \n",
      "184510         NaN  \n",
      "\n",
      "[7552 rows x 5 columns]\n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3/id_10/recording2/15 mins trial. \n",
      "<function shift_df at 0x1234a35e0>\n",
      "        03-02-2023 12:47:08.400  430858240  03-02-2023 12:47:15.264  1734  \\\n",
      "176959  03-02-2023 13:10:44.080  442183680  03-02-2023 13:10:52.105  2126   \n",
      "176960  03-02-2023 13:10:44.080  442183680  03-02-2023 13:10:52.105  2146   \n",
      "176961  03-02-2023 13:10:44.080  442183680  03-02-2023 13:10:52.105  2189   \n",
      "176962  03-02-2023 13:10:44.080  442183680  03-02-2023 13:10:52.105  2256   \n",
      "176963  03-02-2023 13:10:44.080  442183680  03-02-2023 13:10:52.105  2355   \n",
      "...                         ...        ...                      ...   ...   \n",
      "184506  03-02-2023 13:11:44.240  442664960  03-02-2023 13:11:51.526  1523   \n",
      "184507  03-02-2023 13:11:44.240  442664960  03-02-2023 13:11:51.526  1516   \n",
      "184508  03-02-2023 13:11:44.240  442664960  03-02-2023 13:11:51.526  1508   \n",
      "184509  03-02-2023 13:11:44.240  442664960  03-02-2023 13:11:51.526  1501   \n",
      "184510  03-02-2023 13:11:44.240  442664960  03-02-2023 13:11:51.526  1496   \n",
      "\n",
      "        Unnamed: 4  \n",
      "176959         NaN  \n",
      "176960         NaN  \n",
      "176961         NaN  \n",
      "176962         NaN  \n",
      "176963         NaN  \n",
      "...            ...  \n",
      "184506         NaN  \n",
      "184507         NaN  \n",
      "184508         NaN  \n",
      "184509         NaN  \n",
      "184510         NaN  \n",
      "\n",
      "[7552 rows x 5 columns]\n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3/id_11/recording2/15 mins trial. \n",
      "<function shift_df at 0x1234a35e0>\n",
      "        03-02-2023 12:47:08.400  430858240  03-02-2023 12:47:15.264  1734  \\\n",
      "176959  03-02-2023 13:10:44.080  442183680  03-02-2023 13:10:52.105  2126   \n",
      "176960  03-02-2023 13:10:44.080  442183680  03-02-2023 13:10:52.105  2146   \n",
      "176961  03-02-2023 13:10:44.080  442183680  03-02-2023 13:10:52.105  2189   \n",
      "176962  03-02-2023 13:10:44.080  442183680  03-02-2023 13:10:52.105  2256   \n",
      "176963  03-02-2023 13:10:44.080  442183680  03-02-2023 13:10:52.105  2355   \n",
      "...                         ...        ...                      ...   ...   \n",
      "184506  03-02-2023 13:11:44.240  442664960  03-02-2023 13:11:51.526  1523   \n",
      "184507  03-02-2023 13:11:44.240  442664960  03-02-2023 13:11:51.526  1516   \n",
      "184508  03-02-2023 13:11:44.240  442664960  03-02-2023 13:11:51.526  1508   \n",
      "184509  03-02-2023 13:11:44.240  442664960  03-02-2023 13:11:51.526  1501   \n",
      "184510  03-02-2023 13:11:44.240  442664960  03-02-2023 13:11:51.526  1496   \n",
      "\n",
      "        Unnamed: 4  \n",
      "176959         NaN  \n",
      "176960         NaN  \n",
      "176961         NaN  \n",
      "176962         NaN  \n",
      "176963         NaN  \n",
      "...            ...  \n",
      "184506         NaN  \n",
      "184507         NaN  \n",
      "184508         NaN  \n",
      "184509         NaN  \n",
      "184510         NaN  \n",
      "\n",
      "[7552 rows x 5 columns]\n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3/id_12/recording2/15 mins trial. \n",
      "<function shift_df at 0x1234a35e0>\n",
      "        03-02-2023 12:47:08.400  430858240  03-02-2023 12:47:15.264  1734  \\\n",
      "176959  03-02-2023 13:10:44.080  442183680  03-02-2023 13:10:52.105  2126   \n",
      "176960  03-02-2023 13:10:44.080  442183680  03-02-2023 13:10:52.105  2146   \n",
      "176961  03-02-2023 13:10:44.080  442183680  03-02-2023 13:10:52.105  2189   \n",
      "176962  03-02-2023 13:10:44.080  442183680  03-02-2023 13:10:52.105  2256   \n",
      "176963  03-02-2023 13:10:44.080  442183680  03-02-2023 13:10:52.105  2355   \n",
      "...                         ...        ...                      ...   ...   \n",
      "184506  03-02-2023 13:11:44.240  442664960  03-02-2023 13:11:51.526  1523   \n",
      "184507  03-02-2023 13:11:44.240  442664960  03-02-2023 13:11:51.526  1516   \n",
      "184508  03-02-2023 13:11:44.240  442664960  03-02-2023 13:11:51.526  1508   \n",
      "184509  03-02-2023 13:11:44.240  442664960  03-02-2023 13:11:51.526  1501   \n",
      "184510  03-02-2023 13:11:44.240  442664960  03-02-2023 13:11:51.526  1496   \n",
      "\n",
      "        Unnamed: 4  \n",
      "176959         NaN  \n",
      "176960         NaN  \n",
      "176961         NaN  \n",
      "176962         NaN  \n",
      "176963         NaN  \n",
      "...            ...  \n",
      "184506         NaN  \n",
      "184507         NaN  \n",
      "184508         NaN  \n",
      "184509         NaN  \n",
      "184510         NaN  \n",
      "\n",
      "[7552 rows x 5 columns]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3/id_13/recording2/15 mins trial. \n",
      "<function shift_df at 0x1234a35e0>\n",
      "        03-02-2023 12:47:08.400  430858240  03-02-2023 12:47:15.264  1734  \\\n",
      "176959  03-02-2023 13:10:44.080  442183680  03-02-2023 13:10:52.105  2126   \n",
      "176960  03-02-2023 13:10:44.080  442183680  03-02-2023 13:10:52.105  2146   \n",
      "176961  03-02-2023 13:10:44.080  442183680  03-02-2023 13:10:52.105  2189   \n",
      "176962  03-02-2023 13:10:44.080  442183680  03-02-2023 13:10:52.105  2256   \n",
      "176963  03-02-2023 13:10:44.080  442183680  03-02-2023 13:10:52.105  2355   \n",
      "...                         ...        ...                      ...   ...   \n",
      "184506  03-02-2023 13:11:44.240  442664960  03-02-2023 13:11:51.526  1523   \n",
      "184507  03-02-2023 13:11:44.240  442664960  03-02-2023 13:11:51.526  1516   \n",
      "184508  03-02-2023 13:11:44.240  442664960  03-02-2023 13:11:51.526  1508   \n",
      "184509  03-02-2023 13:11:44.240  442664960  03-02-2023 13:11:51.526  1501   \n",
      "184510  03-02-2023 13:11:44.240  442664960  03-02-2023 13:11:51.526  1496   \n",
      "\n",
      "        Unnamed: 4  \n",
      "176959         NaN  \n",
      "176960         NaN  \n",
      "176961         NaN  \n",
      "176962         NaN  \n",
      "176963         NaN  \n",
      "...            ...  \n",
      "184506         NaN  \n",
      "184507         NaN  \n",
      "184508         NaN  \n",
      "184509         NaN  \n",
      "184510         NaN  \n",
      "\n",
      "[7552 rows x 5 columns]\n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3/id_14/recording2/15 mins trial. \n",
      "<function shift_df at 0x1234a35e0>\n",
      "        03-02-2023 12:47:08.400  430858240  03-02-2023 12:47:15.264  1734  \\\n",
      "176959  03-02-2023 13:10:44.080  442183680  03-02-2023 13:10:52.105  2126   \n",
      "176960  03-02-2023 13:10:44.080  442183680  03-02-2023 13:10:52.105  2146   \n",
      "176961  03-02-2023 13:10:44.080  442183680  03-02-2023 13:10:52.105  2189   \n",
      "176962  03-02-2023 13:10:44.080  442183680  03-02-2023 13:10:52.105  2256   \n",
      "176963  03-02-2023 13:10:44.080  442183680  03-02-2023 13:10:52.105  2355   \n",
      "...                         ...        ...                      ...   ...   \n",
      "184506  03-02-2023 13:11:44.240  442664960  03-02-2023 13:11:51.526  1523   \n",
      "184507  03-02-2023 13:11:44.240  442664960  03-02-2023 13:11:51.526  1516   \n",
      "184508  03-02-2023 13:11:44.240  442664960  03-02-2023 13:11:51.526  1508   \n",
      "184509  03-02-2023 13:11:44.240  442664960  03-02-2023 13:11:51.526  1501   \n",
      "184510  03-02-2023 13:11:44.240  442664960  03-02-2023 13:11:51.526  1496   \n",
      "\n",
      "        Unnamed: 4  \n",
      "176959         NaN  \n",
      "176960         NaN  \n",
      "176961         NaN  \n",
      "176962         NaN  \n",
      "176963         NaN  \n",
      "...            ...  \n",
      "184506         NaN  \n",
      "184507         NaN  \n",
      "184508         NaN  \n",
      "184509         NaN  \n",
      "184510         NaN  \n",
      "\n",
      "[7552 rows x 5 columns]\n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3/id_15/recording2/15 mins trial. \n",
      "<function shift_df at 0x1234a35e0>\n",
      "        03-02-2023 12:47:08.400  430858240  03-02-2023 12:47:15.264  1734  \\\n",
      "176959  03-02-2023 13:10:44.080  442183680  03-02-2023 13:10:52.105  2126   \n",
      "176960  03-02-2023 13:10:44.080  442183680  03-02-2023 13:10:52.105  2146   \n",
      "176961  03-02-2023 13:10:44.080  442183680  03-02-2023 13:10:52.105  2189   \n",
      "176962  03-02-2023 13:10:44.080  442183680  03-02-2023 13:10:52.105  2256   \n",
      "176963  03-02-2023 13:10:44.080  442183680  03-02-2023 13:10:52.105  2355   \n",
      "...                         ...        ...                      ...   ...   \n",
      "184506  03-02-2023 13:11:44.240  442664960  03-02-2023 13:11:51.526  1523   \n",
      "184507  03-02-2023 13:11:44.240  442664960  03-02-2023 13:11:51.526  1516   \n",
      "184508  03-02-2023 13:11:44.240  442664960  03-02-2023 13:11:51.526  1508   \n",
      "184509  03-02-2023 13:11:44.240  442664960  03-02-2023 13:11:51.526  1501   \n",
      "184510  03-02-2023 13:11:44.240  442664960  03-02-2023 13:11:51.526  1496   \n",
      "\n",
      "        Unnamed: 4  \n",
      "176959         NaN  \n",
      "176960         NaN  \n",
      "176961         NaN  \n",
      "176962         NaN  \n",
      "176963         NaN  \n",
      "...            ...  \n",
      "184506         NaN  \n",
      "184507         NaN  \n",
      "184508         NaN  \n",
      "184509         NaN  \n",
      "184510         NaN  \n",
      "\n",
      "[7552 rows x 5 columns]\n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3/id_16/recording2/15 mins trial. \n",
      "<function shift_df at 0x1234a35e0>\n",
      "        03-02-2023 12:47:08.400  430858240  03-02-2023 12:47:15.264  1734  \\\n",
      "176959  03-02-2023 13:10:44.080  442183680  03-02-2023 13:10:52.105  2126   \n",
      "176960  03-02-2023 13:10:44.080  442183680  03-02-2023 13:10:52.105  2146   \n",
      "176961  03-02-2023 13:10:44.080  442183680  03-02-2023 13:10:52.105  2189   \n",
      "176962  03-02-2023 13:10:44.080  442183680  03-02-2023 13:10:52.105  2256   \n",
      "176963  03-02-2023 13:10:44.080  442183680  03-02-2023 13:10:52.105  2355   \n",
      "...                         ...        ...                      ...   ...   \n",
      "184506  03-02-2023 13:11:44.240  442664960  03-02-2023 13:11:51.526  1523   \n",
      "184507  03-02-2023 13:11:44.240  442664960  03-02-2023 13:11:51.526  1516   \n",
      "184508  03-02-2023 13:11:44.240  442664960  03-02-2023 13:11:51.526  1508   \n",
      "184509  03-02-2023 13:11:44.240  442664960  03-02-2023 13:11:51.526  1501   \n",
      "184510  03-02-2023 13:11:44.240  442664960  03-02-2023 13:11:51.526  1496   \n",
      "\n",
      "        Unnamed: 4  \n",
      "176959         NaN  \n",
      "176960         NaN  \n",
      "176961         NaN  \n",
      "176962         NaN  \n",
      "176963         NaN  \n",
      "...            ...  \n",
      "184506         NaN  \n",
      "184507         NaN  \n",
      "184508         NaN  \n",
      "184509         NaN  \n",
      "184510         NaN  \n",
      "\n",
      "[7552 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "# Import the required libraries\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "From frame_v2 import info\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# ------------------------------------------------------------------------------------------------------------------------------\n",
    "# for splitting the csv files of PPG and hr csv files in 15 mins trial#\n",
    "def df(Id, index, datafile_dir: str, datafile_dir_new: str, save_excel: bool = False) -> pd.DataFrame:\n",
    "    \n",
    "    # Settings and filenames\n",
    "    devices = [\"Iphone\", \"Ipad\"]\n",
    "    filename = [\"MPDataExport_shifted\", \"NOM_PLETHWaveExport\"]\n",
    "    lum_dist = [\"100_0.4\",\"100_0.5\", \"100_0.6\", \"200_0.4\",\"200_0.5\",\"200_0.6\", \"300_0.4\", \"300_0.5\",\"300_0.6\", \"500_0.4\", \"500_0.5\", \"500_0.6\", \"1000_0.4\", \"1000_0.5\", \"1000_0.6\"]\n",
    "    # load the recording timeframe of Ipad video recordings in second\n",
    "    rgb = np.load(r\"{}/{}_mediapipe_meanRGB.npz\".format(datafile_dir, devices[1]), mmap_mode = 'r', allow_pickle = True)['arr_0']\n",
    "\n",
    "    rgb = rgb.reshape(-1, 1)[0][0]\n",
    "    \n",
    "    # Start record timestamps of Ipad\n",
    "    dt = [datetime.strptime(\"13-02-2023 17:00:34.00\", \"%d-%m-%Y %H:%M:%S.%f\"),\n",
    "        datetime.strptime(\"19-01-2023 15:56:47.00\", \"%d-%m-%Y %H:%M:%S.%f\"),\n",
    "         datetime.strptime(\"03-02-2023 12:47:16.00\", \"%d-%m-%Y %H:%M:%S.%f\"),\n",
    "          datetime.strptime(\"13-02-2023 17:46:14.00\", \"%d-%m-%Y %H:%M:%S.%f\"),\n",
    "          datetime.strptime(\"19-01-2023 12:17:25.00\", \"%d-%m-%Y %H:%M:%S.%f\"),\n",
    "          datetime.strptime(\"19-01-2023 17:11:56.00\", \"%d-%m-%Y %H:%M:%S.%f\"),\n",
    "         datetime.strptime(\"20-01-2023 12:35:17.00\", \"%d-%m-%Y %H:%M:%S.%f\"),\n",
    "          \n",
    "         datetime.strptime(\"20-01-2023 16:45:16.00\", \"%d-%m-%Y %H:%M:%S.%f\"),\n",
    "         datetime.strptime(\"26-01-2023 15:35:41.00\", \"%d-%m-%Y %H:%M:%S.%f\"),\n",
    "         datetime.strptime(\"26-01-2023 16:39:31.00\", \"%d-%m-%Y %H:%M:%S.%f\"),\n",
    "         datetime.strptime(\"26-01-2023 18:00:58.00\", \"%d-%m-%Y %H:%M:%S.%f\"),\n",
    "         datetime.strptime(\"27-01-2023 15:14:51.00\", \"%d-%m-%Y %H:%M:%S.%f\"),\n",
    "         datetime.strptime(\"03-02-2023 15:16:17.00\", \"%d-%m-%Y %H:%M:%S.%f\"),\n",
    "         datetime.strptime(\"06-02-2023 16:34:22.00\", \"%d-%m-%Y %H:%M:%S.%f\"),\n",
    "         datetime.strptime(\"06-02-2023 17:31:56.00\", \"%d-%m-%Y %H:%M:%S.%f\"),\n",
    "         datetime.strptime(\"07-02-2023 11:05:04.00\", \"%d-%m-%Y %H:%M:%S.%f\")]\n",
    "    # Generate timestamps of Ipad\n",
    "    ts = dt[index].timestamp()\n",
    "    list1 = [str((dt[index].fromtimestamp(int((rgb['mean_RGB']['Timestamp (s)'][i]) + ts) ))) for i in range(0,len(rgb['mean_RGB']['Timestamp (s)']))]\n",
    "\n",
    "    # Generate timestamps of start/stop for the 15 conditions\n",
    "    timestp_start = [list1[info[\"{}_Ipad_{}\".format(Id, ld)][0]] for ld in  lum_dist]\n",
    "    timestp_stop = [list1[info[\"{}_Ipad_{}\".format(Id, ld)][1]] for ld in lum_dist]\n",
    "    \n",
    "    # Generate timestamps of start/stop for the 15 conditions (If above timestamps do not correspond to csv timestamps )\n",
    "    timestp_start_new =  [str(datetime.strptime(timestp_start[i] , \"%Y-%m-%d %H:%M:%S\") + timedelta(seconds=1)) for i in range(0, len(timestp_start))]\n",
    "    timestp_stop_new =  [str(datetime.strptime(timestp_stop[i] , \"%Y-%m-%d %H:%M:%S\") + timedelta(seconds=1)) for i in range(0, len(timestp_start))]\n",
    "\n",
    "   \n",
    "    # Rea the csv files\n",
    "    df = [pd.read_csv(r\"/Users/kinho123/Downloads/v3/id_{}/recording2/15 mins trial/{}.csv\".format(Id, j)) for j in filename]\n",
    "    \n",
    "    # Timestamps of csv files\n",
    "    ti = [[datetime.strptime(df[0][\"SystemLocalTime\"][i], \"%d-%m-%Y %H:%M:%S.%f\") for i in range(0, len(df[0]))],\n",
    "          [datetime.strptime(df[1].iloc[:, 2][i], \"%d-%m-%Y %H:%M:%S.%f\") for i in range(0, len(df[1]))]]\n",
    "    \n",
    "    # Relative time and Timestamps of csv files (rounded) \n",
    "    trel = [[int(ti[j][i].timestamp()) for i in range(0, len(df[j]))] for j in range(0,2)]\n",
    "    tcsv = [[str(dt[index].fromtimestamp(trel[j][i])) for i in range(0, len(df[j]))] for j in range(0,2)]\n",
    "    \n",
    "    # Start/Stop index of csv files for the 15 conditions\n",
    "    index_start = [np.array([tcsv[j].index(timestp_start[i]) if timestp_start[i] in tcsv[j] else tcsv[j].index(timestp_start_new[i]) for i in range(0, len(timestp_start))]) for j in range(0,2)] \n",
    "    index_stop = [np.array([tcsv[j].index(timestp_stop[i]) if timestp_stop[i] in tcsv[j] else tcsv[j].index(timestp_stop_new[i]) for i in range(0, len(timestp_stop))]) for j in range(0,2)]\n",
    "    \n",
    "    # Loop over each filename and setup\n",
    "    for j, name in enumerate(filename):\n",
    "        s = index_start[j] \n",
    "        f = index_stop[j]\n",
    "        for i, ld in enumerate(lum_dist):\n",
    "            for device in devices:\n",
    "                \n",
    "                # Split the csv files into 15 conditions for Iphone/Ipad\n",
    "                mp_df = pd.read_csv(r\"{}/{}.csv\".format(datafile_dir, name) )[s[i]:f[i]]\n",
    "                mp_df.to_csv(r\"{}_{}_{}/{}.csv\".format(datafile_dir_new, device, ld, name), header = True, index = False)\n",
    "                print(\"The csv file has been formed in the directory {}. \".format(datafile_dir))\n",
    "                \n",
    "                if name == \"MPDataExport_shifted\":\n",
    "                    mp_df[\"NOM_PRESS_BLD_NONINV_PULS_RATE\"].to_csv(r\"{}_{}_{}/HR_Clip.csv\".format(datafile_dir_new, device, ld, name), header = True, index = False)\n",
    "                    mp_df[\"NOM_ECG_CARD_BEAT_RATE\"].to_csv(r\"{}_{}_{}/HR_ECG.csv\".format(datafile_dir_new, device, ld, name), header = True, index = False)\n",
    "                    print(\"The csv file has been formed in the directory {}. \".format(datafile_dir))\n",
    "                        # Return the dataframe\n",
    "    return mp_df\n",
    "\n",
    "\n",
    "def shift_df(datafile_dir: str, save_excel: bool = False) -> pd.DataFrame:\n",
    "    # Import the required libraries\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    # Read the mp csv\n",
    "    df = pd.read_csv(r\"{}/MPDataExport.csv\".format(datafile_dir))\n",
    "    # Change the data type of time\n",
    "    df[\"Time\"] = pd.to_datetime(df[\"Time\"], format=\"%d-%m-%Y %H:%M:%S.%f\")\n",
    "    # Change the data type of system local time\n",
    "    df[\"SystemLocalTime\"] = pd.to_datetime(df[\"SystemLocalTime\"], format=\"%d-%m-%Y %H:%M:%S.%f\")\n",
    "    # Replace the hivine by np.nan\n",
    "    df = df.replace(\"-\", np.nan)\n",
    "    # Change the types of the data\n",
    "    df[['NOM_PRESS_BLD_NONINV_SYS', 'NOM_PRESS_BLD_NONINV_DIA',\n",
    "        'NOM_PRESS_BLD_NONINV_MEAN', 'NOM_PRESS_BLD_NONINV_PULS_RATE',\n",
    "        'NOM_PULS_OXIM_SAT_O2', 'NOM_PLETH_PULS_RATE']] = df[['NOM_PRESS_BLD_NONINV_SYS', 'NOM_PRESS_BLD_NONINV_DIA',\n",
    "                                                              'NOM_PRESS_BLD_NONINV_MEAN',\n",
    "                                                              'NOM_PRESS_BLD_NONINV_PULS_RATE',\n",
    "                                                              'NOM_PULS_OXIM_SAT_O2', 'NOM_PLETH_PULS_RATE']].astype(\n",
    "        np.float64())\n",
    "    df[['NOM_PLETH_PULS_RATE']] = df[['NOM_PLETH_PULS_RATE']].astype(np.float64())\n",
    "\n",
    "    # ---------------------------------------- shift_df part --------------------------------\n",
    "    # To adjust the displaced tables in MP data csv file\n",
    "    # Extract the shifted rows\n",
    "    shift_df = df[df[\"NOM_PLETH_PULS_RATE\"].isna() & df[\"NOM_PULS_OXIM_PERF_REL\"].isna()]\n",
    "    # Extract the values of the req_df\n",
    "    mat = np.concatenate([shift_df.values[:, 0:4], shift_df.values[:, 12:14], shift_df.values[:, 4:12]], axis=1)\n",
    "    # Restore the shifted rows\n",
    "    restored_shift_df = pd.DataFrame(mat, columns=shift_df.columns.tolist(), index=shift_df.index)\n",
    "    # Check the dimensions after the restoration\n",
    "    assert np.shape(shift_df) == np.shape(restored_shift_df)\n",
    "    # Restored the mp dataframe\n",
    "    df.iloc[shift_df.index] = restored_shift_df\n",
    "    # Save the dataframe as an excel file\n",
    "    if save_excel == True:\n",
    "        df.to_csv(r\"{}/MPDataExport_shifted.csv\".format(datafile_dir), header=True, index=False)\n",
    "        print(\"The csv file has been formed in the directory {}. \".format(datafile_dir))\n",
    "    # Return the dataframe\n",
    "    return df\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Define the directory and the filename\n",
    "    num = [1,2,3,4,6,7,8,9,10,11,12,13,14,15,16]\n",
    "    for index, Id in enumerate(num):\n",
    "        \n",
    "        # Show the directory\n",
    "        datafile_dir = r\"/Users/kinho123/Downloads/v3/id_{}/recording2/15 mins trial\".format(Id)\n",
    "        datafile_dir_new = r\"/Users/kinho123/Downloads/PABPv4 (Shutao)/id{}\".format(Id)\n",
    "\n",
    "        # Generate the split csv\n",
    "        shift_df(datafile_dir = datafile_dir , save_excel = True)\n",
    "        #mp_df = df(Id, index, datafile_dir = datafile_dir, datafile_dir_new = datafile_dir_new, save_excel = True)\n",
    "        # Read the csv\n",
    "        print(shift_df)\n",
    "        print(mp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_1/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/PABPv3.1 (Trimmed)/id1. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_1/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/PABPv3.1 (Trimmed)/id1. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_1/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_1/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_1/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/PABPv3.1 (Trimmed)/id1. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_1/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/PABPv3.1 (Trimmed)/id1. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_1/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_1/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_1/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/PABPv3.1 (Trimmed)/id1. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_1/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/PABPv3.1 (Trimmed)/id1. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_1/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_1/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_1/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/PABPv3.1 (Trimmed)/id1. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_1/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/PABPv3.1 (Trimmed)/id1. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_1/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_1/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_1/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/PABPv3.1 (Trimmed)/id1. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_1/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/PABPv3.1 (Trimmed)/id1. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_1/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_1/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_2/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/PABPv3.1 (Trimmed)/id2. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_2/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/PABPv3.1 (Trimmed)/id2. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_2/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_2/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_2/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/PABPv3.1 (Trimmed)/id2. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_2/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/PABPv3.1 (Trimmed)/id2. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_2/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_2/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_2/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/PABPv3.1 (Trimmed)/id2. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_2/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/PABPv3.1 (Trimmed)/id2. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_2/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_2/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_2/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/PABPv3.1 (Trimmed)/id2. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_2/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/PABPv3.1 (Trimmed)/id2. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_2/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_2/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_2/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/PABPv3.1 (Trimmed)/id2. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_2/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/PABPv3.1 (Trimmed)/id2. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_2/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_2/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_3/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/PABPv3.1 (Trimmed)/id3. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_3/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/PABPv3.1 (Trimmed)/id3. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_3/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_3/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_3/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/PABPv3.1 (Trimmed)/id3. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_3/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/PABPv3.1 (Trimmed)/id3. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_3/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_3/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_3/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/PABPv3.1 (Trimmed)/id3. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_3/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/PABPv3.1 (Trimmed)/id3. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_3/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_3/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_3/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/PABPv3.1 (Trimmed)/id3. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_3/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/PABPv3.1 (Trimmed)/id3. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_3/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_3/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_3/recording2/13 mins trial. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The csv file has been formed in the directory /Users/kinho123/Downloads/PABPv3.1 (Trimmed)/id3. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_3/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/PABPv3.1 (Trimmed)/id3. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_3/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_3/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_4/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/PABPv3.1 (Trimmed)/id4. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_4/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/PABPv3.1 (Trimmed)/id4. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_4/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_4/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_4/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/PABPv3.1 (Trimmed)/id4. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_4/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/PABPv3.1 (Trimmed)/id4. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_4/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_4/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_4/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/PABPv3.1 (Trimmed)/id4. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_4/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/PABPv3.1 (Trimmed)/id4. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_4/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_4/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_4/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/PABPv3.1 (Trimmed)/id4. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_4/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/PABPv3.1 (Trimmed)/id4. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_4/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_4/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_4/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/PABPv3.1 (Trimmed)/id4. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_4/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/PABPv3.1 (Trimmed)/id4. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_4/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_4/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_5/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/PABPv3.1 (Trimmed)/id5. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_5/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/PABPv3.1 (Trimmed)/id5. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_5/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_5/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_5/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/PABPv3.1 (Trimmed)/id5. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_5/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/PABPv3.1 (Trimmed)/id5. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_5/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_5/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_5/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/PABPv3.1 (Trimmed)/id5. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_5/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/PABPv3.1 (Trimmed)/id5. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_5/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_5/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_5/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/PABPv3.1 (Trimmed)/id5. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_5/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/PABPv3.1 (Trimmed)/id5. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_5/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_5/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_5/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/PABPv3.1 (Trimmed)/id5. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_5/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/PABPv3.1 (Trimmed)/id5. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_5/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_5/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_6/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/PABPv3.1 (Trimmed)/id6. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_6/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/PABPv3.1 (Trimmed)/id6. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_6/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_6/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_6/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/PABPv3.1 (Trimmed)/id6. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_6/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/PABPv3.1 (Trimmed)/id6. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_6/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_6/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_6/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/PABPv3.1 (Trimmed)/id6. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_6/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/PABPv3.1 (Trimmed)/id6. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_6/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_6/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_6/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/PABPv3.1 (Trimmed)/id6. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_6/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/PABPv3.1 (Trimmed)/id6. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_6/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_6/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_6/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/PABPv3.1 (Trimmed)/id6. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_6/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/PABPv3.1 (Trimmed)/id6. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_6/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_6/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_7/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/PABPv3.1 (Trimmed)/id7. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_7/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/PABPv3.1 (Trimmed)/id7. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_7/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_7/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_7/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/PABPv3.1 (Trimmed)/id7. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_7/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/PABPv3.1 (Trimmed)/id7. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_7/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_7/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_7/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/PABPv3.1 (Trimmed)/id7. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_7/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/PABPv3.1 (Trimmed)/id7. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_7/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_7/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_7/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/PABPv3.1 (Trimmed)/id7. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_7/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/PABPv3.1 (Trimmed)/id7. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_7/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_7/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_7/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/PABPv3.1 (Trimmed)/id7. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_7/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/PABPv3.1 (Trimmed)/id7. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_7/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_7/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_8/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/PABPv3.1 (Trimmed)/id8. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_8/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/PABPv3.1 (Trimmed)/id8. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_8/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_8/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_8/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/PABPv3.1 (Trimmed)/id8. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_8/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/PABPv3.1 (Trimmed)/id8. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_8/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_8/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_8/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/PABPv3.1 (Trimmed)/id8. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_8/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/PABPv3.1 (Trimmed)/id8. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_8/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_8/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_8/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/PABPv3.1 (Trimmed)/id8. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_8/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/PABPv3.1 (Trimmed)/id8. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_8/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_8/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_8/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/PABPv3.1 (Trimmed)/id8. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_8/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/PABPv3.1 (Trimmed)/id8. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_8/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_8/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_9/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/PABPv3.1 (Trimmed)/id9. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_9/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/PABPv3.1 (Trimmed)/id9. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_9/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_9/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_9/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/PABPv3.1 (Trimmed)/id9. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_9/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/PABPv3.1 (Trimmed)/id9. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_9/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_9/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_9/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/PABPv3.1 (Trimmed)/id9. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_9/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/PABPv3.1 (Trimmed)/id9. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_9/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_9/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_9/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/PABPv3.1 (Trimmed)/id9. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_9/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/PABPv3.1 (Trimmed)/id9. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_9/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_9/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_9/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/PABPv3.1 (Trimmed)/id9. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_9/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/PABPv3.1 (Trimmed)/id9. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_9/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_9/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_10/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/PABPv3.1 (Trimmed)/id10. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_10/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/PABPv3.1 (Trimmed)/id10. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_10/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_10/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_10/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/PABPv3.1 (Trimmed)/id10. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_10/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/PABPv3.1 (Trimmed)/id10. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_10/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_10/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_10/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/PABPv3.1 (Trimmed)/id10. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_10/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/PABPv3.1 (Trimmed)/id10. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_10/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_10/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_10/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/PABPv3.1 (Trimmed)/id10. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_10/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/PABPv3.1 (Trimmed)/id10. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_10/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_10/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_10/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/PABPv3.1 (Trimmed)/id10. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_10/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/PABPv3.1 (Trimmed)/id10. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_10/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_10/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_11/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/PABPv3.1 (Trimmed)/id11. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_11/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/PABPv3.1 (Trimmed)/id11. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_11/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_11/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_11/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/PABPv3.1 (Trimmed)/id11. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_11/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/PABPv3.1 (Trimmed)/id11. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_11/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_11/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_11/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/PABPv3.1 (Trimmed)/id11. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_11/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/PABPv3.1 (Trimmed)/id11. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_11/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_11/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_11/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/PABPv3.1 (Trimmed)/id11. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_11/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/PABPv3.1 (Trimmed)/id11. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_11/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_11/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_11/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/PABPv3.1 (Trimmed)/id11. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_11/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/PABPv3.1 (Trimmed)/id11. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_11/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_11/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_12/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/PABPv3.1 (Trimmed)/id12. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_12/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/PABPv3.1 (Trimmed)/id12. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_12/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_12/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_12/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/PABPv3.1 (Trimmed)/id12. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_12/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/PABPv3.1 (Trimmed)/id12. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_12/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_12/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_12/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/PABPv3.1 (Trimmed)/id12. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_12/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/PABPv3.1 (Trimmed)/id12. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_12/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_12/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_12/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/PABPv3.1 (Trimmed)/id12. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_12/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/PABPv3.1 (Trimmed)/id12. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_12/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_12/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_12/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/PABPv3.1 (Trimmed)/id12. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_12/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/PABPv3.1 (Trimmed)/id12. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_12/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_12/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_13/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/PABPv3.1 (Trimmed)/id13. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_13/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/PABPv3.1 (Trimmed)/id13. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_13/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_13/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_13/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/PABPv3.1 (Trimmed)/id13. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_13/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/PABPv3.1 (Trimmed)/id13. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_13/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_13/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_13/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/PABPv3.1 (Trimmed)/id13. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_13/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/PABPv3.1 (Trimmed)/id13. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_13/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_13/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_13/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/PABPv3.1 (Trimmed)/id13. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_13/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/PABPv3.1 (Trimmed)/id13. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_13/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_13/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_13/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/PABPv3.1 (Trimmed)/id13. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_13/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/PABPv3.1 (Trimmed)/id13. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_13/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_13/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_14/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/PABPv3.1 (Trimmed)/id14. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_14/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/PABPv3.1 (Trimmed)/id14. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_14/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_14/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_14/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/PABPv3.1 (Trimmed)/id14. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_14/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/PABPv3.1 (Trimmed)/id14. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_14/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_14/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_14/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/PABPv3.1 (Trimmed)/id14. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_14/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/PABPv3.1 (Trimmed)/id14. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_14/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_14/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_14/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/PABPv3.1 (Trimmed)/id14. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_14/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/PABPv3.1 (Trimmed)/id14. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_14/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_14/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_14/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/PABPv3.1 (Trimmed)/id14. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_14/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/PABPv3.1 (Trimmed)/id14. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_14/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_14/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_15/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/PABPv3.1 (Trimmed)/id15. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_15/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/PABPv3.1 (Trimmed)/id15. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_15/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_15/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_15/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/PABPv3.1 (Trimmed)/id15. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_15/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/PABPv3.1 (Trimmed)/id15. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_15/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_15/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_15/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/PABPv3.1 (Trimmed)/id15. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_15/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/PABPv3.1 (Trimmed)/id15. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_15/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_15/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_15/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/PABPv3.1 (Trimmed)/id15. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_15/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/PABPv3.1 (Trimmed)/id15. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_15/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_15/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_15/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/PABPv3.1 (Trimmed)/id15. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_15/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/PABPv3.1 (Trimmed)/id15. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_15/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_15/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_16/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/PABPv3.1 (Trimmed)/id16. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_16/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/PABPv3.1 (Trimmed)/id16. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_16/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_16/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_16/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/PABPv3.1 (Trimmed)/id16. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_16/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/PABPv3.1 (Trimmed)/id16. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_16/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_16/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_16/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/PABPv3.1 (Trimmed)/id16. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_16/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/PABPv3.1 (Trimmed)/id16. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_16/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_16/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_16/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/PABPv3.1 (Trimmed)/id16. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_16/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/PABPv3.1 (Trimmed)/id16. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_16/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_16/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_16/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/PABPv3.1 (Trimmed)/id16. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_16/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/PABPv3.1 (Trimmed)/id16. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_16/recording2/13 mins trial. \n",
      "The csv file has been formed in the directory /Users/kinho123/Downloads/v3&4/id_16/recording2/13 mins trial. \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from datetime import datetime\n",
    "# ------------------------------------------------------------------------------------------------------------------------------\n",
    "# for splitting the csv files of vital in 13 mins trial#\n",
    "def sec_to_stamps(sec, fps):\n",
    "    if sec == 0:\n",
    "        return None\n",
    "    else:\n",
    "        return -(round(sec*fps))\n",
    "\n",
    "# for splitting the csv files of PPG and hr csv files in 13 mins trial#\n",
    "def df(datafile_dir: str, datafile_dir_new: str, save_excel: bool = False) -> pd.DataFrame:\n",
    "    # Import the required libraries\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    # Read the mp csv\n",
    "    filename = [\"MPDataExport_shifted\",  \"NOM_PLETHWaveExport\"]\n",
    "    # Settings and filenames\n",
    "    fps = [1/(1.024), 125]\n",
    "    states = [\"RestL0\", \"Breath\", \"RestS\", \"Pedal\",\"RestL1\"]\n",
    "    devices = [\"Iphone\", \"Ipad\"]\n",
    "    s = [780, 592, 405, 338, 181]\n",
    "    f = [599, 411, 344, 187, 0 ]\n",
    "    \n",
    "    # Loop over each filename and setup\n",
    "    for i, state in enumerate(states):\n",
    "        for j, name in enumerate(filename):\n",
    "            for k in devices:\n",
    "                \n",
    "                # Split the csv files into 5 conditions for Iphone/Ipad\n",
    "                mp_df = pd.read_csv(r\"{}/{}.csv\".format(datafile_dir, name) )[sec_to_stamps(s[i],fps[j]):sec_to_stamps(f[i],fps[j])]\n",
    "                mp_df.to_csv(r\"{}/{}.csv\".format(datafile_dir, name), header = True, index = False)\n",
    "                print(\"The csv file has been formed in the directory {}. \".format(datafile_dir))\n",
    "                    # Return the dataframe\n",
    "                \n",
    "                if name == \"MPDataExport_shifted\":\n",
    "                    mp_df[\"NOM_PRESS_BLD_NONINV_PULS_RATE\"].to_csv(r\"{}_{}_{}/HR_Clip.csv\".format(datafile_dir_new, k, state, name), header = True, index = False)\n",
    "                    mp_df[\"NOM_ECG_CARD_BEAT_RATE\"].to_csv(r\"{}_{}_{}/HR_ECG.csv\".format(datafile_dir_new, k, state, name), header = True, index = False)\n",
    "                    print(\"The csv file has been formed in the directory {}. \".format(datafile_dir_new))\n",
    "                    # Return the dataframe\n",
    "    return mp_df\n",
    "\n",
    "def shift_df(datafile_dir: str, save_excel: bool = False) -> pd.DataFrame:\n",
    "    # Import the required libraries\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    # Read the mp csv\n",
    "    \n",
    "    df = pd.read_csv(r\"{}/MPDataExport.csv\".format(datafile_dir))\n",
    "    # Change the data type of time\n",
    "    df[\"Time\"] = pd.to_datetime(df[\"Time\"], format=\"%d-%m-%Y %H:%M:%S.%f\")\n",
    "    # Change the data type of system local time\n",
    "    df[\"SystemLocalTime\"] = pd.to_datetime(df[\"SystemLocalTime\"], format=\"%d-%m-%Y %H:%M:%S.%f\")\n",
    "    # Replace the hivine by np.nan\n",
    "    df = df.replace(\"-\", np.nan)\n",
    "    # Change the types of the data\n",
    "    df[['NOM_PRESS_BLD_NONINV_SYS', 'NOM_PRESS_BLD_NONINV_DIA',\n",
    "        'NOM_PRESS_BLD_NONINV_MEAN', 'NOM_PRESS_BLD_NONINV_PULS_RATE',\n",
    "        'NOM_PULS_OXIM_SAT_O2', 'NOM_PLETH_PULS_RATE']] = df[['NOM_PRESS_BLD_NONINV_SYS', 'NOM_PRESS_BLD_NONINV_DIA','NOM_PRESS_BLD_NONINV_MEAN','NOM_PRESS_BLD_NONINV_PULS_RATE','NOM_PULS_OXIM_SAT_O2', 'NOM_PLETH_PULS_RATE']].astype(np.float64())\n",
    "    df[['NOM_PLETH_PULS_RATE']] = df[['NOM_PLETH_PULS_RATE']].astype(np.float64())\n",
    "\n",
    "    # ---------------------------------------- shift_df part --------------------------------\n",
    "    # To adjust the displaced tables in MP data csv file\n",
    "    # Extract the shifted rows\n",
    "    shift_df = df[df[\"NOM_PLETH_PULS_RATE\"].isna() & df[\"NOM_PULS_OXIM_PERF_REL\"].isna()]\n",
    "    # Extract the values of the req_df\n",
    "    mat = np.concatenate([shift_df.values[:, 0:4], shift_df.values[:, 12:14], shift_df.values[:, 4:12]], axis=1)\n",
    "    # Restore the shifted rows\n",
    "    restored_shift_df = pd.DataFrame(mat, columns=shift_df.columns.tolist(), index=shift_df.index)\n",
    "    # Check the dimensions after the restoration\n",
    "    assert np.shape(shift_df) == np.shape(restored_shift_df)\n",
    "    # Restored the mp dataframe\n",
    "    df.iloc[shift_df.index] = restored_shift_df\n",
    "    # Save the dataframe as an excel file\n",
    "    if save_excel == True:\n",
    "        df.to_csv(r\"{}/MPDataExport_shifted.csv\".format(datafile_dir), header=True, index=False)\n",
    "        print(\"The csv file has been formed in the directory {}. \".format(datafile_dir))\n",
    "    # Return the dataframe\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Define the directory and the filename\n",
    "    num = [Id for Id in range(1,17) ]\n",
    "    for i in num:\n",
    "        datafile_dir = r\"/Users/kinho123/Downloads/v3&4/id_{}/recording2/13 mins trial\".format(i)\n",
    "        datafile_dir_new = r\"/Users/kinho123/Downloads/PABPv3.1 (Trimmed)/id{}\".format(i)\n",
    "\n",
    "    # Read the mp csv\n",
    "     # Generate the split csv\n",
    "        #shift_df(datafile_dir = datafile_dir , save_excel = True)\n",
    "        mp_df = df(datafile_dir = datafile_dir, datafile_dir_new = datafile_dir_new, save_excel = True)\n",
    "        #print(shift_df)\n",
    "        #print(mp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
